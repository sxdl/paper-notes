<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[PaperNotesRemote]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>PaperNotesRemote</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 02 Dec 2024 05:56:11 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 02 Dec 2024 05:55:46 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br>å›ºå®šæœºä½çš„å•ç›®é‡å»º<br>åŠç›‘ç£3Dç›®æ ‡æ£€æµ‹<br>ä¸€ä¸ªæ ·æœ¬ä¸­éƒ¨åˆ†æœ‰æ ‡ç­¾çš„æƒ…å†µ<br>åŠç›‘ç£3Dç›®æ ‡æ£€æµ‹åœ¨è·¨åŸŸæ•°æ®ä¸Šçš„è¿ç§»èƒ½åŠ›<br><br><a data-href="Active&amp;SS3DOD" href="projects\active&amp;ss3dod.html" class="internal-link" target="_self" rel="noopener nofollow">Active&amp;SS3DOD</a><br>éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæ¨¡å‹çš„èƒ½åŠ›é€æ¸æé«˜ï¼Œä¼ªæ ‡ç­¾æ•°é‡é€æ¸å¢åŠ ã€‚åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç®€å•çš„ç‰©ä½“ä¼šåœ¨ä¸€å¼€å§‹å°±è¢«ç›‘ç£ï¼Œè€Œå›°éš¾çš„ç‰©ä½“å¾ˆåé¢æ‰ä¼šåŠ å…¥ï¼Œè¿™å¯¼è‡´äº†ä¸åŒçš„æ ·æœ¬ï¼Œå‡ºç°æ¬¡æ•°çš„ä¸å‡è¡¡ã€‚ä»å¦ä¸€ä¸ªè§’åº¦è®²ï¼Œæ¨¡å‹é¢å¯¹çš„æœ‰æ ‡æ³¨æ ·æœ¬æ€»ä½“ï¼ˆåŒ…å«ä¼ªæ ‡ç­¾ï¼‰åˆ†å¸ƒï¼Œä¸€ç›´åœ¨å˜åŒ–ã€‚å¦ä¸€ä¸ªè§’åº¦è®²ï¼Œå°±æ˜¯ä¸€ä¸ªæ•°æ®é›†ï¼Œä»ç®€å•åˆ°å›°éš¾ï¼Œä¸€ç‚¹ä¸€ç‚¹åœ°é€æ¸åŠ å…¥åˆ°è®­ç»ƒä¸­ï¼Œæ˜¯ä¸æ˜¯ä¸€ç§å˜ç›¸çš„æ•°æ®å¤±è¡¡ï¼Ÿ<br><img alt="Pasted image 20241023205939.png" src="lib\media\pasted-image-20241023205939.png"><br>å¦ä¸€ç§ä¸å‡è¡¡ï¼Œæ˜¯æœ‰æ ‡æ³¨æ ·æœ¬å’Œæœªæ ‡æ³¨æ ·æœ¬è®­ç»ƒbatchæ¯”ä¾‹ä¸å‡è¡¡ã€‚æ¯”å¦‚10%çš„æ•°æ®åˆ’åˆ†ï¼Œbatch sizeä¸º12ï¼ŒåŒ…å«4ä¸ªæœ‰æ ‡ç­¾æ ·æœ¬å’Œ8ä¸ªæ— æ ‡æ³¨æ ·æœ¬ã€‚é‚£ä¹ˆå¹³å‡æ¯è®­ç»ƒä¸€ä¸ªæ— æ ‡æ³¨æ ·æœ¬ï¼Œå°±è¦è®­ç»ƒ4.5éæœ‰æ ‡æ³¨æ ·æœ¬ã€‚æˆ‘ä»¬å‡è®¾ç»è¿‡ç­›é€‰çš„ä¼ªæ ‡ç­¾éƒ½æ˜¯true positiveçš„ã€‚<br><br><a rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/50710267?utm_id=0" target="_blank">https://zhuanlan.zhihu.com/p/50710267?utm_id=0</a><br>è¾“å…¥æ ·æœ¬é‡å‚æ•°]]></description><link>ideas\index.html</link><guid isPermaLink="false">Ideas/index.md</guid><pubDate>Wed, 23 Oct 2024 13:27:51 GMT</pubDate><enclosure url="lib\media\pasted-image-20241023205939.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241023205939.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-08-23]]></title><description><![CDATA[ 
 <br>
<br>é‡æ–°çœ‹äº†ä¸€é diffusion-ss3d
<br>æµè§ˆç±»å¢é‡ç›®æ ‡æ£€æµ‹è®ºæ–‡ï¼Œ<a data-href="Learning task-aware language-image representation for class-incremental object detection" href="paper-reading-notes\learning-task-aware-language-image-representation-for-class-incremental-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Learning task-aware language-image representation for class-incremental object detection</a>ï¼Œæåˆ°â€œcross-modality learning paradigm has shown strong zero-shot and few-shot transfer ability to object detectionâ€ï¼Œæ€è€ƒæ˜¯å¦èƒ½å°†æ–‡æœ¬å¤šæ¨¡æ€ä¿¡æ¯ç”¨äº3dç›®æ ‡æ£€æµ‹çš„åŠç›‘ç£å­¦ä¹ ã€‚
<br>æœç´¢æ˜¯å¦æœ‰ç›¸å…³çš„æ–‡æœ¬-è§†è§‰çš„3dç›®æ ‡æ£€æµ‹å™¨ï¼Œå‘ç°ä¸€ä¸ªæ–°é¢†åŸŸ<a data-href="Open Vocabulary Learning" href="research-notes\open-vocabulary-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Open Vocabulary Learning</a>ï¼Œä¼¼ä¹ä¸åŠç›‘ç£å­¦ä¹ çš„æ€æƒ³æœ‰ç›¸é€šä¹‹å¤„ï¼Œæ˜å¤©è®¡åˆ’çœ‹ä¸€ä¸‹è¯¥é¢†åŸŸçš„ç»¼è¿°<a data-href="Towards open vocabulary learning_ A survey" href="paper-reading-notes\towards-open-vocabulary-learning_-a-survey.html" class="internal-link" target="_self" rel="noopener nofollow">Towards open vocabulary learning_ A survey</a>,ä»¥åŠ3dç›®æ ‡æ£€æµ‹çš„è®ºæ–‡
]]></description><link>logs\2024-08-23.html</link><guid isPermaLink="false">Logs/2024-08-23.md</guid><pubDate>Tue, 27 Aug 2024 12:34:37 GMT</pubDate></item><item><title><![CDATA[2024-08-24]]></title><description><![CDATA[ 
 <br>
<br>çœ‹äº†ç»¼è¿°<a data-href="Towards open vocabulary learning_ A survey" href="paper-reading-notes\towards-open-vocabulary-learning_-a-survey.html" class="internal-link" target="_self" rel="noopener nofollow">Towards open vocabulary learning_ A survey</a>èƒŒæ™¯å’Œé—®é¢˜å®šä¹‰ã€‚visual-language model åœ¨è·¨åŸŸä¸Šæœ‰ä¼˜åŠ¿
<br>éœ€è¦ç ”ç©¶ä¸€ä¸‹CLIPçš„åŸç†
<br>æ˜¯å¦å¯ä»¥ä½¿ç”¨3D Novel Object Discovery (3D-NOD)çš„æ–¹æ³•æ¥å¢å¼ºåŠç›‘ç£3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ä¼ªæ ‡ç­¾çš„ç”Ÿæˆè´¨é‡ï¼Ÿ
<br><a data-href="CoDA_ Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3D object detection" href="paper-reading-notes\coda_-collaborative-novel-box-discovery-and-cross-modal-alignment-for-open-vocabulary-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">CoDA_ Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3D object detection</a>çœ‹åˆ°Methodéƒ¨åˆ†
]]></description><link>logs\2024-08-24.html</link><guid isPermaLink="false">Logs/2024-08-24.md</guid><pubDate>Sat, 24 Aug 2024 08:54:51 GMT</pubDate></item><item><title><![CDATA[2024-08-25]]></title><description><![CDATA[ 
 <br>
<br>ç ”ç©¶ç»“åˆæ–‡æœ¬ç‰¹å¾æ˜¯å¦èƒ½æå‡ä¼ªæ ‡ç­¾çš„ç”Ÿæˆè´¨é‡ï¼ŒGLIPå°†ç›®æ ‡æ£€æµ‹ä»»åŠ¡å’Œæ–‡æœ¬çš„groudingä»»åŠ¡ç»“åˆèµ·æ¥ï¼Œç”¨deepfusionç»“åˆæ–‡æœ¬ç‰¹å¾å’Œå›¾åƒç‰¹å¾ï¼Œåœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬è¿ç§»ä¸Šè¡¨ç°è¾ƒå¥½ã€‚å¦ä¸€ç¯‡å…³äºç›®æ ‡æ£€æµ‹çš„ç±»å¢é‡å­¦ä¹ <a data-href="Learning task-aware language-image representation for class-incremental object detection" href="paper-reading-notes\learning-task-aware-language-image-representation-for-class-incremental-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Learning task-aware language-image representation for class-incremental object detection</a>çš„è®ºæ–‡ï¼Œä¹Ÿä½¿ç”¨äº†GLIPæ–¹æ³•æ¥æé«˜åœ¨æ–°çš„taskä¸Šçš„è¿ç§»èƒ½åŠ›ã€‚å› æ­¤æˆ‘è§‰å¾—æ–‡æœ¬ä¿¡æ¯çš„å¼•å…¥å¯ä»¥æé«˜ç›®æ ‡æ£€æµ‹çš„æ•ˆæœã€‚å¦‚æœå‚è€ƒè¿™æ ·çš„æ€è·¯ï¼Œå°†æ–‡æœ¬ä¿¡æ¯å¼•å…¥åŠç›‘ç£3Dç›®æ ‡æ£€æµ‹ä¸­ï¼Œæ¥æé«˜ä¼ªæ ‡ç­¾çš„ç”Ÿæˆè´¨é‡ï¼Œæé«˜å¬å›ç‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¼ºåŒ–æ¨¡å‹åœ¨è·¨åŸŸæ•°æ®é›†ä¸Šçš„è¡¨æ•ˆæœã€‚é—®é¢˜åœ¨äºï¼Œå¦‚ä½•å°†GLIPè¿™ç§ç”¨äº2Dç›®æ ‡æ£€æµ‹çš„é¢„è®­ç»ƒæ¨¡å‹æˆ–è€…å…¶ä»–çš„å¤šæ¨¡æ€ç»“åˆçš„æ–¹å¼ç”¨äº3Dç‚¹äº‘ã€‚ä¸€ç§æ–¹å¼æ˜¯ä»3Dç‚¹äº‘ä¸­æŠ•å½±å¾—åˆ°2Dçš„å›¾åƒï¼Œç„¶åä½¿ç”¨é¢„è®­ç»ƒçš„GLIPæ¥ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œçº¦æŸteacheræ¨¡å‹ç”Ÿæˆçš„3Dä¼ªæ ‡ç­¾ï¼Œä½†è¿™æ ·æœ¬è´¨å°±æ˜¯ç®€å•åœ°ä½¿ç”¨2Dçš„ç›®æ ‡æ£€æµ‹æ¥çº¦æŸteacherç”Ÿæˆçš„ä¼ªæ ‡ç­¾ã€‚å¦ä¸€ç§æ–¹å¼æ˜¯å°†æ–‡æœ¬ç‰¹å¾åµŒå…¥åˆ°æ¨¡å‹ä¸­ï¼Œä½†éœ€è¦è€ƒè™‘å¦‚ä½•å»å¯¹é½ä¸¤ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚äº†è§£åˆ°ä¸€äº›å¯èƒ½ç›¸å…³çš„å…³é”®è¯ï¼šcontrastive learningï¼Œdeep fusion
<br>äº†è§£contrastive learningçš„æ–¹æ³•
<br>çœ‹ä¸€ä¸‹SS2Då’ŒSS3Dçš„æ‰€æœ‰è®ºæ–‡ä½¿ç”¨çš„æ–¹æ³•
<br>å¯ä»¥ä½¿ç”¨GLIPä¸»ä½“å¾—åˆ°çš„fusionç‰¹å¾
<br>èƒ½å¦å€Ÿé‰´å¼±ç›‘ç£çš„æ–¹æ³•æ¥æ ¹æ®boxçš„centeræ¥é¢„æµ‹rotationï¼Ÿ
]]></description><link>logs\2024-08-25.html</link><guid isPermaLink="false">Logs/2024-08-25.md</guid><pubDate>Sun, 25 Aug 2024 14:43:38 GMT</pubDate></item><item><title><![CDATA[2024-08-26]]></title><description><![CDATA[ 
 <br>
<br>è·¨åŸŸé€‚åº”æ–‡ç« è°ƒç ”
<br>å›¾ç¥ç»ç½‘ç»œæ„å»ºæ•°æ®åˆ†å¸ƒï¼ˆæƒ³æ³•
<br>æ„å›¾ï¼ŒLLM
<br>ä¸åŒclassç‚¹äº‘æ‹¼æ¥ï¼Œé¢„æµ‹è¾¹ç•Œclass
]]></description><link>logs\2024-08-26.html</link><guid isPermaLink="false">Logs/2024-08-26.md</guid><pubDate>Mon, 26 Aug 2024 02:54:28 GMT</pubDate></item><item><title><![CDATA[2024-08-27]]></title><description><![CDATA[ 
 <br>
<br>çœ‹äº†SSODçš„2022å¹´åŠä»¥å‰çš„è®ºæ–‡ï¼Œçœ‹åˆ° <a data-href="Semi-supervised object detection via multi-instance alignment with global class prototypes" href="paper-reading-notes\semi-supervised-object-detection-via-multi-instance-alignment-with-global-class-prototypes.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised object detection via multi-instance alignment with global class prototypes</a> è¿™ç¯‡
<br>å¯ä»¥ç ”ç©¶çš„ç‚¹ï¼šlabel noise overfitting problemã€scale inconsistencyã€class imbalance
<br>å¯èƒ½ç»“åˆçš„é¢†åŸŸï¼šè‡ªè’¸é¦ã€ä¸»åŠ¨å­¦ä¹ ã€åŸŸè‡ªé€‚åº”
]]></description><link>logs\2024-08-27.html</link><guid isPermaLink="false">Logs/2024-08-27.md</guid><pubDate>Tue, 27 Aug 2024 12:33:04 GMT</pubDate></item><item><title><![CDATA[2024-08-30]]></title><description><![CDATA[ 
 <br>
<br>å°†3DIoUMatchä¸­ sunrgbdæ•°æ®ä»£ç ç§»æ¤åˆ°äº†Diffusion-ss3dä¸­ï¼Œä¿®æ”¹detectå’Œssæ•°æ®é›†ç±»çš„ä»£ç ï¼Œå¢åŠ äº†ç›¸åº”çš„æ•°æ®ï¼Œåœ¨sunrgbä¸Šè·‘èµ·äº†pretrainä»£ç 
<br>çœ‹äº†<a data-href="DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection" href="paper-reading-notes\dqs3d_-densely-matched-quantization-aware-semi-supervised-3d-detection.html" class="internal-link" target="_self" rel="noopener nofollow">DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection</a>ï¼Œä¸»è¦åˆ›æ–°ç‚¹æ˜¯å°†æ¯”è¾ƒæ–°çš„å…¨å·ç§¯çš„æ£€æµ‹backboneåŠ å…¥ï¼Œæ˜¾è‘—æå‡ä¼ªæ ‡ç­¾çš„ç”Ÿæˆè´¨é‡ã€‚
]]></description><link>logs\2024-08-30.html</link><guid isPermaLink="false">Logs/2024-08-30.md</guid><pubDate>Fri, 30 Aug 2024 13:28:02 GMT</pubDate></item><item><title><![CDATA[2024-08-31]]></title><description><![CDATA[ 
 <br>
<br>ideaï¼Œå°†studentæˆ–teacherçš„é¢„è®­ç»ƒå’Œè®­ç»ƒè¿‡ç¨‹çœ‹ä½œæ˜¯å¢é‡å­¦ä¹ ï¼Ÿ
<br>æ‰“ç®—follow<a data-href="DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection" href="paper-reading-notes\dqs3d_-densely-matched-quantization-aware-semi-supervised-3d-detection.html" class="internal-link" target="_self" rel="noopener nofollow">DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection</a>è¿™ç¯‡ï¼Œè§£å†³å…¶ä¸­çš„voxel sizeçµæ•ä»¥åŠscale variance é—®é¢˜ã€‚ç›´æ¥å‡å°voxel sizeä¼šå¯¼è‡´è®¡ç®—é‡å€å¢ï¼Œå› æ­¤éœ€è¦æŸç§æ–¹å¼æ¥å‡å°æ•´ä¸ªåœºæ™¯çš„å¤§å°ï¼Œåœ¨å°åœºæ™¯ä¸­åšå…¨å·ç§¯ä¼šå¥½å¾ˆå¤šã€‚æ”¹å˜åœºæ™¯å¤§å°ï¼Œå‡å°voxel sizeï¼Œæœ¬è´¨ä¸Šå°±æ˜¯æ”¹å˜å±€éƒ¨ç‚¹äº‘çš„ç¨ å¯†ç¨‹åº¦ï¼Œä¼¼ä¹å¯ä»¥åŒæ—¶å»å¢å¼ºå°ºåº¦ä¸Šçš„é—®é¢˜ã€‚
<br>éœ€è¦è®¾è®¡ä¸€ä¸ªå®éªŒæ¥ç ”ç©¶ç‚¹äº‘åˆ†è¾¨ç‡ï¼ˆå°ºåº¦ï¼‰å˜åŒ–å¯¹3Dç›®æ ‡æ£€æµ‹çš„ç½®ä¿¡åº¦çš„å½±å“ã€‚åˆæ­¥æƒ³æ³•æ˜¯å¯¹åæ ‡x0.5ä»¥åŠx2æ¥æ”¹å˜ç‚¹äº‘çš„åˆ†è¾¨ç‡
]]></description><link>logs\2024-08-31.html</link><guid isPermaLink="false">Logs/2024-08-31.md</guid><pubDate>Sat, 31 Aug 2024 14:16:31 GMT</pubDate></item><item><title><![CDATA[2024-09-02]]></title><description><![CDATA[ 
 <br>
<br>è®ºæ–‡é˜…è¯» pointpillarsï¼Œæ€è·¯æœ‰ç›¸ä¼¼<a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1812.05784" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1812.05784" target="_blank">[1812.05784] PointPillars: Fast Encoders for Object Detection from Point Clouds (arxiv.org)</a>
<br>ä¸»åŠ¨å­¦ä¹ +åŠç›‘ç£å­¦ä¹ 
]]></description><link>logs\2024-09-02.html</link><guid isPermaLink="false">Logs/2024-09-02.md</guid><pubDate>Mon, 02 Sep 2024 14:20:21 GMT</pubDate></item><item><title><![CDATA[2024-09-03]]></title><description><![CDATA[ 
 <br>
<br>çœ‹3DIoUMatchä»£ç 
<br>ç²¾è¯»<a data-href="Active teacher for semi-supervised object detection" href="paper-reading-notes\active-teacher-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Active teacher for semi-supervised object detection</a>
]]></description><link>logs\2024-09-03.html</link><guid isPermaLink="false">Logs/2024-09-03.md</guid><pubDate>Tue, 03 Sep 2024 00:14:57 GMT</pubDate></item><item><title><![CDATA[2024-09-04]]></title><description><![CDATA[ 
 <br>
<br>æ—©ä¸Šäº†è§£Active Learningé¢†åŸŸ
<br>DQS3Dä»£ç ç¯å¢ƒ
]]></description><link>logs\2024-09-04.html</link><guid isPermaLink="false">Logs/2024-09-04.md</guid><pubDate>Wed, 04 Sep 2024 14:17:57 GMT</pubDate></item><item><title><![CDATA[2024-09-05]]></title><description><![CDATA[ 
 <br>
<br>active teacher è¢«å¼•æ–‡çŒ®
]]></description><link>logs\2024-09-05.html</link><guid isPermaLink="false">Logs/2024-09-05.md</guid><pubDate>Thu, 05 Sep 2024 09:24:01 GMT</pubDate></item><item><title><![CDATA[2024-09-10]]></title><description><![CDATA[ 
 <br>
<br>æ˜å¤©çœ‹è¿™ä¸€ç¯‡<a data-tooltip-position="top" aria-label="https://arxiv.org/pdf/2305.10643" rel="noopener nofollow" class="external-link" href="https://arxiv.org/pdf/2305.10643" target="_blank">2305.10643 (arxiv.org)</a>ï¼Œstreaming based active learning
<br>online active learning ç»¼è¿°<a data-tooltip-position="top" aria-label="https://www.semanticscholar.org/reader/10a7f6463a6abe3e4723576a9c0ba03c1339cfbb" rel="noopener nofollow" class="external-link" href="https://www.semanticscholar.org/reader/10a7f6463a6abe3e4723576a9c0ba03c1339cfbb" target="_blank">[PDF] Active learning for data streams: a survey | Semantic Scholar</a>
]]></description><link>logs\2024-09-10.html</link><guid isPermaLink="false">Logs/2024-09-10.md</guid><pubDate>Tue, 10 Sep 2024 14:11:12 GMT</pubDate></item><item><title><![CDATA[2024-09-13]]></title><description><![CDATA[ 
 <br>
<br>2dç›®æ ‡æ£€æµ‹å’Œ3dç›®æ ‡æ£€æµ‹çš„åŒºåˆ«ï¼š2dä¸­å¯èƒ½ä¸€å¼ å›¾ç‰‡åªæœ‰ä¸€ä¸ªç›®æ ‡ï¼Œè€Œ3dçš„æ•°æ®æ˜¯ä¸€ä¸ªåœºæ™¯ï¼Œæ€»æ˜¯åŒ…å«å¤šä¸ªç›®æ ‡
<br>ä¸»åŠ¨å­¦ä¹ åœ¨é‡é‡‡æ ·
]]></description><link>logs\2024-09-13.html</link><guid isPermaLink="false">Logs/2024-09-13.md</guid><pubDate>Fri, 13 Sep 2024 13:27:39 GMT</pubDate></item><item><title><![CDATA[2024-09-14]]></title><description><![CDATA[ 
 <br>
<br>çœ‹äº†é‡é‡‡æ ·çš„æ€è·¯ã€‚æ˜å¤©å†™å®éªŒä»£ç ã€‚åˆ†åˆ«åœ¨é¢„è®­ç»ƒå’ŒåŠç›‘ç£è¿‡ç¨‹ä¸­åŠ å…¥é‡é‡‡æ ·ç­–ç•¥ã€‚é‡é‡‡æ ·çš„æ¯”ä¾‹é€šè¿‡ä¸»åŠ¨å­¦ä¹ çš„æŒ‡æ ‡è®¡ç®—åæ’åºå¾—åˆ°ã€‚é‡é‡‡æ ·çš„æ¯”ä¾‹é—´éš”nä¸ªepoché‡æ–°è®¡ç®—ã€‚è‡ªå®šä¹‰ä¸€ä¸ªDataloaderï¼ŒåŒ…å«ä¸€ä¸ªè‡ªå®šä¹‰çš„Samplerç±»ï¼Œæä¾›ä¸€ä¸ªupdate_weights()æ–¹æ³•ï¼Œæ¯æ¬¡train_one_epoch()åï¼Œæ›´æ–°æƒé‡ã€‚
]]></description><link>logs\2024-09-14.html</link><guid isPermaLink="false">Logs/2024-09-14.md</guid><pubDate>Sat, 14 Sep 2024 14:37:20 GMT</pubDate></item><item><title><![CDATA[2024-09-18]]></title><description><![CDATA[ 
 <br>
<br>é¢„è®­ç»ƒè¿‡ç¨‹é‡é‡‡æ ·
<br>æ ¹æ®æ ·æœ¬çš„ALåˆ†æ•°è°ƒæ•´ä¼ªæ ‡ç­¾é˜ˆå€¼
]]></description><link>logs\2024-09-18.html</link><guid isPermaLink="false">Logs/2024-09-18.md</guid><pubDate>Wed, 18 Sep 2024 13:08:57 GMT</pubDate></item><item><title><![CDATA[2024-09-19]]></title><description><![CDATA[ 
 <br>
<br>åœ¨æ¯ä¸ªè®­ç»ƒé˜¶æ®µï¼ŒåŒæ—¶ç”¨åŸå§‹æ•°æ®å’Œé‡é‡‡æ ·æ•°æ®è®­ç»ƒï¼Œè¯„ä¼°ä¹‹åï¼Œé€‰æ‹©æ€§èƒ½æ›´å¥½çš„æ¨¡å‹ï¼Œå¹¶è®°å½•ã€‚ç ”ç©¶æ˜¯å¦åœ¨æŸä¸ªç‰¹å®šé˜¶æ®µé‡é‡‡æ ·ç­–ç•¥æœ‰æ•ˆ
]]></description><link>logs\2024-09-19.html</link><guid isPermaLink="false">Logs/2024-09-19.md</guid><pubDate>Thu, 19 Sep 2024 10:45:06 GMT</pubDate></item><item><title><![CDATA[2024-09-26]]></title><description><![CDATA[ 
 <br>
<br>3DIoUMatchå’ŒDiffusionSS3Dåœ¨è®­ç»ƒååŠé˜¶æ®µï¼ˆepoch&gt;500ï¼‰classåˆ†ç±»ä¼šå‡ºç°è¿‡æ‹Ÿåˆç°è±¡ï¼Œè¡¨ç°ä¸ºeval_cls_accä¸Šå‡ã€‚
<br>ä¿®æ”¹äº†ä¹‹å‰ä»£ç ä¸­çš„é”™è¯¯ï¼šæƒé‡å½’ä¸€åŒ–ä»£ç å†™åœ¨äº†å¾ªç¯é‡Œé¢ï¼Œå¯¼è‡´å¯¹æ¯ä¸ªbatchçš„æ ·æœ¬åšäº†å½’ä¸€åŒ–ä½†æ˜¯æ²¡æœ‰å¯¹å…¨éƒ¨çš„æ ·æœ¬åšå½’ä¸€åŒ–ï¼Œå·²ä¿®æ”¹ï¼Œé‡è·‘å®éªŒ
<br>infomationçš„æŒ‡æ ‡è®¡ç®—åšäº†ä¿®æ”¹ï¼Œç°åœ¨åªè®¡ç®—é«˜äºcls_thresholdçš„ç½®ä¿¡åº¦ï¼Œå› ä¸ºåœ¨ä¼ªæ ‡ç­¾ç­›é€‰è¿‡ç¨‹ä¸­ï¼Œä½äºcls_thresholdçš„æ ·æœ¬éƒ½ä¼šè¢«ç­›å‡ºã€‚ä¿®æ”¹åæŒ‡æ ‡åæ˜ æ ·æœ¬ä¸­å½“ä½œä¼ªæ ‡ç­¾çš„proposalçš„ä¿¡æ¯é‡
<br>æŒ‡æ ‡çš„åˆ†æ•°åªä½¿ç”¨maxå½’ä¸€åŒ–ä½œä¸ºæƒé‡ï¼Œä¼šå¯¼è‡´æƒé‡è¿‡äºåˆ†æ•£ï¼ˆ0.4~1.0ï¼‰ï¼Œå› æ­¤åŠ äº†éçº¿æ€§æ»¤æ³¢æ¥äººä¸ºæ§åˆ¶æƒé‡çš„åˆ†æ•£ç¨‹åº¦
]]></description><link>logs\2024-09-26.html</link><guid isPermaLink="false">Logs/2024-09-26.md</guid><pubDate>Thu, 26 Sep 2024 02:32:20 GMT</pubDate></item><item><title><![CDATA[2024-10-16]]></title><description><![CDATA[ 
 <br>
<br>åœ¨ä¸åŒçš„æ•°æ®é›†æ¯”ä¾‹ä¸Šæµ‹è¯•äº†resampleç­–ç•¥çš„æ•ˆæœï¼Œæ•ˆæœç•¥æœ‰æå‡ä½†è¶…å‚æ•°éœ€è¦è°ƒä¼˜ã€‚
<br><img alt="Pasted image 20241016215813.png" src="lib\media\pasted-image-20241016215813.png"><br>
<br>å°è¯•åˆ©ç”¨ä¸»åŠ¨å­¦ä¹ æŒ‡æ ‡åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼Œæ²¡æœ‰æ•ˆæœã€‚<br>
<img alt="Pasted image 20241016221548.png" src="lib\media\pasted-image-20241016221548.png">
<br>é‡æ–°æ€è€ƒï¼Œå°è¯• æ··åˆæ•°æ®å¢å¼ºç­–ç•¥ç»“åˆä¸»åŠ¨å­¦ä¹ ï¼Œè®¡åˆ’å°è¯•ä¸¤ç§å¢å¼ºæ–¹å¼ï¼š

<br>å¯¹æœªæ ‡æ³¨åœºæ™¯è®¡ç®—diffæŒ‡æ ‡ï¼Œè‹¥åœºæ™¯å°äºdiffé˜ˆå€¼ï¼Œåº”ç”¨æ··åˆå¢å¼ºï¼Œå°†æœ‰æ ‡æ³¨å®ä¾‹ç²˜è´´åˆ°è¯¥æœªæ ‡æ³¨åœºæ™¯ä¸­ï¼›
<br>å°†ä¼ªæ ‡ç­¾å®ä¾‹ç²˜è´´åˆ°æœ‰æ ‡ç­¾åœºæ™¯ä¸­ï¼ˆéœ€è¦è§£å†³ä¼ªæ ‡ç­¾bboxå®šä½ä¸ç²¾ç¡®é—®é¢˜ï¼‰


<br>ç¼–å†™æ··åˆå¢å¼ºç­–ç•¥å®éªŒä»£ç ï¼Œè®¡åˆ’

<br>å®ä¾‹databaseï¼šæ ¹æ®bboxæå–ç›¸å…³ç‚¹äº‘ï¼ŒåŠ å…¥åˆ°database
<br>æ–¹å¼ä¸€å®ç°ï¼šåœ¨datasetç±»getitemæ–¹æ³•ä¸­ï¼Œdata augmentä¹‹å‰ï¼Œåº”ç”¨æ··åˆæ•°æ®å¢å¼º
<br>æ–¹å¼äºŒå®ç°
<br>å…¶ä»–ï¼šåœºæ™¯å¯è§†åŒ–openpcdetæ¥å£è°ƒç”¨


<br><br>
<br>å®ç°äº†bboxæå–ç›¸å…³ç‚¹äº‘
<br><img alt="Pasted image 20241016222242.png" src="lib\media\pasted-image-20241016222242.png">]]></description><link>logs\2024-10-16.html</link><guid isPermaLink="false">Logs/2024-10-16.md</guid><pubDate>Wed, 16 Oct 2024 14:22:47 GMT</pubDate><enclosure url="lib\media\pasted-image-20241016215813.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241016215813.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-17]]></title><description><![CDATA[ 
 <br>
<br>å®ç°æ–¹å¼ä¸€ç­–ç•¥ä»£ç ï¼šåœ¨datasetç±»getitemæ–¹æ³•ä¸­ï¼Œdata augmentä¹‹å‰ï¼Œåº”ç”¨æ··åˆæ•°æ®å¢å¼º
<br>original  &lt;-- | --&gt; noisy<br><img alt="Pasted image 20241017163934.png" src="lib\media\pasted-image-20241017163934.png"><br><img alt="Pasted image 20241017164006.png" src="lib\media\pasted-image-20241017164006.png"><br><img alt="Pasted image 20241017164030.png" src="lib\media\pasted-image-20241017164030.png"><br>
<br>åœ¨scannet 5%ä¸Šæµ‹è¯•ï¼šnohup ./my_sh/exp_mix_resample_scan_3.sh &gt; LOG.log 2&gt;&amp;1 &amp; scannet_0.05, gamma=0.15, mix_thresh=mean_diff, dir=exp_mix_resample
]]></description><link>logs\2024-10-17.html</link><guid isPermaLink="false">Logs/2024-10-17.md</guid><pubDate>Thu, 17 Oct 2024 09:15:20 GMT</pubDate><enclosure url="lib\media\pasted-image-20241017163934.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241017163934.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-18]]></title><description><![CDATA[ 
 <br>
<br>æ•´ç†æœ¬åœ°ä»£ç ï¼Œæ–¹ä¾¿è¿ç§»åˆ°å¤šä¸ªç¯å¢ƒä¸­åŒæ—¶è·‘
<br>æ–¹å¼ä¸€ç­–ç•¥ä»£ç sunrgbdå®ç°
<br> todo: <br>
<br>sunrgbdä»£ç é€‚é…
<br>ä»£ç è¿ç§»æœåŠ¡å™¨
]]></description><link>logs\2024-10-18.html</link><guid isPermaLink="false">Logs/2024-10-18.md</guid><pubDate>Fri, 18 Oct 2024 13:30:28 GMT</pubDate></item><item><title><![CDATA[2024-10-21]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹ï¼š<br>
<br>æ•´ç†æ··åˆæ•°æ®å¢å¼ºideaæ€è·¯ï¼Œæ’°å†™æ–‡æ¡£ã€‚
<br>å®Œæˆäº†æ•°æ®å¢å¼ºç­–ç•¥çš„åŸºç¡€ä»£ç ï¼Œè°ƒè¯•é€šè¿‡ã€‚
<br>åœ¨scannet 10%ä¸Šè¿è¡Œæ··åˆæ•°æ®å¢å¼ºå¯¹æ¯”è¯•éªŒï¼ˆground truth instance -&gt; unlabeled sceneï¼Œéšæœºä½ç½®ï¼‰ï¼Œé¢„è®¡å‰©ä½™48h
<br>è§£å†³äº†åº”ç”¨æ•°æ®å¢å¼ºç­–ç•¥åï¼Œåœ¨sunrgbdä¸Šè®­ç»ƒevalç»“æœå¼‚å¸¸é—®é¢˜ã€‚
<br>åœ¨sunrgbd 5%ä¸Šè¿è¡Œå¯¹æ¯”è¯•éªŒï¼ŒåŒä¸Š
<br>å·¥ä½œè¿›å±•ï¼š<br>é‡åˆ°çš„é—®é¢˜ï¼š<br>
<br>æ··åˆæ•°æ®å¢å¼ºç­–ç•¥è®­ç»ƒæ—¶é—´å¼‚å¸¸ï¼šscannet 10% baselineçº¦6hï¼Œæµ‹è¯•è®­ç»ƒæ—¶é—´&gt;24h
<br>è§£å†³æ–¹æ¡ˆä¸è®¡åˆ’ï¼š<br>
<br>å¯èƒ½ä¸ä¸€å¼ å¡åŒæ—¶è·‘ä¸¤ä¸ªè®­ç»ƒæœ‰å…³ï¼Œæ¢å¡é‡è¯•ä¸€ä¸‹ï¼›ç›‘æµ‹ä»£ç æ¯ä¸ªæ¨¡å—çš„è¿è¡Œæ—¶é—´ï¼Œçœ‹æ˜¯å¦æœ‰å¼‚å¸¸è€—æ—¶ã€‚
<br>æ˜æ—¥è®¡åˆ’ï¼š<br>
<br>ç¼–å†™collision testæ¨¡å—ä»£ç 
<br>è§£å†³è®­ç»ƒæ—¶é—´å¼‚å¸¸é—®é¢˜
<br>é˜…è¯»ç›¸å…³è®ºæ–‡<a data-href="De-biased teacher_ Rethinking iou matching for semi-supervised object detection" href="paper-reading-notes\de-biased-teacher_-rethinking-iou-matching-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">De-biased teacher_ Rethinking iou matching for semi-supervised object detection</a>
]]></description><link>logs\2024-10-21.html</link><guid isPermaLink="false">Logs/2024-10-21.md</guid><pubDate>Mon, 21 Oct 2024 14:52:13 GMT</pubDate></item><item><title><![CDATA[2024-10-22]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹ï¼š<br>
<br>æ˜¨å¤©åœ¨ä¸¤å¼ å¡åŒæ—¶è®­ç»ƒscannet 10%ï¼ŒCUDA OOMäº†ï¼Œç­‰å¾…å¦ä¸€ä¸ªè®­ç»ƒç»“æŸåç»§ç»­ã€‚
<br>å®Œæˆcollision testæ¨¡å—ä»£ç ã€‚
<br>ä¿®æ”¹mixå®ä¾‹ä½ç½®çš„é€‰æ‹©ï¼šä¸ä»…éœ€è¦é¿å…ç¢°æ’ï¼Œè¿˜éœ€è¦é¿å…é€‰æ‹©çš„ä½ç½®å’Œå…¶ä»–ç‰©ä½“è·ç¦»è¿‡è¿œã€‚
<br>å®Œæˆä¸Šè¿°åŠŸèƒ½ï¼Œæ‰©å……äº†collision testæ¨¡å—ï¼Œç¡®ä¿æ–°çš„ä½ç½®åœ¨åŸå§‹ç‚¹äº‘é™„è¿‘ï¼Œåœ¨scannet 10%ä¸Šè®­ç»ƒæµ‹è¯•ã€‚
<br>è°ƒè¯•äº†è®­ç»ƒæ—¶é—´å¼‚å¸¸çš„é—®é¢˜ï¼Œç¡®è®¤æ˜¯å•å¡å¤šè®­ç»ƒçš„åŸå› ã€‚
<br>é‡åˆ°çš„é—®é¢˜ï¼š<br>
<br>ä½¿ç”¨ground truth instance mixå¢å¼ºä¹‹åçš„unlabelled sceneæ•°æ®ï¼Œæ˜¯åªè¾“å…¥ç»™studentæ¨¡å‹ï¼Œæˆ–æ˜¯åŒæ—¶è¾“å…¥ç»™studentå’Œteacheræ¨¡å‹ï¼Œæˆ–è€…å°†ground truthå’Œteacheræ¨¡å‹ç”Ÿæˆçš„ä¼ªæ ‡ç­¾åˆå¹¶ç”¨äºç›‘ç£studentçš„ç»“æœï¼Ÿæˆ‘è§‰å¾—ä¸‰ç§æ–¹å¼éƒ½æœ‰é“ç†ï¼Œæœ€åä¸€ç§ç›¸æ¯”æ›´ä¸ºåˆç†ä¸€ç‚¹ï¼Œä½†æ˜¯å¢åŠ çš„ä»£ç ä¼šå¤æ‚å¾ˆå¤šã€‚ç›®å‰ä½¿ç”¨ç¬¬ä¸€ç§æ–¹å¼å…ˆçœ‹æ•ˆæœã€‚
<br>æ˜æ—¥è®¡åˆ’ï¼š<br>
<br>å¼€å§‹å†™pseudo instance â€”&gt; labeled sceneç­–ç•¥çš„ä»£ç ï¼Œäº‰å–åœ¨ç°åœ¨çš„å®éªŒè·‘å®Œä¹‹å‰ï¼Œèƒ½å¤Ÿå°†è¿™ä¸ªç­–ç•¥çš„è®­ç»ƒå®éªŒè·‘èµ·æ¥ã€‚
]]></description><link>logs\2024-10-22.html</link><guid isPermaLink="false">Logs/2024-10-22.md</guid><pubDate>Tue, 22 Oct 2024 15:27:28 GMT</pubDate></item><item><title><![CDATA[2024-10-24]]></title><description><![CDATA[ 
 <br>å·¥ä½œè¿›å±•ï¼š<br>
<br>21å·è·‘çš„å®éªŒ(ground truth instance -&gt; unlabeled scene)ï¼Œæ•ˆæœè¿˜ä¸é”™ï¼Œåœ¨scannet10%å’Œsunrgbd5%ä¸Šéƒ½æœ‰æå‡
<br><img alt="Pasted image 20241024171824.png" src="lib\media\pasted-image-20241024171824.png"><br>é‡åˆ°çš„é—®é¢˜ï¼š<br>
<br>æƒ³è¿™ä¸ªç­–ç•¥åŠ¨æœºçš„æ—¶å€™ï¼Œå‘ç°é—æ¼çš„ä¸€ç¯‡AAAI 24çš„è®ºæ–‡â€œDual-Perspective Knowledge Enrichment for Semi-Supervised 3D Object Detectionâ€ï¼ŒåŒæ ·ä¹Ÿæ˜¯åšå®¤å†…çš„ï¼Œå¹¶ä¸”æŒ‡æ ‡è¶…è¿‡äº†Diffusion-SS3Dï¼Œåœ¨Githubä¸Šæ‰¾åˆ°äº†å¼€æºçš„ä»£ç ã€‚èƒ½ç”¨è¿™ç¯‡è®ºæ–‡åšbaselineå—ï¼Ÿ
]]></description><link>logs\2024-10-24.html</link><guid isPermaLink="false">Logs/2024-10-24.md</guid><pubDate>Thu, 24 Oct 2024 13:45:58 GMT</pubDate><enclosure url="lib\media\pasted-image-20241024171824.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241024171824.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-26]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹ï¼š<br>
<br>å®Œæˆ pseudo instance â€”&gt; labeled sceneç­–ç•¥çš„ä»£ç ï¼ŒåŒ…æ‹¬æ›¿æ¢å’Œç²˜è´´ã€‚
<br>é‡åˆ°çš„é—®é¢˜ï¼š<br>
<br>å‘ç°æ¨¡å‹åœ¨è®­ç»ƒåˆæœŸï¼Œç­›é€‰è¿‡çš„pseudo instanceï¼Œbounding boxçš„å®šä½ä»éå¸¸ä¸å‡†ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œå³ä½¿ä½¿ç”¨å¤šä¸ªproposalçš„å¹¶é›†ä¹Ÿæ— æ³•ä¿è¯å¾—åˆ°å®Œæ•´çš„ç‰©ä½“ã€‚éœ€è¦è¿›ä¸€æ­¥åˆ†æä¸€ä¸‹iou scoreå’Œconfidenceçš„è¾“å‡ºï¼Œè°ƒæ•´ä¸Šé¢çš„ç­–ç•¥ã€‚
<br><img alt="Pasted image 20241026214940.png" src="lib\media\pasted-image-20241026214940.png">]]></description><link>logs\2024-10-26.html</link><guid isPermaLink="false">Logs/2024-10-26.md</guid><pubDate>Sat, 26 Oct 2024 13:49:53 GMT</pubDate><enclosure url="lib\media\pasted-image-20241026214940.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241026214940.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-29]]></title><description><![CDATA[ 
 <br>
<br>è¯¦ç»†çœ‹ä¸€ä¸‹fixmatch
]]></description><link>logs\2024-10-29.html</link><guid isPermaLink="false">Logs/2024-10-29.md</guid><pubDate>Tue, 29 Oct 2024 14:53:16 GMT</pubDate></item><item><title><![CDATA[2024-10-30]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹ï¼š<br>
<br>å®Œæˆmixup ä¸‰ç§ç­–ç•¥çš„ä»£ç ï¼ŒåŒæ—¶åœ¨ä¸‰å¼ å¡ä¸Šå¯¹scannet 10%æ•°æ®é›†å®éªŒï¼Œé¢„è®¡31å·ä¸­åˆçœ‹åˆ°ç»“æœ
<br>å®éªŒè®°å½•ï¼š<br>mixup ç­–ç•¥1<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup_1/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>mixup ç­–ç•¥2<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup_2/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_2_scan_1.sh
<br>mixup ç­–ç•¥3<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup_3/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_3_scan_1.sh
]]></description><link>logs\2024-10-30.html</link><guid isPermaLink="false">Logs/2024-10-30.md</guid><pubDate>Wed, 30 Oct 2024 16:36:02 GMT</pubDate></item><item><title><![CDATA[2024-10-31]]></title><description><![CDATA[ 
 <br>æ˜¨å¤©çš„ä»£ç æœ‰é”™è¯¯ï¼Œæ··åˆç‚¹äº‘çš„æ—¶å€™æ²¡æœ‰å¯¹é½centeråæ ‡ï¼›åŠ å…¥å¯†åº¦ã€ç‚¹äº‘æ•°é‡è¿›ä¸€æ­¥ç­›é€‰éœ€è¦mixupçš„ä¼ªæ ‡ç­¾<br>è®°å¾—gitæäº¤ä»£ç ]]></description><link>logs\2024-10-31.html</link><guid isPermaLink="false">Logs/2024-10-31.md</guid><pubDate>Thu, 31 Oct 2024 16:36:52 GMT</pubDate></item><item><title><![CDATA[2024-11-01]]></title><description><![CDATA[ 
 <br>åŒ¹é…æ–¹å¼ï¼šæŒ‰ç…§é•¿å®½é«˜åŒ¹é…ï¼›å‡è®¾1sté•¿åº¦ä¸ºé•¿ï¼›2ndé•¿åº¦ä¸ºå®½ï¼›3rdé•¿åº¦ä¸ºé«˜ï¼Œä¸¤ä¸ªproposalå°±å¯ä»¥ç”¨é•¿å®½é«˜åŒ¹é…å’Œresize<br>
ç¬¬ä¸€ç§ï¼šä»dataå–ä¸€ä¸ªæ¤…å­ï¼Œæ›¿æ¢æ‰è€å¸ˆproposalä¸­çš„æ¤…å­ï¼ŒåŸæ¥çš„ç‚¹å»é™¤<br>ç¬¬äºŒç§ï¼šmixupï¼Œdataé‡Œçš„æ¤…å­ä¸teacherå¾—åˆ°çš„æ¤…å­åšmixupï¼Œä¾‹å¦‚æ¤…å­1çš„é‡‡æ ·ç‡ä¸ºA%ï¼Œé‚£ä¹ˆæ¤…å­2å°±æ˜¯100-A%<br>
ç¬¬ä¸‰ç§ï¼šmixupï¼Œdataé‡Œçš„æ¡Œå­ä¸teacherå¾—åˆ°çš„æ¤…å­åšmixupï¼Œæ¤…å­æ˜¯A%ï¼Œæ¡Œå­æ˜¯100-A%ï¼ˆA&gt;&gt;50%ï¼‰<br>11-01-3ï¼šä¸ä¿æŒæ€»æ•°é‡ä¸å˜ï¼Œè€Œæ˜¯gt A% + pseudo (1-A)% &gt;=N ï¼Œç„¶ååœ¨æ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘é‡é‡‡æ ·åˆ°40000ï¼Œä¸å¸¦å¯†åº¦ç­›é€‰æ¨¡å—]]></description><link>logs\2024-11-01.html</link><guid isPermaLink="false">Logs/2024-11-01.md</guid><pubDate>Fri, 01 Nov 2024 14:01:09 GMT</pubDate></item><item><title><![CDATA[2024-11-04]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹ï¼š<br>
<br>æ’°å†™è®ºæ–‡ï¼Œå®Œæˆäº†è®ºæ–‡methodéƒ¨åˆ†
<br>ç»˜åˆ¶äº†æ¨¡å‹æ¡†æ¶è‰å›¾
<br><img alt="Pasted image 20241104194929.png" src="lib\media\pasted-image-20241104194929.png"><br>
<br>ç›®å‰çš„æ•ˆæœæ²¡æœ‰è¶…è¿‡sotaï¼Œæ‰“ç®—åœ¨diffusion-ss3dä¸Šå®ç°ç°åœ¨çš„æ–¹æ³•ã€‚diffusion-ss3d æ²¡æœ‰æä¾› sunrgbdæ•°æ®é›†ä»£ç ï¼Œä¹‹å‰æ²¡æœ‰å¤ç°æˆã€‚é‡æ–°è¡¥å……äº†sunrgbdéƒ¨åˆ†çš„ä»£ç ï¼Œå¤ç°1%æ•°æ®é›†ï¼Œç›®å‰è®­ç»ƒæŒ‡æ ‡çœ‹èµ·æ¥æ­£å¸¸ã€‚
<br>å·¥ä½œè¿›å±•ï¼š<br>
<br>ä¸‰ç§ç­–ç•¥åœ¨scannetä¸Šæ•ˆæœæ¯”å•ç‹¬ä½¿ç”¨ä¸€ç§ç­–ç•¥éƒ½æœ‰æå‡ã€‚
<br><img alt="Pasted image 20241104194220.png" src="lib\media\pasted-image-20241104194220.png"><br>
<br>åœ¨scannetä¸Šå®Œæˆäº† å¼ºå¢å¼ºçš„ä¼ªæ ‡ç­¾æ¯”ä¾‹(ä¹‹å‰è®¾å®šçš„æ˜¯50%) çš„çµæ•åº¦åˆ†æå®éªŒ
<br><img alt="Pasted image 20241104194629.png" src="lib\media\pasted-image-20241104194629.png"><br>
<br>å¼€å§‹å†™è®ºæ–‡ï¼Œå®Œæˆäº†è®ºæ–‡methodéƒ¨åˆ†ç¬¬ä¸€ç‰ˆ
<br>é‡åˆ°çš„é—®é¢˜ï¼š<br>
<br>ä¸‰ç§ç­–ç•¥çš„æ¶ˆèæœ‰äº›å¥‡æ€ªï¼Œä¸¤ç§ç­–ç•¥ä¸€èµ·æ¯”ä¸€ç§ç­–ç•¥å•ç‹¬è¦å·®ï¼Œå¯èƒ½æ˜¯æœ‰åå·®ï¼Œåé¢æœ‰æ—¶é—´å¤šè·‘å‡ æ¬¡
<br>åœ¨æœåŠ¡å™¨ä¸Šçš„gpuä¸Šè®­ç»ƒæ—¶ï¼Œsunrgbdæ•°æ®é›†çš„è®­ç»ƒå¼‚å¸¸æ…¢ï¼Œæ’æŸ¥ä¸å‡ºåŸå› ï¼Œç›®å‰çœ‹èµ·æ¥æ˜¯å¶ç„¶ç°è±¡ï¼Œå¸Œæœ›åé¢çš„å®éªŒå°‘å‡ºé—®é¢˜ã€‚
<br>ç²—ç•¥è®¡ç®—äº†ä¸‹ç›®å‰å‰©ä¸‹çš„å®éªŒï¼Œå‰©ä¸‹çš„æ¶ˆèå®éªŒåŠ ä¸Šdiffusion-ss3d baseline é¢„è®¡æœ€å°‘éœ€è¦6.5å¤©+ï¼Œå¦‚æœåŠ ä¸Š3dioumatch baseline çš„ç»“æœï¼Œæœ€å°‘éœ€è¦8.7å¤©+ï¼Œdiffusion-ss3dè®­ç»ƒæ—¶é—´ä¸å¤ªç¡®å®šï¼Œsunrgbdæ•°æ®é›†ä¸Šè®­ç»ƒæ—¶é—´å¯èƒ½å‡ºç°å¼‚å¸¸ï¼Œè¿˜éœ€è¦é¢„ç•™æ—¶é—´ç»™ç»“æœä¸å¥½çš„å®éªŒé‡è·‘ã€‚ç®—ä¸‹æ¥æ—¶é—´æ¯”è¾ƒæé™ã€‚
<br>åç»­è®¡åˆ’ï¼š<br>
<br>ç»§ç»­åœ¨sunrgbdä¸Šè·‘ å¼ºå¢å¼ºçš„ä¼ªæ ‡ç­¾æ¯”ä¾‹(ä¹‹å‰è®¾å®šçš„æ˜¯50%) çš„çµæ•åº¦åˆ†æå®éªŒ
<br>diffusion-ss3d sunrgbdæ•°æ®é›†ä¸Šå¤ç°æ²¡é—®é¢˜åï¼Œç§»æ¤ç°åœ¨çš„æ–¹æ³•åˆ°diffusion-ss3dä¸Š
<br>è®ºæ–‡éœ€è¦æ··åˆå¢å¼ºçš„æ•ˆæœå¯è§†åŒ–ï¼Œéœ€è¦è·‘é€šOpenPCDetçš„å¯è§†åŒ–ä»£ç 
]]></description><link>logs\2024-11-04.html</link><guid isPermaLink="false">Logs/2024-11-04.md</guid><pubDate>Mon, 04 Nov 2024 12:05:13 GMT</pubDate><enclosure url="lib\media\pasted-image-20241104194929.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241104194929.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-11-12]]></title><description><![CDATA[ 
 <br>
<br>åŒä¸€ä¸ªåœºæ™¯çš„ä¸åŒæ‰«æï¼Œæ¨¡å‹çš„æ¨ç†è¡¨ç°å·®å¼‚å¾ˆå¤§ã€‚å³ä½¿æ˜¯åšè¿‡å¢å¼ºï¼Œä¾æ—§ä¼šæœ‰è¾ƒå¤§æ€§èƒ½å·®å¼‚ï¼Œ ä¸é²æ£’
<br>åŠç›‘ç£äººå·¥æ ‡æ³¨é—æ¼/é”™è¯¯é—®é¢˜
]]></description><link>logs\2024-11-12.html</link><guid isPermaLink="false">Logs/2024-11-12.md</guid><pubDate>Tue, 12 Nov 2024 12:11:36 GMT</pubDate></item><item><title><![CDATA[2024-11-13]]></title><description><![CDATA[ 
 <br>æ¥ä¸‹æ¥ï¼Œæˆ‘ä¼šç»™ä½ éƒ¨åˆ†å®Œæˆçš„è®ºæ–‡introductionéƒ¨åˆ†ï¼Œä»¥åŠåç»­çš„è®ºæ–‡æ€è·¯ï¼Œä½ éœ€è¦å®Œæˆintroductionåé¢æœªå®Œæˆçš„æ®µè½ã€‚The goal of 3D object detection is to identify category labels of objects and locate 3D boundary boxes from a point cloud scen, playing a crucial role in applications in autonomous driving and robotics[].<br>
Recent works~\cite{liu2021group, qi2019deep, rukhovich2022fcaf3d, shi2023pv, shi2019pointrcnn, shi2020points,  wang2022cagroup3d, yang20203dssd, zhou2018voxelnet, chen2023voxelnext, wang2022sparse2dense, yin2021center, fan2022fully} have made significant progress in 3D object detection. However, obtaining a large amount of carefully annotated 3D scene data is very expensive and time-consuming.<br>To overcome the limitation, semi-supervised learning (SSL) methods leverage a combination of few labeled data and a large amount of unlabeled data to enhance training and improve model performance. Prior works~\cite{zhao2020sess, wang20213dioumatch, ho2023diffusion, wang2023not} [sess, 3dioumatch, diffusion-ss3d, not-every-side-is-equal, DPKE] adopt a student-teacher framework with asymmetric data augmentation to train the student model through pseudo-labeling and consistency regularization. For instance, SESS~\cite{zhao2020sess} ... 3DIoUMatch~\cite{wang20213dioumatch} ... NESE~\cite{wang2023not} ...  Diffusion-SS3D~\cite{ho2023diffusion} ... Specifically, One of the critical keys to the well-performed semi-supervised learning is the strong augmentation strategy. Strong augmentation aids in robust feature learning by exposing the model to a wide range of transformations, which enhances its ability to detect objects under various real-world conditions. Additionally, it prevents overfitting by introducing variability into the training process, ensuring that the model generalizes better to novel, unseen data. Specifically, these approaches focused on scene-level augmentation strategies, such as flipping, rotation, and scaling. However, only utilize scene-level augmentation can suffer from limited diversity. This is because applying uniform transformations to entire scenes does not significantly alter individual objects within the scene, leading to less variability at the object level. As a result, the model may not experience a wide range of object poses or appearances, limiting its ability to learn robust, object-specific features necessary for accurate detection under varied conditions.  <br>To ... we propose...<br>Additionally, ... we propose ... augmentation constraints...<br>Our contribution.... ï¼›<br>åé¢æ®µè½æ€è·¯ï¼šDPKEåœ¨data augmentationä¸Šåšå‡ºäº†æ”¹è¿›ï¼Œæå‡ºäº†åŒè§†è§’çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä½†ä»æ—§æ˜¯åŸºäºç›®å‰åœ¨3Dç›®æ ‡æ£€æµ‹ä¸­ä½¿ç”¨çš„scene-levelçš„å¢å¼ºæ–¹æ³•ã€‚å—åˆ°åœ¨3D classificationä»»åŠ¡ä¸­PointMixup [31], RSMix [32], and SageMix [36].çš„å¯å‘ï¼Œæˆ‘ä»¬åˆ©ç”¨åŠç›‘ç£å­¦ä¹ æ¡†æ¶student-teacher frameworkç‹¬ç‰¹çš„ç»“æ„ç‰¹æ€§,å……åˆ†åˆ©ç”¨teacher modelå¾—åˆ°çš„ä¼ªæ ‡ç­¾ï¼Œæå‡ºäº†é€‚ç”¨äºåŠç›‘ç£ä¸‹çš„instance-level augmentation methods. æˆ‘ä»¬æå‡ºäº†ä¸‰ç§instance-level çš„å¢å¼ºç­–ç•¥æ¥æ‰©å……æ•°æ®çš„å¤šæ ·æ€§ï¼ŒåŒæ—¶åŠ å¼ºæ¨¡å‹å¯¹ç›®æ ‡çš„è¯­ä¹‰åˆ†ç±»èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œç¬¬ä¸€ç§æ–¹å¼æ˜¯ same class replacement, ä½¿ç”¨ç›¸åŒçš„ç±»çš„çœŸå®objectæ›¿æ¢æœªæ ‡æ³¨åœºæ™¯ä¸­çš„ç‰©ä½“ï¼Œæ¥ä¸°å¯Œè¯¥ç±»ç‰©ä½“çš„æ•°æ®è¡¨ç¤ºã€‚ç¬¬äºŒç§æ–¹å¼æ˜¯ same class mixup, ä½¿ç”¨ç›¸åŒçš„ç±»çš„çœŸå®objectçš„ç‚¹äº‘ä¸æœªæ ‡æ³¨åœºæ™¯ç‚¹äº‘æ··åˆï¼Œä»è€ŒåŠ å¼ºæ¨¡å‹å¯¹åŒç±»ç‰©ä½“å½¢çŠ¶çš„é²æ£’æ€§ï¼›ç¬¬ä¸‰ç§æ–¹å¼æ˜¯different class mixupï¼Œä½¿ç”¨ä¸åŒçš„ç±»çš„çœŸå®objectç‚¹äº‘æ··å…¥åˆ°æœªæ ‡æ³¨ç‰©ä½“ä¸­ï¼Œä»è€ŒåŠ å¼ºæ¨¡å‹çš„è¯­ä¹‰åˆ†ç±»èƒ½åŠ›ã€‚<br>å¦å¤–ï¼Œä¸ºäº†ä¿è¯å¢å¼ºçš„æ•°æ®çš„è¯­ä¹‰ä¿¡æ¯ç¨³å®šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§constraints methodæ¥çº¦æŸinstance-levelæ•°æ®å¢å¼ºã€‚The first constraint ensures that the augmented in-<br>
stances maintain a certain level of physically realism by<br>
aligning the shape and orientation of the objects. The sec<br>
ond constraint focuses on maintaining instance characteris<br>
tics by controlling the number of points after mixup oper<br>
ation. By enforcing these constraints, the model is guided<br>
to learn from augmented samples that contribute positively<br>
to training, improving robustness and generalization in 3D<br>
object detection. ]]></description><link>logs\2024-11-13.html</link><guid isPermaLink="false">Logs/2024-11-13.md</guid><pubDate>Wed, 13 Nov 2024 02:30:31 GMT</pubDate></item><item><title><![CDATA[2024-11-14]]></title><description><![CDATA[ 
 ]]></description><link>logs\2024-11-14.html</link><guid isPermaLink="false">Logs/2024-11-14.md</guid><pubDate>Thu, 14 Nov 2024 09:06:26 GMT</pubDate></item><item><title><![CDATA[2024-11-26]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹<br>
<br>é˜…è¯»SSL theoryç›¸å…³è®ºæ–‡ï¼Œä»98å¹´å¼€å§‹ï¼Œçœ‹äº† <a data-href="Combining labeled and unlabeled data with co-training" href="paper-reading-notes\combining-labeled-and-unlabeled-data-with-co-training.html" class="internal-link" target="_self" rel="noopener nofollow">Combining labeled and unlabeled data with co-training</a>ï¼Œ <a data-href="Learning from labeled and unlabeled data with label propagation" href="paper-reading-notes\learning-from-labeled-and-unlabeled-data-with-label-propagation.html" class="internal-link" target="_self" rel="noopener nofollow">Learning from labeled and unlabeled data with label propagation</a>ï¼Œ  <a data-href="Semi-supervised learning using gaussian fields and harmonic functions" href="paper-reading-notes\semi-supervised-learning-using-gaussian-fields-and-harmonic-functions.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning using gaussian fields and harmonic functions</a>ï¼Œ <a data-href="Semi-supervised learning by entropy minimization" href="paper-reading-notes\semi-supervised-learning-by-entropy-minimization.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning by entropy minimization</a>ï¼Œ <a data-href="A co-regularization approach to semi-supervised learning with multiple views" href="paper-reading-notes\a-co-regularization-approach-to-semi-supervised-learning-with-multiple-views.html" class="internal-link" target="_self" rel="noopener nofollow">A co-regularization approach to semi-supervised learning with multiple views</a>ï¼Œ<a data-href="Generalization error bounds in semi-supervised classiï¬cation under the cluster assumption" href="paper-reading-notes\generalization-error-bounds-in-semi-supervised-classiï¬cation-under-the-cluster-assumption.html" class="internal-link" target="_self" rel="noopener nofollow">Generalization error bounds in semi-supervised classiï¬cation under the cluster assumption</a>
<br>ideaï¼Œèƒ½å¦å°†teacherç”Ÿæˆä¼ªæ ‡ç­¾çš„è¿‡ç¨‹çœ‹ä½œæ˜¯å¼‚å¸¸å€¼æ£€æµ‹ï¼Œç„¶åç”¨å¼‚å¸¸å€¼æ£€æµ‹çš„æ–¹æ³•æ¥æ›¿ä»£teacherä¼ªæ ‡ç­¾æ¨¡å—
<br>æ˜æ—¥è®¡åˆ’<br>
<br>ç»§ç»­é˜…è¯»SSL theory
<br>æ¢³ç†å¼‚å¸¸å€¼æ£€æµ‹é¢†åŸŸçš„ç ”ç©¶è„‰ç»œ
<br>æ•´ç†autodlä¸Šçš„æ•°æ®ä»£ç 
<br>diffusionçš„å¤ç°ç»§ç»­ï¼ˆå¦‚æœæœ‰æ¡ä»¶ï¼‰
]]></description><link>logs\2024-11-26.html</link><guid isPermaLink="false">Logs/2024-11-26.md</guid><pubDate>Tue, 26 Nov 2024 14:02:37 GMT</pubDate></item><item><title><![CDATA[2024-11-27]]></title><description><![CDATA[ 
 <br>å·¥ä½œå†…å®¹<br>
<br>å°†autodlä¸Šçš„è®­ç»ƒresultsä¸‹è½½åˆ°äº†æœ¬åœ°
<br>çœ‹äº†youtubeçš„deep semi-supervised å…¬å¼€è¯¾ï¼Œ<a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=PXOhi6m09bA" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/watch?v=PXOhi6m09bA" target="_blank">L9 Semi-Supervised Learning and Unsupervised Distribution Alignment -- CS294-158-SP20 UC Berkeley</a> ç†æ¸…åŠç›‘ç£å‘å±•è„‰ç»œ
<br>SESSåº”è¯¥æ˜¯3DåŠç›‘ç£ç›®æ ‡æ£€æµ‹çš„å¼€å±±ä¹‹ä½œï¼ŒSESS follow äº† <a data-tooltip-position="top" aria-label="Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results" data-href="Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results" href="paper-reading-notes\mean-teachers-are-better-role-models_-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html" class="internal-link" target="_self" rel="noopener nofollow">mean-teacher</a> è¿™ç¯‡å·¥ä½œã€‚SESSé‡‡ç”¨é¦–å…ˆåœ¨æœ‰ç›‘ç£æ ·æœ¬ä¸Šé¢„è®­ç»ƒçš„æ–¹å¼ï¼Œè€Œ mean-teacher æ²¡æœ‰ï¼Œè®ºæ–‡ä¸­æ²¡æœ‰è§£é‡Šè¿™æ ·åšçš„åŸå› ï¼Œåé¢çš„å·¥ä½œä¹Ÿéƒ½ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒç­–ç•¥ã€‚<a data-href="Not every side is equal_ Localization uncertainty estimation for semi-supervised 3D object detection" href="paper-reading-notes\not-every-side-is-equal_-localization-uncertainty-estimation-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Not every side is equal_ Localization uncertainty estimation for semi-supervised 3D object detection</a> é¢„è®­ç»ƒå’Œè®­ç»ƒçš„è½®æ•°æ›´å°‘360ï¼Œåœ¨è¡¥å……ææ–™ä¸­æåˆ°ã€‚
<br>æ˜æ—¥è®¡åˆ’<br>
<br>å†è¯¦ç»†çœ‹ä¸€ä¸‹<a data-href="Self-training with Noisy Student improves ImageNet classification" href="paper-reading-notes\self-training-with-noisy-student-improves-imagenet-classification.html" class="internal-link" target="_self" rel="noopener nofollow">Self-training with Noisy Student improves ImageNet classification</a> è¿™ç¯‡æ–‡ç« 
<br>å¤ç°SESSä»£ç ï¼Œçœ‹æ˜¯å¦æœ‰é¢„è®­ç»ƒå½±å“
]]></description><link>logs\2024-11-27.html</link><guid isPermaLink="false">Logs/2024-11-27.md</guid><pubDate>Wed, 27 Nov 2024 13:50:53 GMT</pubDate></item><item><title><![CDATA[2024-12-02]]></title><description><![CDATA[ 
 <br>
<br>å‘¨æŠ¥åˆ†äº«é“¾æ¥
<br>æ¢è½´ä½“
<br>æš‘ç ”é™¶ç“·
]]></description><link>logs\2024-12-02.html</link><guid isPermaLink="false">Logs/2024-12-02.md</guid><pubDate>Mon, 02 Dec 2024 05:46:57 GMT</pubDate></item><item><title><![CDATA[3D gaussian splatting for real-time radiance field rendering]]></title><description><![CDATA[ 
 <br>è®ºæ–‡ä»£ç ï¼š<br>
<a rel="noopener nofollow" class="external-link" href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/</a><br>
First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space;
<br>
Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; 
<br>
Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. \
<br><br>ä¸‰ä¸ªéƒ¨åˆ†ï¼š3D Gaussiansã€optimization of the properties of the 3D Gaussiansã€real-time rendering solution<br>è®ºæ–‡ä¸»è¦è´¡çŒ®ï¼š<br>

<br>The introduction of anisotropic 3D Gaussians as a high-quality, unstructured representation of radiance fields. 
<br>An optimization method of 3D Gaussian properties, interleaved with adaptive density control that creates high-quality representations for captured scenes. 
<br>A fast, differentiable rendering approach for the GPU, which is visibility-aware, allows anisotropic splatting and fast backpropagation to achieve high-quality novel view synthesis.

<br><br><br>è¾“å…¥æ˜¯é™æ€åœºæ™¯çš„ä¸€ç»„å›¾åƒï¼Œå’Œsfmé‡å»ºå¾—åˆ°çš„ç³»æ•°ç‚¹äº‘ã€‚<br>
The input to our method is a set of images of a static scene, together with the corresponding cameras calibrated by SfM which produces a sparse point cloud as a sideeffect.
<br>ä»ç¨€ç–ç‚¹äº‘ä¸­åˆ›å»ºä¸€ç»„3D Gaussiansï¼Œå‚æ•°åŒ…å«ï¼ˆå¹³å‡ä½ç½®åæ ‡ã€åæ–¹å·®çŸ©é˜µã€å¯†åº¦ï¼‰<br>
From these points we create a set of 3D Gaussians (Sec. 4), defined by a position (mean), covariance matrix and opacity ğ›¼, that allows a very flexible optimization regime. This results in a reasonably compact representation of the 3D scene, in part because highly anisotropic(å„å‘å¼‚æ€§) volumetric splats can be used to represent fine structures compactly.
<br>ä½¿ç”¨çƒè°å‡½æ•°æ¥è¡¨ç¤ºé¢œè‰²ï¼Œä½¿ç”¨è¾å°„åœºè¡¨ç¤ºå…‰<br>
The directional appearance component (color) of the radiance field is represented via spherical harmonics (SH), following standard practice.
<br>anisotropicï¼ˆå„å‘å¼‚æ€§ï¼‰ï¼šè¿™ä¸ªè¯è¡¨ç¤ºåœ¨ä¸åŒæ–¹å‘ä¸Šå…·æœ‰ä¸åŒçš„ç‰¹æ€§ã€‚åœ¨å›¾å½¢å­¦ä¸­ï¼Œå„å‘å¼‚æ€§é€šå¸¸æŒ‡çº¹ç†æˆ–å…‰ç…§åœ¨ä¸åŒæ–¹å‘ä¸Šè¡¨ç°å‡ºçš„ä¸åŒæ•ˆæœã€‚ä¸å„å‘åŒæ€§ï¼ˆå„ä¸ªæ–¹å‘ä¸Šç‰¹æ€§ç›¸åŒï¼‰ç›¸å¯¹ã€‚<br>spherical harmonics(SH): çƒè°å‡½æ•°<br>Tile-based rendererï¼ˆåŸºäºå—çš„æ¸²æŸ“å™¨ï¼‰<br><img alt="Pasted image 20240620235810.png" src="lib\media\pasted-image-20240620235810.png"><br><br>ä½¿ç”¨3Dåæ–¹å·®çŸ©é˜µå®šä¹‰Gaussians, å…¶ä¸­<br><img alt="Pasted image 20240621132209.png" src="lib\media\pasted-image-20240621132209.png"><br><br><img alt="Pasted image 20240621001519.png" src="lib\media\pasted-image-20240621001519.png"><br>
<br>é›…å¯æ¯”çŸ©é˜µ
<br>]]></description><link>paper-reading-notes\3d-gaussian-splatting-for-real-time-radiance-field-rendering.html</link><guid isPermaLink="false">Paper reading notes/3D gaussian splatting for real-time radiance field rendering.md</guid><pubDate>Fri, 21 Jun 2024 05:48:00 GMT</pubDate><enclosure url="lib\media\pasted-image-20240620235810.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240620235810.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3DIoUMatch Leveraging IoU prediction for semi-supervised 3D object detection]]></title><description><![CDATA[ 
 <br>ä½¿ç”¨å¸¦IoU estimationæ¨¡å—çš„åŸºäºconfidence-based filteringçš„æ–¹æ³•æ¥åŠ å¼ºä¼ªæ ‡ç­¾è´¨é‡]]></description><link>paper-reading-notes\3dioumatch_-leveraging-iou-prediction-for-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/3DIoUMatch_ Leveraging IoU prediction for semi-supervised 3D object detection.md</guid><pubDate>Fri, 23 Aug 2024 12:21:37 GMT</pubDate></item><item><title><![CDATA[A co-regularization approach to semi-supervised learning with multiple views]]></title><description><![CDATA[ 
 <br>æå‡ºä¸€ç§co-regularization æ–¹æ³•æ¥åˆ©ç”¨ä¸¤ä¸ªview<br><img alt="Pasted image 20241126211456.png" src="lib\media\pasted-image-20241126211456.png">]]></description><link>paper-reading-notes\a-co-regularization-approach-to-semi-supervised-learning-with-multiple-views.html</link><guid isPermaLink="false">Paper reading notes/A co-regularization approach to semi-supervised learning with multiple views.md</guid><pubDate>Tue, 26 Nov 2024 13:15:44 GMT</pubDate><enclosure url="lib\media\pasted-image-20241126211456.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241126211456.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[A simple vision transformer for weakly semi-supervised 3D object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\a-simple-vision-transformer-for-weakly-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/A simple vision transformer for weakly semi-supervised 3D object detection.md</guid><pubDate>Mon, 26 Aug 2024 00:58:37 GMT</pubDate></item><item><title><![CDATA[A-teacher Asymmetric network for 3D semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\a-teacher_-asymmetric-network-for-3d-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/A-teacher_ Asymmetric network for 3D semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 00:44:13 GMT</pubDate></item><item><title><![CDATA[Active learning for deep object detection via probabilistic modeling]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\active-learning-for-deep-object-detection-via-probabilistic-modeling.html</link><guid isPermaLink="false">Paper reading notes/Active learning for deep object detection via probabilistic modeling.md</guid><pubDate>Tue, 10 Sep 2024 05:22:58 GMT</pubDate></item><item><title><![CDATA[Active learning strategies for weakly-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\active-learning-strategies-for-weakly-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Active learning strategies for weakly-supervised object detection.md</guid><pubDate>Tue, 10 Sep 2024 05:39:09 GMT</pubDate></item><item><title><![CDATA[Active teacher for semi-supervised object detection]]></title><description><![CDATA[ 
 <br>
<br>data initialization
<br>iterative version: the label set is partially initialized and gradually augmented by three factors of unlabeled examples

<br>difficulty
<br>information
<br>diversity


<br>ç”±äºbatchä¸­åŒ…å«äº†labeledå’Œunlabelledæ•°æ®ï¼Œground truthçš„ä¿¡æ¯å¯¹ä¼ªæ ‡ç­¾çš„ç”Ÿæˆè´¨é‡èµ·å…³é”®ä½œç”¨ï¼Œå› æ­¤å¦‚ä½•é€‰æ‹©åˆé€‚çš„æœ‰æ ‡æ³¨æ•°æ®å’Œæœªæ ‡æ³¨æ•°æ®çš„ç»„åˆä»¥åŠæ•°æ®å¢å¼ºæ–¹æ³•å°¤ä¸ºé‡è¦
]]></description><link>paper-reading-notes\active-teacher-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Active teacher for semi-supervised object detection.md</guid><pubDate>Wed, 11 Sep 2024 04:03:41 GMT</pubDate></item><item><title><![CDATA[Advanced active learning strategies for object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\advanced-active-learning-strategies-for-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Advanced active learning strategies for object detection.md</guid><pubDate>Tue, 10 Sep 2024 08:06:12 GMT</pubDate></item><item><title><![CDATA[Alleviating catastrophic forgetting of incremental object detection via within-class and between-class knowledge distillation]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\alleviating-catastrophic-forgetting-of-incremental-object-detection-via-within-class-and-between-class-knowledge-distillation.html</link><guid isPermaLink="false">Paper reading notes/Alleviating catastrophic forgetting of incremental object detection via within-class and between-class knowledge distillation.md</guid><pubDate>Fri, 16 Aug 2024 14:08:25 GMT</pubDate></item><item><title><![CDATA[ALWOD Active learning for weakly-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\alwod_-active-learning-for-weakly-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/ALWOD_ Active learning for weakly-supervised object detection.md</guid><pubDate>Tue, 10 Sep 2024 05:09:29 GMT</pubDate></item><item><title><![CDATA[Ambiguity-resistant semi-supervised learning for dense object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\ambiguity-resistant-semi-supervised-learning-for-dense-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Ambiguity-resistant semi-supervised learning for dense object detection.md</guid><pubDate>Mon, 26 Aug 2024 01:51:09 GMT</pubDate></item><item><title><![CDATA[Augmented box replay Overcoming foreground shift for incremental object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\augmented-box-replay_-overcoming-foreground-shift-for-incremental-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Augmented box replay_ Overcoming foreground shift for incremental object detection.md</guid><pubDate>Fri, 16 Aug 2024 14:08:45 GMT</pubDate></item><item><title><![CDATA[BAOD_ Budget-aware object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\baod_-budget-aware-object-detection.html</link><guid isPermaLink="false">Paper reading notes/BAOD_ Budget-aware object detection.md</guid><pubDate>Tue, 10 Sep 2024 05:37:55 GMT</pubDate></item><item><title><![CDATA[Box-level active detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\box-level-active-detection.html</link><guid isPermaLink="false">Paper reading notes/Box-level active detection.md</guid><pubDate>Tue, 10 Sep 2024 06:33:14 GMT</pubDate></item><item><title><![CDATA[Bridging non co-occurrence with unlabeled in-the-wild data for incremental object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\bridging-non-co-occurrence-with-unlabeled-in-the-wild-data-for-incremental-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Bridging non co-occurrence with unlabeled in-the-wild data for incremental object detection.md</guid><pubDate>Fri, 16 Aug 2024 13:39:31 GMT</pubDate></item><item><title><![CDATA[CoDA Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3D object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\coda_-collaborative-novel-box-discovery-and-cross-modal-alignment-for-open-vocabulary-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/CoDA_ Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3D object detection.md</guid><pubDate>Sat, 24 Aug 2024 07:31:44 GMT</pubDate></item><item><title><![CDATA[Combining labeled and unlabeled data with co-training]]></title><description><![CDATA[ 
 <br>proposed a co-training strategy that trains two models simultaneously using two randomly selected labeled data. then enlarge labeled dataset from unlabeled dataset with positive and negative samples each iteration.<br>æå‡ºä¸€ç§co-trainingç­–ç•¥ï¼ŒåŒæ—¶è®­ç»ƒä¸¤ä¸ªclassifier(h1, h2)ï¼Œä½¿ç”¨ä¸åŒçš„è®­ç»ƒæ•°æ®(x1, x2)ï¼Œç„¶åä»Uä¸­æŒ‘é€‰åˆ†æœ€é«˜çš„positiveå’Œnegativeæ ·æœ¬åŠ å…¥åˆ°Lä¸­ï¼Œç„¶åè¡¥å……Uä¸­çš„æ ·æœ¬æ•°é‡ã€‚<br><img alt="Pasted image 20241126191220.png" src="lib\media\pasted-image-20241126191220.png">]]></description><link>paper-reading-notes\combining-labeled-and-unlabeled-data-with-co-training.html</link><guid isPermaLink="false">Paper reading notes/Combining labeled and unlabeled data with co-training.md</guid><pubDate>Tue, 26 Nov 2024 12:06:35 GMT</pubDate><enclosure url="lib\media\pasted-image-20241126191220.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241126191220.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Consistent-teacher Towards reducing inconsistent pseudo-targets in semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\consistent-teacher_-towards-reducing-inconsistent-pseudo-targets-in-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Consistent-teacher_ Towards reducing inconsistent pseudo-targets in semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 02:56:18 GMT</pubDate></item><item><title><![CDATA[Continual detection transformer for incremental object detection]]></title><description><![CDATA[ 
 <br>code not yet<br>transformer-based detectors]]></description><link>paper-reading-notes\continual-detection-transformer-for-incremental-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Continual detection transformer for incremental object detection.md</guid><pubDate>Fri, 23 Aug 2024 07:30:31 GMT</pubDate></item><item><title><![CDATA[Correlation field for boosting 3D object detection in structured scenes]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\correlation-field-for-boosting-3d-object-detection-in-structured-scenes.html</link><guid isPermaLink="false">Paper reading notes/Correlation field for boosting 3D object detection in structured scenes.md</guid><pubDate>Sun, 20 Oct 2024 15:29:27 GMT</pubDate></item><item><title><![CDATA[Data-uncertainty guided multi-phase learning for semi-supervised object detection]]></title><description><![CDATA[ 
 <br>è§£å†³ label noise overvittingé—®é¢˜ï¼šdifficult labelä¼šäº§ç”Ÿæ›´å¤šçš„å™ªå£°ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹æ€»æ˜¯ä¼šå€¾å‘äºæ‹Ÿåˆdifficultçš„labelè€Œå¿½ç•¥easy labelï¼Œä»è€Œå¯¼è‡´åœ¨è®­ç»ƒé˜¶æ®µï¼Œdifficultçš„mAPä¸Šå‡åè€Œeasyçš„mAPä¸‹é™ã€‚<br>æå‡ºäº†easy labels å’Œdifficult labelsçš„å¤šé˜¶æ®µè®­ç»ƒï¼Œä½¿ç”¨å¤šä¸ªæ¨¡å‹åˆ†åˆ«è®­ç»ƒeasyå’Œdifficult labelï¼Œä½¿åœ¨å„è‡ªçš„labeléƒ½æœ‰è¾ƒå¥½çš„ç½®ä¿¡åº¦ï¼Œç»“åˆæ‰€æœ‰è®­ç»ƒçš„æ¨¡å‹å…±åŒé¢„æµ‹ç»“æœ<br>ä½¿ç”¨å¤šä¸ªæ¨¡å‹é¢„æµ‹çš„ä¼ªæ ‡ç­¾çš„äº¤é›†æ¥ç”Ÿæˆä¼ªæ ‡ç­¾]]></description><link>paper-reading-notes\data-uncertainty-guided-multi-phase-learning-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Data-uncertainty guided multi-phase learning for semi-supervised object detection.md</guid><pubDate>Tue, 27 Aug 2024 06:38:47 GMT</pubDate></item><item><title><![CDATA[De-biased teacher Rethinking iou matching for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\de-biased-teacher_-rethinking-iou-matching-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/De-biased teacher_ Rethinking iou matching for semi-supervised object detection.md</guid><pubDate>Mon, 21 Oct 2024 14:08:23 GMT</pubDate></item><item><title><![CDATA[Deep active learning for efficient training of a LiDAR 3D object detector]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\deep-active-learning-for-efficient-training-of-a-lidar-3d-object-detector.html</link><guid isPermaLink="false">Paper reading notes/Deep active learning for efficient training of a LiDAR 3D object detector.md</guid><pubDate>Tue, 10 Sep 2024 08:03:33 GMT</pubDate></item><item><title><![CDATA[Deep hough voting for 3D object detection in point clouds]]></title><description><![CDATA[ 
 <br>3Dç›®æ ‡æ£€æµ‹å™¨ï¼ˆå®¤å†…ï¼‰<br><a data-href="PV-RCNN_ Point-voxel feature set abstraction for 3D object detection" href="paper-reading-notes\pv-rcnn_-point-voxel-feature-set-abstraction-for-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">PV-RCNN_ Point-voxel feature set abstraction for 3D object detection</a>]]></description><link>paper-reading-notes\deep-hough-voting-for-3d-object-detection-in-point-clouds.html</link><guid isPermaLink="false">Paper reading notes/Deep hough voting for 3D object detection in point clouds.md</guid><pubDate>Thu, 15 Aug 2024 14:32:24 GMT</pubDate></item><item><title><![CDATA[Dense learning based semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\dense-learning-based-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Dense learning based semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 02:32:43 GMT</pubDate></item><item><title><![CDATA[DetMatch Two teachers are better than one for joint 2D and 3D semi-supervised object detection]]></title><description><![CDATA[ 
 <br>å¤šè§†è§’]]></description><link>paper-reading-notes\detmatch_-two-teachers-are-better-than-one-for-joint-2d-and-3d-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/DetMatch_ Two teachers are better than one for joint 2D and 3D semi-supervised object detection.md</guid><pubDate>Fri, 23 Aug 2024 12:22:48 GMT</pubDate></item><item><title><![CDATA[Diffusion-ss3d Diffusion model for semi-supervised 3D object detection]]></title><description><![CDATA[ 
 <br>ä½¿ç”¨PointNet++ä½œencoderï¼Œ<a data-tooltip-position="top" aria-label="Deep hough voting for 3D object detection in point clouds" data-href="Deep hough voting for 3D object detection in point clouds" href="paper-reading-notes\deep-hough-voting-for-3d-object-detection-in-point-clouds.html" class="internal-link" target="_self" rel="noopener nofollow">VoteNet</a>ä½œdecoder<br>code<br>è®­ç»ƒé˜¶æ®µï¼Œæ¯ä¸ªepochä¸­ï¼Œiterative_train äº†ä¸¤éï¼Œç´¯è®¡äº†ä¸¤æ¬¡çš„è¯¯å·®ä¹‹åï¼Œä¹‹åæ‰åšåå‘è¿‡ç¨‹ï¼Ÿ<br>ç»“è®ºä¸­æåˆ°çš„<br>
<br>ç‰©ä½“æ ‡æ³¨boxçš„æ–¹å‘ï¼šè®ºæ–‡ä¸­diffusionçš„å™ªå£°åŠ åœ¨äº†box size å’Œclass labelä¸Šï¼Œæ²¡æœ‰è€ƒè™‘box directionã€‚æ—‹è½¬ä¸å˜æ€§ï¼ˆobject-level rotation equivalenceï¼‰ï¼Œscannetæ•°æ®é›†æ˜¯æ²¡æœ‰object orientationçš„ã€‚<a data-href="Rotationally equivariant 3D object detection" href="paper-reading-notes\rotationally-equivariant-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Rotationally equivariant 3D object detection</a>

<br>æ—‹è½¬åœºæ™¯æ¥å¢å¼ºæ•°æ®ï¼Ÿ


<br>å®¤å¤–æ•°æ®é›†
<br>å®æ—¶æ€§
<br>TODO<br>
<br>è·¨åŸŸé—®é¢˜
<br>é•¿å°¾åˆ†å¸ƒé—®é¢˜
]]></description><link>paper-reading-notes\diffusion-ss3d_-diffusion-model-for-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Diffusion-ss3d_ Diffusion model for semi-supervised 3D object detection.md</guid><pubDate>Sat, 24 Aug 2024 06:38:06 GMT</pubDate></item><item><title><![CDATA[Does unlabeled data provably help? Worst-case analysis of the sample complexity of semi-supervised learning]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\does-unlabeled-data-provably-help_-worst-case-analysis-of-the-sample-complexity-of-semi-supervised-learning.html</link><guid isPermaLink="false">Paper reading notes/Does unlabeled data provably help_ Worst-case analysis of the sample complexity of semi-supervised learning.md</guid><pubDate>Wed, 27 Nov 2024 07:57:04 GMT</pubDate></item><item><title><![CDATA[DQS3D Densely-matched quantization-aware semi-supervised 3D detection]]></title><description><![CDATA[ 
 <br>ä¹‹å‰çš„ sparse spatial training signal --&gt; æå‡º dense spatial training signal<br>ç”±äºä¹‹å‰åƒvotenetçš„æ¡†æ¶ï¼Œå…ˆæå–å‡ºseed pointsï¼Œç„¶åå†ä¹‹ä¸Šåšé¢„æµ‹ï¼Œè¿™å¯¼è‡´äº†training signalçš„ç©ºé—´ç¨€ç–æ€§ã€‚è®ºæ–‡å—å…¨å·ç§¯3Dæ£€æµ‹çš„å¯å‘ï¼Œè®¾è®¡äº†ç©ºé—´å¯†é›†å‹çš„training signalã€‚<br>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨dense matchingï¼Œä¼ªæ ‡ç­¾çš„ç”Ÿæˆè´¨é‡æœ‰æ˜æ˜¾çš„æå‡ï¼Œå¹¶ä¸”æå‡æ›²çº¿æ›´åŠ å…‰æ»‘ã€‚<br><img alt="Pasted image 20240830211025.png" src="lib\media\pasted-image-20240830211025.png"><br>æ¨¡å‹ç»†èŠ‚ï¼›<br>ä½¿ç”¨Fcaf3dä¸º3dæ£€æµ‹å¤´ <a data-href="FCAF3D_ Fully convolutional anchor-free 3D object detection" href="paper-reading-notes\fcaf3d_-fully-convolutional-anchor-free-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">FCAF3D_ Fully convolutional anchor-free 3D object detection</a><br>limitation<br>
<br>æ€§èƒ½å¯¹voxel sizeè¾ƒçµæ•ï¼š
<br><img alt="Pasted image 20240831200342.png" src="lib\media\pasted-image-20240831200342.png"><br>
<br>ç‚¹äº‘åˆ†è¾¨ç‡å¯¹ä½“ç´ åŒ–çš„å½±å“è¾ƒå¤§
]]></description><link>paper-reading-notes\dqs3d_-densely-matched-quantization-aware-semi-supervised-3d-detection.html</link><guid isPermaLink="false">Paper reading notes/DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection.md</guid><pubDate>Tue, 03 Sep 2024 15:59:27 GMT</pubDate><enclosure url="lib\media\pasted-image-20240830211025.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240830211025.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Dynamic neural radiance fields for monocular 4D facial avatar reconstruction]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\dynamic-neural-radiance-fields-for-monocular-4d-facial-avatar-reconstruction.html</link><guid isPermaLink="false">Paper reading notes/Dynamic neural radiance fields for monocular 4D facial avatar reconstruction.md</guid><pubDate>Mon, 08 Jul 2024 02:05:51 GMT</pubDate></item><item><title><![CDATA[End-to-end semi-supervised object detection with soft teacher]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\end-to-end-semi-supervised-object-detection-with-soft-teacher.html</link><guid isPermaLink="false">Paper reading notes/End-to-end semi-supervised object detection with soft teacher.md</guid><pubDate>Fri, 16 Aug 2024 05:44:37 GMT</pubDate></item><item><title><![CDATA[FCAF3D Fully convolutional anchor-free 3D object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\fcaf3d_-fully-convolutional-anchor-free-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/FCAF3D_ Fully convolutional anchor-free 3D object detection.md</guid><pubDate>Sun, 01 Sep 2024 08:00:11 GMT</pubDate></item><item><title><![CDATA[FixMatch Simplifying semi-supervised learning with consistency and confidence]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\fixmatch_-simplifying-semi-supervised-learning-with-consistency-and-confidence.html</link><guid isPermaLink="false">Paper reading notes/FixMatch_ Simplifying semi-supervised learning with consistency and confidence.md</guid><pubDate>Fri, 16 Aug 2024 05:34:46 GMT</pubDate></item><item><title><![CDATA[FlashAvatar_ High-fidelity head avatar with efficient gaussian embedding]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\flashavatar_-high-fidelity-head-avatar-with-efficient-gaussian-embedding.html</link><guid isPermaLink="false">Paper reading notes/FlashAvatar_ High-fidelity head avatar with efficient gaussian embedding.md</guid><pubDate>Sat, 15 Jun 2024 13:47:54 GMT</pubDate></item><item><title><![CDATA[Gaussian head avatar Ultra high-fidelity head avatar via dynamic gaussians]]></title><description><![CDATA[ 
 <br>æœ‰ä»£ç ]]></description><link>paper-reading-notes\gaussian-head-avatar_-ultra-high-fidelity-head-avatar-via-dynamic-gaussians.html</link><guid isPermaLink="false">Paper reading notes/Gaussian head avatar_ Ultra high-fidelity head avatar via dynamic gaussians.md</guid><pubDate>Wed, 10 Jul 2024 03:19:23 GMT</pubDate></item><item><title><![CDATA[GaussianAvatars Photorealistic head avatars with rigged 3D gaussians]]></title><description><![CDATA[ 
 <br>ä»£ç è¿˜æœªå…¬å¼€<br>CVPR2024 highlight]]></description><link>paper-reading-notes\gaussianavatars_-photorealistic-head-avatars-with-rigged-3d-gaussians.html</link><guid isPermaLink="false">Paper reading notes/GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians.md</guid><pubDate>Mon, 08 Jul 2024 01:57:29 GMT</pubDate></item><item><title><![CDATA[GaussianHead High-fidelity head avatars with learnable gaussian derivation]]></title><description><![CDATA[ 
 <br>æœ‰ä»£ç <br><br>motion deformation field]]></description><link>paper-reading-notes\gaussianhead_-high-fidelity-head-avatars-with-learnable-gaussian-derivation.html</link><guid isPermaLink="false">Paper reading notes/GaussianHead_ High-fidelity head avatars with learnable gaussian derivation.md</guid><pubDate>Wed, 10 Jul 2024 03:20:42 GMT</pubDate></item><item><title><![CDATA[Generalization error bounds in semi-supervised classiï¬cation under the cluster assumption]]></title><description><![CDATA[ 
 <br>cluster assumption]]></description><link>paper-reading-notes\generalization-error-bounds-in-semi-supervised-classiï¬cation-under-the-cluster-assumption.html</link><guid isPermaLink="false">Paper reading notes/Generalization error bounds in semi-supervised classiï¬cation under the cluster assumption.md</guid><pubDate>Tue, 26 Nov 2024 13:22:56 GMT</pubDate></item><item><title><![CDATA[Gradient-based sampling for class imbalanced semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\gradient-based-sampling-for-class-imbalanced-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Gradient-based sampling for class imbalanced semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 01:30:46 GMT</pubDate></item><item><title><![CDATA[HeadGaS Real-time animatable head avatars via 3D gaussian splatting]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\headgas_-real-time-animatable-head-avatars-via-3d-gaussian-splatting.html</link><guid isPermaLink="false">Paper reading notes/HeadGaS_ Real-time animatable head avatars via 3D gaussian splatting.md</guid><pubDate>Mon, 08 Jul 2024 02:00:38 GMT</pubDate></item><item><title><![CDATA[Hierarchical supervision and shuffle data augmentation for 3D semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\hierarchical-supervision-and-shuffle-data-augmentation-for-3d-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Hierarchical supervision and shuffle data augmentation for 3D semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 02:57:59 GMT</pubDate></item><item><title><![CDATA[Humble teachers teach better students for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\humble-teachers-teach-better-students-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Humble teachers teach better students for semi-supervised object detection.md</guid><pubDate>Tue, 27 Aug 2024 05:07:31 GMT</pubDate></item><item><title><![CDATA[Incremental object detection via meta-learning]]></title><description><![CDATA[ 
 <br>TPAMI 2021]]></description><link>paper-reading-notes\incremental-object-detection-via-meta-learning.html</link><guid isPermaLink="false">Paper reading notes/Incremental object detection via meta-learning.md</guid><pubDate>Fri, 16 Aug 2024 14:22:38 GMT</pubDate></item><item><title><![CDATA[Incremental object detection with CLIP]]></title><description><![CDATA[ 
 <br>
<br>language-visual model
]]></description><link>paper-reading-notes\incremental-object-detection-with-clip.html</link><guid isPermaLink="false">Paper reading notes/Incremental object detection with CLIP.md</guid><pubDate>Fri, 23 Aug 2024 07:04:33 GMT</pubDate></item><item><title><![CDATA[Instant-teaching An end-to-end semi-supervised object detection framework]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\instant-teaching_-an-end-to-end-semi-supervised-object-detection-framework.html</link><guid isPermaLink="false">Paper reading notes/Instant-teaching_ An end-to-end semi-supervised object detection framework.md</guid><pubDate>Mon, 26 Aug 2024 03:32:06 GMT</pubDate></item><item><title><![CDATA[Interactive self-training with mean teachers for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\interactive-self-training-with-mean-teachers-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Interactive self-training with mean teachers for semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 03:16:19 GMT</pubDate></item><item><title><![CDATA[Interpolation-based semi-supervised learning for object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\interpolation-based-semi-supervised-learning-for-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Interpolation-based semi-supervised learning for object detection.md</guid><pubDate>Mon, 26 Aug 2024 03:32:35 GMT</pubDate></item><item><title><![CDATA[Joint semi-supervised and active learning via 3D consistency for 3D object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\joint-semi-supervised-and-active-learning-via-3d-consistency-for-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Joint semi-supervised and active learning via 3D consistency for 3D object detection.md</guid><pubDate>Tue, 10 Sep 2024 07:38:15 GMT</pubDate></item><item><title><![CDATA[Label matching semi-supervised object detection]]></title><description><![CDATA[ 
 <br>ç°æœ‰çš„é—®é¢˜ï¼š<br>label mismatch problem<br>
<br>distribution level mismatchï¼šæ¯ç§ç±»çš„ ä¼ªæ ‡ç­¾/GT  çš„åˆ†å¸ƒä¸å‡åŒ€ï¼Œä½“ç°åœ¨æŸäº›ç±»ä¸­ä¼ªæ ‡ç­¾æ•°é‡è¿œå¤šäºGTï¼Œè€Œåœ¨å¦ä¸€äº›ç±»ä¸­GTæ•°é‡è¿œå¤šäºä¼ªæ ‡ç­¾
<br>instance level mismatchï¼šå¤§æ¦‚æ„æ€æ˜¯ç”¨IoUçš„æ–¹æ³•ï¼Œä¼šåœ¨å¯èƒ½çš„ç›®æ ‡å‘¨å›´ç”Ÿæˆä¸€ç°‡å€™é€‰æ¡†ï¼Œä½†å¯èƒ½å®ƒä»¬çš„objectiveåˆ†æ•°ååˆ†ç›¸ä¼¼ï¼Œä½¿ç”¨NMSç­›é€‰å¯èƒ½å¯¼è‡´æœ€ç»ˆçš„å€™é€‰æ¡†å®šä½ä¸å‡†ç¡®
<br>è´¡çŒ®<br>
<br>æå‡ºä½¿ç”¨è’™ç‰¹å¡æ´›é‡‡æ ·Monte Carlo Samplingæ¥è§£å†³distribution mismatch
<br>å°†labelsåˆ†ä¸ºreliableå’Œhard labelï¼Œå¯¹hardåšRPLMï¼ˆä¼ªæ ‡ç­¾æŒ–æ˜ï¼‰è§£å†³instance mismatché—®é¢˜
]]></description><link>paper-reading-notes\label-matching-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Label matching semi-supervised object detection.md</guid><pubDate>Wed, 28 Aug 2024 10:39:14 GMT</pubDate></item><item><title><![CDATA[Learning from labeled and unlabeled data with label propagation]]></title><description><![CDATA[ 
 <br>proposed a label propagation iterative algorithm to propagate labels through the dataset along high density areas defined by unlabeled data.<br>åŸºäºè¿™ä¸ªå‡è®¾ï¼šassume: closer data points tend to have similar class labels<br>æå‡ºäº†ä¸€ç§ label propagation çš„ç®—æ³•<br><img alt="Pasted image 20241126200507.png" src="lib\media\pasted-image-20241126200507.png">]]></description><link>paper-reading-notes\learning-from-labeled-and-unlabeled-data-with-label-propagation.html</link><guid isPermaLink="false">Paper reading notes/Learning from labeled and unlabeled data with label propagation.md</guid><pubDate>Tue, 26 Nov 2024 12:06:22 GMT</pubDate><enclosure url="lib\media\pasted-image-20241126200507.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241126200507.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Learning from noisy data for semi-supervised 3D object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\learning-from-noisy-data-for-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Learning from noisy data for semi-supervised 3D object detection.md</guid><pubDate>Mon, 26 Aug 2024 01:00:01 GMT</pubDate></item><item><title><![CDATA[Learning object-level point augmentor for semi-supervised 3D object detection]]></title><description><![CDATA[ 
 <br>å¯è®­ç»ƒçš„ object-level augmentor]]></description><link>paper-reading-notes\learning-object-level-point-augmentor-for-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Learning object-level point augmentor for semi-supervised 3D object detection.md</guid><pubDate>Fri, 23 Aug 2024 12:22:21 GMT</pubDate></item><item><title><![CDATA[Learning task-aware language-image representation for class-incremental object detection]]></title><description><![CDATA[ 
 <br>AAAI 2024<br>
<br>language-image detector
]]></description><link>paper-reading-notes\learning-task-aware-language-image-representation-for-class-incremental-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Learning task-aware language-image representation for class-incremental object detection.md</guid><pubDate>Fri, 23 Aug 2024 07:00:08 GMT</pubDate></item><item><title><![CDATA[Mean teachers are better role models Weight-averaged consistency targets improve semi-supervised deep learning results]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\mean-teachers-are-better-role-models_-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html</link><guid isPermaLink="false">Paper reading notes/Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results.md</guid><pubDate>Wed, 27 Nov 2024 13:16:16 GMT</pubDate></item><item><title><![CDATA[MixTeacher Mining promising labels with mixed scale teacher for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\mixteacher_-mining-promising-labels-with-mixed-scale-teacher-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/MixTeacher_ Mining promising labels with mixed scale teacher for semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 01:56:28 GMT</pubDate></item><item><title><![CDATA[Monocular 3D object detection with LiDAR guided semi supervised active learning]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\monocular-3d-object-detection-with-lidar-guided-semi-supervised-active-learning.html</link><guid isPermaLink="false">Paper reading notes/Monocular 3D object detection with LiDAR guided semi supervised active learning.md</guid><pubDate>Tue, 10 Sep 2024 07:34:22 GMT</pubDate></item><item><title><![CDATA[MonoGaussianAvatar_ Monocular gaussian point-based head avatar]]></title><description><![CDATA[ 
 <br>ä»£ç coming soon<br><br><br>a 4D facial avatar model based on NeRFï¼š<a data-href="Dynamic neural radiance fields for monocular 4D facial avatar reconstruction" href="paper-reading-notes\dynamic-neural-radiance-fields-for-monocular-4d-facial-avatar-reconstruction.html" class="internal-link" target="_self" rel="noopener nofollow">Dynamic neural radiance fields for monocular 4D facial avatar reconstruction</a>]]></description><link>paper-reading-notes\monogaussianavatar_-monocular-gaussian-point-based-head-avatar.html</link><guid isPermaLink="false">Paper reading notes/MonoGaussianAvatar_ Monocular gaussian point-based head avatar.md</guid><pubDate>Tue, 09 Jul 2024 09:58:37 GMT</pubDate></item><item><title><![CDATA[MUM Mix image tiles and UnMix feature tiles for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\mum_-mix-image-tiles-and-unmix-feature-tiles-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/MUM_ Mix image tiles and UnMix feature tiles for semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 02:55:08 GMT</pubDate></item><item><title><![CDATA[NeRF-Art Text-driven neural radiance fields stylization]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\nerf-art_-text-driven-neural-radiance-fields-stylization.html</link><guid isPermaLink="false">Paper reading notes/NeRF-Art_ Text-driven neural radiance fields stylization.md</guid><pubDate>Thu, 18 Jul 2024 11:11:31 GMT</pubDate></item><item><title><![CDATA[Not all labels are equal Rationalizing the labeling costs for training object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\not-all-labels-are-equal_-rationalizing-the-labeling-costs-for-training-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Not all labels are equal_ Rationalizing the labeling costs for training object detection.md</guid><pubDate>Tue, 10 Sep 2024 07:43:11 GMT</pubDate></item><item><title><![CDATA[Not every side is equal Localization uncertainty estimation for semi-supervised 3D object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\not-every-side-is-equal_-localization-uncertainty-estimation-for-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Not every side is equal_ Localization uncertainty estimation for semi-supervised 3D object detection.md</guid><pubDate>Sun, 03 Nov 2024 02:47:19 GMT</pubDate></item><item><title><![CDATA[Open-vocabulary point-cloud object detection without 3D annotation]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\open-vocabulary-point-cloud-object-detection-without-3d-annotation.html</link><guid isPermaLink="false">Paper reading notes/Open-vocabulary point-cloud object detection without 3D annotation.md</guid><pubDate>Fri, 23 Aug 2024 14:44:06 GMT</pubDate></item><item><title><![CDATA[Overcoming catastrophic forgetting in incremental object detection via elastic response distillation]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\overcoming-catastrophic-forgetting-in-incremental-object-detection-via-elastic-response-distillation.html</link><guid isPermaLink="false">Paper reading notes/Overcoming catastrophic forgetting in incremental object detection via elastic response distillation.md</guid><pubDate>Fri, 23 Aug 2024 07:51:20 GMT</pubDate></item><item><title><![CDATA[Plug and play active learning for object detection]]></title><description><![CDATA[ 
 <br>batch active learning setting]]></description><link>paper-reading-notes\plug-and-play-active-learning-for-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Plug and play active learning for object detection.md</guid><pubDate>Thu, 05 Sep 2024 06:19:57 GMT</pubDate></item><item><title><![CDATA[PointNet++ Deep hierarchical feature learning on point sets in a metric space]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\pointnet++_-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.html</link><guid isPermaLink="false">Paper reading notes/PointNet++_ Deep hierarchical feature learning on point sets in a metric space.md</guid><pubDate>Fri, 16 Aug 2024 03:10:43 GMT</pubDate></item><item><title><![CDATA[Proposal learning for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\proposal-learning-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Proposal learning for semi-supervised object detection.md</guid><pubDate>Fri, 16 Aug 2024 05:43:12 GMT</pubDate></item><item><title><![CDATA[PSAvatar A point-based morphable shape model for real-time head avatar animation with 3D gaussian splatting]]></title><description><![CDATA[ 
 <br>æœ‰åŠ¨ç”»é©±åŠ¨ï¼Œç›®å‰æ²¡æœ‰å…¬å¸ƒä»£ç ]]></description><link>paper-reading-notes\psavatar_-a-point-based-morphable-shape-model-for-real-time-head-avatar-animation-with-3d-gaussian-splatting.html</link><guid isPermaLink="false">Paper reading notes/PSAvatar_ A point-based morphable shape model for real-time head avatar animation with 3D gaussian splatting.md</guid><pubDate>Mon, 08 Jul 2024 01:47:49 GMT</pubDate></item><item><title><![CDATA[PV-RCNN Point-voxel feature set abstraction for 3D object detection]]></title><description><![CDATA[ 
 <br><a data-href="PointNet++_ Deep hierarchical feature learning on point sets in a metric space" href="paper-reading-notes\pointnet++_-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.html" class="internal-link" target="_self" rel="noopener nofollow">PointNet++_ Deep hierarchical feature learning on point sets in a metric space</a>]]></description><link>paper-reading-notes\pv-rcnn_-point-voxel-feature-set-abstraction-for-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/PV-RCNN_ Point-voxel feature set abstraction for 3D object detection.md</guid><pubDate>Fri, 16 Aug 2024 03:10:37 GMT</pubDate></item><item><title><![CDATA[1 Introduction]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://blog.csdn.net/qq_45752541/article/details/138244940" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/qq_45752541/article/details/138244940" target="_blank">ã€ä¸‰ç»´é‡å»ºã€‘ä¸­ç§‘é™¢æœ€æ–°3DGSç»¼è¿°ï¼ˆè¿‘æœŸè¿›å±•æ›´æ–°ä¸­ï¼‰_3dgsè¡¨é¢æå–-CSDNåšå®¢</a><br><br>èƒŒæ™¯ï¼šè™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®çš„å‘å±•ï¼Œå¯¹çœŸå®çš„3Då†…å®¹éœ€æ±‚å¢é•¿ã€‚ä¼ ç»Ÿ3Då†…å®¹åˆ›å»ºæ–¹æ³•åŒ…æ‹¬<br>
<br>ä»æ‰«æä»ªæˆ–å¤šè§†è§’å›¾ç‰‡è¿›è¡Œ3Dé‡å»ºï¼šç”±äºä¸å®Œç¾çš„æ•è·å’Œç›¸æœºä¼°è®¡å™ªå£°ï¼Œå¯¼è‡´å¤±è´¥çš„é‡å»ºç»“æœ
<br>ä½¿ç”¨ä¸“ä¸šè½¯ä»¶3Då»ºæ¨¡ï¼šå†…å®¹çœŸå®ï¼Œä½†éœ€è¦ä¸“ä¸šçš„ç”¨æˆ·è®­ç»ƒå’Œäº¤äº’ï¼Œè€—æ—¶
<br>NeRFï¼šä¸ºäº†è‡ªåŠ¨ç”ŸæˆçœŸå®çš„3Då†…å®¹ï¼Œç¥ç»éšå¼åœºï¼ˆNeRFï¼‰æå‡ºåˆ†åˆ«ä½¿ç”¨å¯†åº¦åœºï¼ˆdensity fieldï¼‰å’Œé¢œè‰²åœºï¼ˆcolor fieldï¼‰æ¥å»ºæ¨¡3Dåœºæ™¯çš„å‡ ä½•å’Œçº¹ç†ã€‚è™½ç„¶NeRFå¤§å¤§æå‡äº†æ–°è§†è§’åˆæˆï¼ˆnovel view synthesisï¼‰ç»“æœçš„è´¨é‡ï¼Œä½†æ˜¯å®ƒè®­ç»ƒå’Œæ¸²æŸ“çš„æ—¶é—´ææ…¢ã€‚å°½ç®¡æœ‰ä¸€äº›æ–¹æ³•è‡´åŠ›äºæå‡NeRFçš„é€Ÿåº¦ï¼Œä½†ä¾æ—§æ— æ³•è¾¾åˆ°ä¸€ç§é²æ£’çš„æ–¹æ³•ï¼Œä½¿å…¶åœ¨é€šç”¨è®¾å¤‡ä¸Šçš„è®­ç»ƒæ—¶é—´å°äºç­‰äº1å°æ—¶ï¼Œæ¸²æŸ“é€Ÿåº¦å¤§äºç­‰äº30FPSã€‚<br>3DGSï¼šä¸ºäº†è§£å†³NeRFçš„é€Ÿåº¦é—®é¢˜ï¼Œ3DGSä½¿ç”¨äº†ä¸€ç»„æ …æ ¼åŒ–çš„é«˜æ–¯æ¤­çƒæ¥è¿‘ä¼¼ä¼°è®¡3Dåœºæ™¯çš„çº¹ç†ï¼Œè¿™ä½¿å…¶è®­ç»ƒèƒ½å¤Ÿåœ¨30åˆ†é’Ÿå·¦å³æ”¶æ•›ï¼Œåœ¨1080pçš„åˆ†è¾¨ç‡ä¸Šè¾¾åˆ°30FPSçš„æ¸²æŸ“é€Ÿåº¦ï¼Œå¹¶ä¸”å¤šè§†è§’åˆæˆçš„ç»“æœè´¨é‡ä¸NeRFå¯æ¯”ã€‚<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†è¿‘æœŸçš„åŸºäº3DGSçš„ç ”ç©¶ï¼Œä¸»è¦åŒ…å«äº†3DGSçš„ä»¥ä¸‹å‡ ä¸ªç ”ç©¶æ–¹å‘ï¼š<br>
<br>3Dåœºæ™¯é‡å»ºï¼šGaussian Splatting for 3D Reconstruction
<br>3Dç¼–è¾‘ï¼šGaussian Splatting for 3D Editing
<br>3DGSåº”ç”¨ï¼šApplications of Gaussian Splatting
<br><br><br><br><br><br><br><br><br><br><br><br><br><a data-href="MonoGaussianAvatar_ Monocular gaussian point-based head avatar" href="paper-reading-notes\monogaussianavatar_-monocular-gaussian-point-based-head-avatar.html" class="internal-link" target="_self" rel="noopener nofollow">MonoGaussianAvatar_ Monocular gaussian point-based head avatar</a><br><a data-href="PSAvatar_ A point-based morphable shape model for real-time head avatar animation with 3D gaussian splatting" href="paper-reading-notes\psavatar_-a-point-based-morphable-shape-model-for-real-time-head-avatar-animation-with-3d-gaussian-splatting.html" class="internal-link" target="_self" rel="noopener nofollow">PSAvatar_ A point-based morphable shape model for real-time head avatar animation with 3D gaussian splatting</a><br><a data-href="GaussianHead_ High-fidelity head avatars with learnable gaussian derivation" href="paper-reading-notes\gaussianhead_-high-fidelity-head-avatars-with-learnable-gaussian-derivation.html" class="internal-link" target="_self" rel="noopener nofollow">GaussianHead_ High-fidelity head avatars with learnable gaussian derivation</a><br><a data-href="GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians" href="paper-reading-notes\gaussianavatars_-photorealistic-head-avatars-with-rigged-3d-gaussians.html" class="internal-link" target="_self" rel="noopener nofollow">GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians</a><br><a data-href="Rig3DGS_ Creating controllable portraits from casual monocular videos" href="paper-reading-notes\rig3dgs_-creating-controllable-portraits-from-casual-monocular-videos.html" class="internal-link" target="_self" rel="noopener nofollow">Rig3DGS_ Creating controllable portraits from casual monocular videos</a><br><a data-href="GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians" href="paper-reading-notes\gaussianavatars_-photorealistic-head-avatars-with-rigged-3d-gaussians.html" class="internal-link" target="_self" rel="noopener nofollow">GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians</a><br><a data-href="HeadGaS_ Real-time animatable head avatars via 3D gaussian splatting" href="paper-reading-notes\headgas_-real-time-animatable-head-avatars-via-3d-gaussian-splatting.html" class="internal-link" target="_self" rel="noopener nofollow">HeadGaS_ Real-time animatable head avatars via 3D gaussian splatting</a><br><a data-href="FlashAvatar_ High-fidelity head avatar with efficient gaussian embedding" href="paper-reading-notes\flashavatar_-high-fidelity-head-avatar-with-efficient-gaussian-embedding.html" class="internal-link" target="_self" rel="noopener nofollow">FlashAvatar_ High-fidelity head avatar with efficient gaussian embedding</a><br><a data-href="Gaussian head avatar_ Ultra high-fidelity head avatar via dynamic gaussians" href="paper-reading-notes\gaussian-head-avatar_-ultra-high-fidelity-head-avatar-via-dynamic-gaussians.html" class="internal-link" target="_self" rel="noopener nofollow">Gaussian head avatar_ Ultra high-fidelity head avatar via dynamic gaussians</a><br><br>]]></description><link>paper-reading-notes\recent-advances-in-3d-gaussian-splatting.html</link><guid isPermaLink="false">Paper reading notes/Recent advances in 3D gaussian splatting.md</guid><pubDate>Sat, 15 Jun 2024 13:48:57 GMT</pubDate></item><item><title><![CDATA[Revisiting class imbalance for end-to-end semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\revisiting-class-imbalance-for-end-to-end-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Revisiting class imbalance for end-to-end semi-supervised object detection.md</guid><pubDate>Tue, 10 Sep 2024 06:57:58 GMT</pubDate></item><item><title><![CDATA[Rig3DGS_ Creating controllable portraits from casual monocular videos]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\rig3dgs_-creating-controllable-portraits-from-casual-monocular-videos.html</link><guid isPermaLink="false">Paper reading notes/Rig3DGS_ Creating controllable portraits from casual monocular videos.md</guid><pubDate>Sat, 15 Jun 2024 13:45:49 GMT</pubDate></item><item><title><![CDATA[Rotationally equivariant 3D object detection]]></title><description><![CDATA[ 
 <br>CVPR 2022]]></description><link>paper-reading-notes\rotationally-equivariant-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Rotationally equivariant 3D object detection.md</guid><pubDate>Fri, 23 Aug 2024 05:35:38 GMT</pubDate></item><item><title><![CDATA[S-CLIP_ Semi-supervised vision-language learning using few specialist captions]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\s-clip_-semi-supervised-vision-language-learning-using-few-specialist-captions.html</link><guid isPermaLink="false">Paper reading notes/S-CLIP_ Semi-supervised vision-language learning using few specialist captions.md</guid><pubDate>Tue, 27 Aug 2024 03:57:55 GMT</pubDate></item><item><title><![CDATA[Scale-equivalent distillation for semi-supervised object detection]]></title><description><![CDATA[ 
 <br>åœ¨ç›®å‰çš„ä»»åŠ¡ä¸­å‘ç°çš„é—®é¢˜ï¼š<br>
<br>å¤§é‡false negative æ ·æœ¬
<br>ä¸å¥½çš„å®šä½ç²¾åº¦
<br>ç‰©ä½“size æœ‰large variance
<br>èƒŒæ™¯å’Œobjectç±»åˆ«çš„class imbalance
<br>æå‡ºäº†ä¸€ç§çŸ¥è¯†è’¸é¦æ¡†æ¶å¯¹large object size variance å’Œ class imbalanceæœ‰é²æ£’æ€§<br>å°ºåº¦ä¸€è‡´æ€§çº¦æŸ scale consistency regularization<br>æå‡ºä¸€ç§è‡ªè’¸é¦æ–¹æ³•æ¥æå‡æ³›åŒ–èƒ½åŠ›<br>ä½¿ç”¨é‡é‡‡æ ·ç­–ç•¥æ¥è§£å†³class imbalanceé—®é¢˜]]></description><link>paper-reading-notes\scale-equivalent-distillation-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Scale-equivalent distillation for semi-supervised object detection.md</guid><pubDate>Tue, 27 Aug 2024 11:10:07 GMT</pubDate></item><item><title><![CDATA[SDDGR Stable diffusion-based deep generative replay for class incremental object detection]]></title><description><![CDATA[ 
 <br>CVPR 2024<br>
<br>diffusion-based deep generative replay
<br>L2 knowledge distillation
]]></description><link>paper-reading-notes\sddgr_-stable-diffusion-based-deep-generative-replay-for-class-incremental-object-detection.html</link><guid isPermaLink="false">Paper reading notes/SDDGR_ Stable diffusion-based deep generative replay for class incremental object detection.md</guid><pubDate>Fri, 23 Aug 2024 06:47:10 GMT</pubDate></item><item><title><![CDATA[SECOND Sparsely embedded convolutional detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\second_-sparsely-embedded-convolutional-detection.html</link><guid isPermaLink="false">Paper reading notes/SECOND_ Sparsely embedded convolutional detection.md</guid><pubDate>Sun, 20 Oct 2024 15:20:30 GMT</pubDate></item><item><title><![CDATA[Self-training with Noisy Student improves ImageNet classification]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\self-training-with-noisy-student-improves-imagenet-classification.html</link><guid isPermaLink="false">Paper reading notes/Self-training with Noisy Student improves ImageNet classification.md</guid><pubDate>Wed, 27 Nov 2024 13:49:36 GMT</pubDate></item><item><title><![CDATA[Semi-detr Semi-supervised object detection with detection transformers]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-detr_-semi-supervised-object-detection-with-detection-transformers.html</link><guid isPermaLink="false">Paper reading notes/Semi-detr_ Semi-supervised object detection with detection transformers.md</guid><pubDate>Mon, 26 Aug 2024 02:08:50 GMT</pubDate></item><item><title><![CDATA[Semi-supervised and long-tailed object detection with cascadematch]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-supervised-and-long-tailed-object-detection-with-cascadematch.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised and long-tailed object detection with cascadematch.md</guid><pubDate>Tue, 10 Sep 2024 06:45:30 GMT</pubDate></item><item><title><![CDATA[Semi-supervised dimension reduction for multi-label classification]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-supervised-dimension-reduction-for-multi-label-classification.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised dimension reduction for multi-label classification.md</guid><pubDate>Wed, 27 Nov 2024 08:14:27 GMT</pubDate></item><item><title><![CDATA[Semi-supervised learning by entropy minimization]]></title><description><![CDATA[ 
 <br>minimum entropy regularizer]]></description><link>paper-reading-notes\semi-supervised-learning-by-entropy-minimization.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised learning by entropy minimization.md</guid><pubDate>Tue, 26 Nov 2024 13:04:51 GMT</pubDate></item><item><title><![CDATA[Semi-supervised learning by sparse representation]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-supervised-learning-by-sparse-representation.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised learning by sparse representation.md</guid><pubDate>Wed, 27 Nov 2024 08:01:28 GMT</pubDate></item><item><title><![CDATA[Semi-supervised learning of mixture models]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-supervised-learning-of-mixture-models.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised learning of mixture models.md</guid><pubDate>Tue, 26 Nov 2024 12:07:25 GMT</pubDate></item><item><title><![CDATA[Semi-supervised learning using gaussian fields and harmonic functions]]></title><description><![CDATA[ 
 <br>weighted graph <br>Gaussian random field model.]]></description><link>paper-reading-notes\semi-supervised-learning-using-gaussian-fields-and-harmonic-functions.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised learning using gaussian fields and harmonic functions.md</guid><pubDate>Tue, 26 Nov 2024 12:57:43 GMT</pubDate></item><item><title><![CDATA[Semi-supervised learning via generalized maximum entropy]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-supervised-learning-via-generalized-maximum-entropy.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised learning via generalized maximum entropy.md</guid><pubDate>Wed, 27 Nov 2024 08:06:12 GMT</pubDate></item><item><title><![CDATA[Semi-supervised object detection via multi-instance alignment with global class prototypes]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\semi-supervised-object-detection-via-multi-instance-alignment-with-global-class-prototypes.html</link><guid isPermaLink="false">Paper reading notes/Semi-supervised object detection via multi-instance alignment with global class prototypes.md</guid><pubDate>Mon, 26 Aug 2024 02:42:20 GMT</pubDate></item><item><title><![CDATA[SESS Self-ensembling semi-supervised 3D object detection]]></title><description><![CDATA[ 
 <br>ä½¿ç”¨ teacher-student framework with pseudo-labeling<br>æ¨¡å‹è®­ç»ƒï¼š<br>
<br>åŒæ—¶è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ï¼ˆstudent&amp;teacherï¼‰
<br>ä½¿ç”¨æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾çš„æ•°æ®ï¼Œç»è¿‡éšæœºå˜æ¢åï¼Œç»™studentæ¨¡å‹è®­ç»ƒ
<br>ä½¿ç”¨æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾çš„æ•°æ®ï¼Œç»™teacheræ¨¡å‹ï¼Œå¾—åˆ°ä¼ªæ ‡ç­¾ï¼Œç„¶åä½¿ç”¨ç›¸åŒçš„éšæœºå˜æ¢ï¼Œå¾—åˆ°å˜æ¢åçš„ä¼ªæ ‡ç­¾
<br>studentæ¨¡å‹çš„æŸå¤±åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šç›‘ç£æŸå¤±å’Œä¸€è‡´æ€§æŸå¤±

<br>ç›‘ç£æŸå¤± (supervised loss) ä¸ºæœ‰æ ‡ç­¾çš„æ•°æ®ï¼Œç»è¿‡éšæœºå˜æ¢åï¼Œæ¨¡å‹çš„é¢„æµ‹ç»“æœä¸ç»è¿‡å˜æ¢åçš„æ ‡æ³¨ï¼Œè®¡ç®—æŸå¤±
<br>ä¸€è‡´æ€§æŸå¤± (consistency loss) ä¸ºstudentä½¿ç”¨ç»è¿‡å˜æ¢åçš„æ•°æ®ï¼ˆåŒ…æ‹¬æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾çš„ï¼‰å¾—åˆ°çš„é¢„æµ‹ç»“æœï¼Œä¸teacheræ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œç»è¿‡ç›¸åŒçš„éšæœºå˜æ¢åï¼Œå¾—åˆ°çš„é¢„æµ‹ç»“æœï¼Œæœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾çš„é¢„æµ‹ï¼Œè®¡ç®—ï¼ˆcenter-aware, class-awareå’Œsize-awareï¼‰


<br><img alt="Pasted image 20240817162119.png" src="lib\media\pasted-image-20240817162119.png">]]></description><link>paper-reading-notes\sess_-self-ensembling-semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Paper reading notes/SESS_ Self-ensembling semi-supervised 3D object detection.md</guid><pubDate>Sat, 17 Aug 2024 08:21:21 GMT</pubDate><enclosure url="lib\media\pasted-image-20240817162119.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240817162119.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[SOOD Towards semi-supervised oriented object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\sood_-towards-semi-supervised-oriented-object-detection.html</link><guid isPermaLink="false">Paper reading notes/SOOD_ Towards semi-supervised oriented object detection.md</guid><pubDate>Mon, 26 Aug 2024 02:07:30 GMT</pubDate></item><item><title><![CDATA[Sparse semi-detr Sparse learnable queries for semi-supervised object detection]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\sparse-semi-detr_-sparse-learnable-queries-for-semi-supervised-object-detection.html</link><guid isPermaLink="false">Paper reading notes/Sparse semi-detr_ Sparse learnable queries for semi-supervised object detection.md</guid><pubDate>Mon, 26 Aug 2024 00:47:16 GMT</pubDate></item><item><title><![CDATA[Towards open vocabulary learning A survey]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\towards-open-vocabulary-learning_-a-survey.html</link><guid isPermaLink="false">Paper reading notes/Towards open vocabulary learning_ A survey.md</guid><pubDate>Fri, 23 Aug 2024 14:54:54 GMT</pubDate></item><item><title><![CDATA[Unbiased teacher v2 Semi-supervised object detection for anchor-free and anchor-based detectors]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\unbiased-teacher-v2_-semi-supervised-object-detection-for-anchor-free-and-anchor-based-detectors.html</link><guid isPermaLink="false">Paper reading notes/Unbiased teacher v2_ Semi-supervised object detection for anchor-free and anchor-based detectors.md</guid><pubDate>Mon, 26 Aug 2024 02:51:44 GMT</pubDate></item><item><title><![CDATA[UpCycling Semi-supervised 3D object detection without sharing raw-level unlabeled scenes]]></title><description><![CDATA[ 
 ]]></description><link>paper-reading-notes\upcycling_-semi-supervised-3d-object-detection-without-sharing-raw-level-unlabeled-scenes.html</link><guid isPermaLink="false">Paper reading notes/UpCycling_ Semi-supervised 3D object detection without sharing raw-level unlabeled scenes.md</guid><pubDate>Mon, 26 Aug 2024 01:25:10 GMT</pubDate></item><item><title><![CDATA[Weight-averaged consistency targets improve semi-supervised deep learning results]]></title><description><![CDATA[ 
 <br><img alt="Pasted image 20240816161651.png" src="lib\media\pasted-image-20240816161651.png"><br>teacher modelå‚æ•°çš„æ›´æ–°ç”¨åˆ°äº†EMAå¹³å‡ï¼š<br><img alt="Pasted image 20240816161750.png" src="lib\media\pasted-image-20240816161750.png">]]></description><link>paper-reading-notes\weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html</link><guid isPermaLink="false">Paper reading notes/Weight-averaged consistency targets improve semi-supervised deep learning results.md</guid><pubDate>Fri, 16 Aug 2024 08:17:52 GMT</pubDate><enclosure url="lib\media\pasted-image-20240816161651.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240816161651.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Active&SS3DOD]]></title><description><![CDATA[ 
 <br>
<br>é¢„è®­ç»ƒ

<br>ä½¿ç”¨æœ‰æ ‡ç­¾æ•°æ®è®­ç»ƒå­¦ç”Ÿ


<br>åŠç›‘ç£å­¦ä¹ 

<br>è¾“å…¥ï¼šæœ‰æ ‡æ³¨+æ— æ ‡æ³¨

<br>æœ‰æ ‡æ³¨æ•°æ®
<br>æ— æ ‡æ³¨æ•°æ®
<br>ï¼ˆ+ä¸»åŠ¨å­¦ä¹ ï¼‰æ¯æ¬¡è¿­ä»£ä½¿ç”¨ä¸»åŠ¨å­¦ä¹ ä¾æ¬¡æ‰©å……æœ‰æ ‡æ³¨æ•°æ®é›†
<br>ï¼ˆ+ä¸»åŠ¨å­¦ä¹ ï¼‰ä¸æ˜¯å¯¹æ•´ä¸ªæ•°æ®é›†åšä¸»åŠ¨å­¦ä¹ ç­›é€‰ï¼Œè€Œæ˜¯åœ¨batchå±‚é¢ï¼Œç­›é€‰é€‚åˆå­¦ä¹ çš„æœªæ ‡æ³¨æ•°æ® --&gt; batch active learning setting?

<br>éœ€è¦ä¿®æ”¹æŒ‡æ ‡ï¼Œæ˜¯æ›´éš¾çš„æ•°æ®è¿˜æ˜¯æ›´å®¹æ˜“çš„æ•°æ®ï¼Ÿï¼ˆå¾…ç¡®å®šï¼‰


<br>ç›¸å¯¹äº2Dç›®æ ‡æ£€æµ‹ä¸»åŠ¨å­¦ä¹ æŒ‡æ ‡difficultyï¼Œinformationï¼Œdiversityï¼Œè®¾è®¡æ›´é€‚åˆ3Dç›®æ ‡æ£€æµ‹çš„æŒ‡æ ‡


<br>åŠç›‘ç£æ¡†æ¶ï¼šmean-teacher

<br>æ•°æ®å¢å¼ºï¼šå¯ä»¥ç»“åˆä¸»åŠ¨å­¦ä¹ è¿‡ç¨‹ä¸­è®¡ç®—çš„æŒ‡æ ‡æ¥ç­›é€‰æ•°æ®å¢å¼ºçš„æ–¹å¼å—ï¼Ÿ
<br>ç›®æ ‡æ£€æµ‹å™¨

<br>votenet

<br>è¾“å…¥ï¼špoint clouds
<br>pointnet2 -&gt; seed points
<br>éœå¤«æŠ•ç¥¨ -&gt; vote points
<br>fpsæœ€è¿œç‚¹é‡‡æ ·
<br>proposal




<br>ä¼ªæ ‡ç­¾

<br>ç»“åˆä¸»åŠ¨å­¦ä¹ çš„æŒ‡æ ‡ï¼ŒåŠ¨æ€è°ƒæ•´ä¼ªæ ‡ç­¾çš„é˜ˆå€¼


<br>loss




<br>ä¸»åŠ¨å­¦ä¹ ï¼šä»æ•°æ®é›†ä¸­ä½¿ç”¨æœ€å°‘çš„æœ‰æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒè¾¾åˆ°éœ€è¦çš„æ•ˆæœ<br>ä¸»åŠ¨å­¦ä¹ +2DåŠç›‘ç£ï¼š<a data-href="Active teacher for semi-supervised object detection" href="paper-reading-notes\active-teacher-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Active teacher for semi-supervised object detection</a><br>
<br>è¿­ä»£åœ°ä»æœªæ ‡æ³¨æ•°æ®ä¸­æŒ‘é€‰åŠ å…¥åˆ°æœ‰æ ‡æ³¨æ•°æ®é›†ä¸­
<br>ä½¿ç”¨ä¼ ç»Ÿçš„ä¸»åŠ¨å­¦ä¹ /å›¾åƒç›®æ ‡æ£€æµ‹æŒ‡æ ‡ï¼šdifficultyï¼Œinformationï¼Œdiversity
<br>limitations

<br>æ¨¡å‹éœ€è¦è¿­ä»£åœ°è®­ç»ƒKéï¼Œéœ€è¦kå€çš„è®­ç»ƒæ—¶é—´
<br>å¯¹ä¸åŒé˜¶æ®µä¸åŒdifficultyçš„è®­ç»ƒæ ·æœ¬ä½¿ç”¨ç›¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼æ¥ç­›é€‰ä¼ªæ ‡ç­¾ï¼Œæ²¡æœ‰å¾ˆå¥½ç»“åˆä¸»åŠ¨å­¦ä¹ çš„ä¼˜ç‚¹


<br>3DIoUMatch<br>mAP 0..25<br><br>mAP 0.5<br><br>Exp: ActiveSampler<br>mAP 0..25<br><br>mAP 0.5<br><br><br>å¦‚ä½•åˆ©ç”¨ä¸»åŠ¨å­¦ä¹ çš„æ€æƒ³ï¼Œå°†å…¶èå…¥åˆ°3DåŠç›‘ç£ç›®æ ‡æ£€æµ‹ä¸­ï¼Ÿ<br>ä¸»åŠ¨å­¦ä¹ 2Dç›®æ ‡æ£€æµ‹æŒ‡æ ‡ï¼š<a data-href="Active teacher for semi-supervised object detection" href="paper-reading-notes\active-teacher-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Active teacher for semi-supervised object detection</a><br>difficulty:<br><br>information:<br><br>diversity:<br><br>ç›®å‰ä½¿ç”¨çš„æ€è·¯ï¼š<br>if epoch % update_interval == 0:
    for all samples in unlabeled datasets:
	    model inference
        compute active scores: (diff, info, dive)
    max_normalize(active_scores)
    new_sample_weight &lt;- nonlinear_transform(active_scores)
<br>nonlinear transform: ï¼ˆä½¿å¾—æ ·æœ¬çš„æƒé‡å·®å¼‚ä¸ä¼šè¿‡äºå¤§ï¼ŒæŒ‡æ ‡çš„åˆ†æ•°åªä½¿ç”¨maxå½’ä¸€åŒ–ä½œä¸ºæƒé‡ï¼Œä¼šå¯¼è‡´æƒé‡è¿‡äºåˆ†æ•£ï¼ˆ0.4~1.0ï¼‰ï¼‰<br><br><img alt="Pasted image 20240927160434.png" src="lib\media\pasted-image-20240927160434.png"><br>ç›®å‰çš„å®éªŒæ•ˆæœï¼ˆæµ‹è¯•å•ç‹¬çš„æŒ‡æ ‡ï¼‰<br><br><br>åˆ†æï¼šactive learningçš„æ€æƒ³åœ¨äºä»æ•°æ®é›†ä¸­æŒ‘é€‰æœ€informativeçš„æ ·æœ¬ç»™æ¨¡å‹å­¦ä¹ ã€‚åœ¨ä¸Šé¢åŠç›‘ç£çš„å®éªŒä¸­ï¼Œé€šè¿‡å¯¹unlabeled dataè®¡ç®—active learningæŒ‡æ ‡ï¼Œæ ¹æ®è®¡ç®—å¾—åˆ°çš„æŒ‡æ ‡é«˜ä½èµ‹äºˆæ ·æœ¬é‡‡æ ·æƒé‡ã€‚è¿™ç§resampleçš„æ–¹å¼ï¼Œä½¿å¾—åœ¨ç»è¿‡ä¼ªæ ‡ç­¾ç”Ÿæˆä¹‹åï¼Œæ¨¡å‹ä¼šæ›´å…³æ³¨informativeçš„æ ·æœ¬ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚<br>æ”¹è¿›ï¼šä¼ªæ ‡ç­¾ç­›é€‰è¿‡ç¨‹ä¸­ï¼Œä½äºcls_thresholdå’Œobj_thresholdçš„æ ·æœ¬éƒ½ä¼šè¢«ç­›å‡ºï¼Œå‰åæ ·æœ¬çš„ä¿¡æ¯é‡ä¼šå˜åŒ–ã€‚ä¸¤ç§æ”¹è¿›æ–¹å‘ï¼Œä¸€æ˜¯ä¿®æ”¹è®¡ç®—çš„æŒ‡æ ‡ï¼ŒåŠ å…¥é˜ˆå€¼çš„è€ƒè™‘ï¼ŒäºŒæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¯æ¬¡ç”Ÿæˆä¼ªæ ‡ç­¾åè®¡ç®—æŒ‡æ ‡ï¼ŒåŠ¨æ€è°ƒæ•´æƒé‡ã€‚<br>æ–¹å‘ä¸€ï¼š<br>information:<br><br>ä¿®æ”¹ä¸ºï¼š<br><br>ç¼ºç‚¹æ˜¯åªèƒ½ç”¨äº3DIoUMatch è¿™ç±»ä½¿ç”¨å›ºå®šé˜ˆå€¼çš„æ–¹æ³•ï¼Œä¸å¤Ÿçµæ´»<br>æ–¹å‘äºŒï¼š<br>for epoch in range(max_epoches)
	for each batch:
	    get_pseudo_label
	    compute active scores for each sample
	if epoch % update_interval == 0:
		new_sample_weight &lt;- nonlinear_transform(active_scores)
<br>éœ€è¦è§£å†³ï¼š<br>
<br>é‡å¤å‡ºç°çš„æ ·æœ¬ä¼šæœ‰å¤šä¸ªactive scoresï¼šå–å¹³å‡
<br>æœ‰äº›æ ·æœ¬å¯èƒ½å¹¶æ²¡æœ‰å‡ºç°è¿‡ï¼Œå› æ­¤æ²¡æœ‰active scoresï¼šå–ä¸­å€¼ï¼Ÿ
<br>ä¼˜ç‚¹æ˜¯è¾ƒæ–¹å‘ä¸€ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼ˆæ¨¡å‹ä¸éœ€è¦é¢å¤–åšæ¨ç†ï¼‰<br><br>Bonusï¼š<br>å‘ç°3DIoUMatchå’ŒDiffusionSS3Dåœ¨è®­ç»ƒååŠé˜¶æ®µï¼ˆepoch&gt;500ï¼‰classåˆ†ç±»ä¼šå‡ºç°è¿‡æ‹Ÿåˆç°è±¡ï¼Œè¡¨ç°ä¸ºevalcls_accä¸Šå‡ï¼ŒåŒæ ·çš„é—®é¢˜åœ¨[[Consistent-teacher Towards reducing inconsistent pseudo-targets in semi-supervised object detection]]ä¸­ä¹Ÿæåˆ°è¿‡<br>åœ¨ä½¿ç”¨active æŒ‡æ ‡çš„å®éªŒä¸­ï¼Œè¿‡æ‹Ÿåˆç°è±¡æœ‰ç¼“è§£<br><img alt="W&amp;B Chart 2024_9_27 15_52_46.png" src="lib\media\w&amp;b-chart-2024_9_27-15_52_46.png"><br><img alt="W&amp;B Chart 2024_9_27 15_59_26.png" src="lib\media\w&amp;b-chart-2024_9_27-15_59_26.png"><br><br>Future:<br>
<br>2Dçš„ä¸»åŠ¨å­¦ä¹ æŒ‡æ ‡-&gt;3Dçš„æŒ‡æ ‡ï¼Œæ˜¯å¦éœ€è¦å¢åŠ æˆ–ä¿®æ”¹ï¼Ÿè¦åˆ†æä¸€ä¸‹
<br>difficultçš„æ ·æœ¬ï¼Œæœ‰äº›æ­£ç¡®çš„boxå› ä¸ºconfidenceä½è€Œè¢«å»é™¤ï¼Œæ˜¯å¦å¯ä»¥åˆ©ç”¨activeçš„æŒ‡æ ‡æ¥è°ƒæ•´ä¼ªæ ‡ç­¾ç­›é€‰çš„é˜ˆå€¼ï¼Ÿ
<br><br>adaptive threthold<br>both (t4)               46.9286    27.1209<br>
obj_thre (t6)         46.2200    28.4349<br>
cls_thre(t5)           47.2853    28.0837          <br>no decay <br>scan 0.05<br>
baseline  40.0           22.5<br>
å¤ç°        39.7603     23.1997<br>
å¤ç°2      39.5772     22.3310<br>
obj          40.2493     23.1322<br>
cls           40.3231     23.1570<br>
both        39.7643     22.9632<br>sun 0.01<br>
baseline  21.9           8.0<br>
fuxian      21.3581     7.8691<br>
cls           21.6591     7.7251<br>
obj          17.7722     6.7264<br>reweight_batch<br>scan_0.05     gamma=0.15<br>
fuxian       39.6383      21.6398<br>
all             39.1293      22.5985<br>
obj_cls      40.2029      23.6400<br>sun_0.01     gamma=0.15<br>
obj_cls     23.2249       9.3678<br>
22.9201       8.6029<br>resample+adaptive thresh<br>
cls_thresh_0.1      40.9022    22.9702<br>
cls_thresh_0.3      39.7219    22.2020<br>adaptive thresh_alone<br>cls_thresh_0.3      38.7497    22.4689<br>
384206   227936<br>gamma=0.5<br>
obj_cls      38.6804     21.3836<br>scan_20<br>
3dioumatch     52.8            35.2<br>
obj_cls_0.5       54.3256      35.6095<br><br><br><br><br><a data-href="active_reweight.xlsx" href="results\active_reweight.xlsx" class="internal-link" target="_self" rel="noopener nofollow">active_reweight.xlsx</a>]]></description><link>projects\active&amp;ss3dod.html</link><guid isPermaLink="false">Projects/Active&amp;SS3DOD.md</guid><pubDate>Fri, 22 Nov 2024 08:48:44 GMT</pubDate><enclosure url="lib\media\pasted-image-20240927160434.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240927160434.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Instance-Level Strong Augmentation]]></title><description><![CDATA[ 
 <br>Mix-Teaching: åŠç›‘ç£å•ç›®3dç›®æ ‡æ£€æµ‹<br>crop-and-paste augmentation<br>teacher model<br>
<br>first predict pseudo-labels for unlabeled data by self-training
<br>then split into image patches collection with high-quality pseudo labels and the collection of background images containing no objects
<br>train student model on<br>
<br>empty backgrounds + instance image patches
<br>human labeled images + instance image patches
<br>ä½¿ç”¨ 2D bounding box collision test ç§»é™¤ invalid pastes<br><img alt="Pasted image 20241014151311.png" src="lib\media\pasted-image-20241014151311.png"><br>instance image patch åœ¨å›¾ç‰‡ä¸­çš„ç›¸å¯¹ä½ç½®æ²¡æœ‰æ”¹å˜<br><br>CorrelaBoost: 3dç›®æ ‡æ£€æµ‹<br>mixing approach,  correlation energy field<br>é¦–å…ˆè®¡ç®—æ¯ç±»ä¹‹é—´çš„correlation energy fieldï¼Œç„¶åå°†instance crop and pasteåˆ°åˆé€‚çš„ä½ç½®ä¸Šï¼ˆlow energyï¼‰<br>å¼•å…¥äº†ç±»é—´å®ä¾‹ç›¸å¯¹ä½ç½®å…³ç³»å…ˆéªŒ<br>
<br>Category Consistent Exchangingï¼šäº¤æ¢ç›¸åŒç±»åˆ«ï¼Œå¹¶ä¸”å¤§å°ã€æœå‘ç›¸ä¼¼çš„ä¸¤ä¸ªå®ä¾‹
<br>Energy Optimized Transformationï¼šå°†ä¸€ä¸ªå®ä¾‹ç§»åŠ¨åˆ°å¦ä¸€ä¸ªå¯èƒ½åˆé€‚çš„ä½ç½®ä¸Š
<br><br><br><br><br>ç›®å‰çš„3DåŠç›‘ç£ç›®æ ‡æ£€æµ‹æ–¹æ³•ï¼ˆSESS. 2020; 3DIoUMatch, 2021; DiffusionSS3D, 2023ç­‰ï¼‰ï¼Œä½¿ç”¨scene-levelçš„æ•°æ®å¢å¼ºæ–¹å¼ï¼ŒåŒ…æ‹¬ scalingï¼Œrotationï¼Œflippingå’Œjitteringæ¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚<br>åœ¨3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œä¸€äº›æ–¹æ³•ï¼ˆYan et al. 2018; Sun et al. 2022ï¼‰æå‡ºåˆ©ç”¨instance-levelçš„mixingæ•°æ®å¢å¼ºæ–¹å¼ï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸”å–å¾—äº†å¯è§‚çš„æå‡ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™ç±»æ–¹æ³•ä»training datasetä¸­æ”¶é›†ç›®æ ‡å®ä¾‹ï¼Œåˆ›å»ºäº†ä¸€ä¸ªinstance databaseï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»training databaseä¸­é€‰æ‹©ground truth instanceï¼Œæ·»åŠ åˆ°å½“å‰è®­ç»ƒçš„ç‚¹äº‘ä¸­ã€‚<br>ä½†æ˜¯åœ¨åŠç›‘ç£ä»»åŠ¡ä¸­ï¼Œstudentæ¨¡å‹ä½¿ç”¨ç»è¿‡å¼ºæ•°æ®å¢å¼ºçš„labeledæ•°æ®å’Œunlabelledæ•°æ®ï¼Œåœ¨labeledæ•°æ®ä¸Šçš„instance-levelçš„æ•°æ®å¢å¼ºæ–¹æ³•æ— æ³•ç›´æ¥ç”¨äºunlabelledæ•°æ®ä¸Šï¼Œå› ä¸ºunlabelledæ•°æ®ä¸­ä¸å­˜åœ¨ground truth instanceï¼Œä¸”ä¼ªæ ‡ç­¾çš„bboxæœ‰æ—¶å¹¶ä¸å¯é ï¼›å¦å¤–ï¼ŒåŠç›‘ç£ä»»åŠ¡ä¸‹ï¼Œmixingå¯ä»¥ä¸å±€é™äºå•ç‹¬åœ¨labeledæˆ–unlabelledæ•°æ®ä¸­ï¼Œä¹Ÿå¯ä»¥åº”ç”¨åœ¨äºŒè€…é—´ã€‚<br>æœ¬å·¥ä½œæ—¨åœ¨ç ”ç©¶instance-level data augmentationåœ¨3DåŠç›‘ç£ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œæå‡ºé€‚ç”¨äºè¯¥ä»»åŠ¡ä¸‹çš„å¯é æœ‰æ•ˆæ–¹æ³•ã€‚<br><br><br>æ ¹æ®databaseå®ä¾‹çš„æ¥æºå’Œå¢å¼ºçš„æ•°æ®é›†ï¼Œmixingå¯èƒ½çš„å¢å¼ºæ–¹å¼å¯ä»¥åˆ†ä¸ºï¼š<br>
<br>ground truth instance --&gt; labeled scene
<br>ground truth instance --&gt; unlabeled scene
<br>pseudo instance --&gt; labeled scene
<br>pseudo instance --&gt; unlabeled scene
<br>å…¶ä¸­ï¼Œç¬¬ä¸€ç§æ–¹æ³•ä¸å…¨ç›‘ç£æƒ…æ™¯å®Œå…¨ç›¸åŒï¼Œä½†åœ¨åŠç›‘ç£ä»»åŠ¡ä¸­æ•ˆæœæœ‰é™ã€‚å› ä¸ºæ ‡æ³¨æ ·æœ¬ç¨€å°‘ï¼ˆsun-rgbd 5%æ•°æ®ä¸‹ï¼Œground truth instanceæ•°é‡åªæœ‰200å·¦å³ï¼‰ï¼Œåªåœ¨æ ‡æ³¨æ•°æ®ä¸­åšmixæ•°æ®å¢å¼ºæœ‰æ•ˆçš„mixæ•°é‡å¾ˆå°‘ã€‚<br><br>ä¸ç¬¬ä¸€ç§æ–¹å¼ç›¸ä¼¼ï¼Œåªæ˜¯å¢å¼ºçš„ç›®æ ‡æ•°æ®ä¸ºunlabeled scene<br>ç®€è¦æ­¥éª¤ï¼š<br>
<br>éå†æœ‰æ ‡æ³¨æ•°æ®é›†ï¼Œæ ¹æ®æ ‡ç­¾åˆ›å»ºground truth dataset
<br>åœ¨è®­ç»ƒæ—¶ï¼Œæ¯æ¬¡datasetè¯»å–æ•°æ®æ—¶ï¼Œæ¦‚ç‡pè¿›è¡Œmixå¢å¼ºè¾“å…¥ç»™studentæ¨¡å‹ï¼Œteacherä½¿ç”¨æœªå¢å¼ºçš„æ•°æ®ç”Ÿæˆä¼ªæ ‡ç­¾
<br>
mixå¢å¼ºåçš„æ•°æ®æ˜¯å¦éœ€è¦è¾“å…¥ç»™teacherï¼Ÿ
<br>
ç²˜è´´ä½ç½®çš„é€‰æ‹©ï¼Œé¿å…é‡åˆã€ç¢°æ’ â€”â€”&gt; è®¾è®¡ collision test
<br>
ä¸ä»…éœ€è¦é¿å…ç¢°æ’ï¼Œè¿˜éœ€è¦é¿å…ä¸å…¶ä»–ç‰©ä½“è·ç¦»è¿‡è¿œ
<br><br>ä¸ground truth instance ä¸åŒï¼Œä½¿ç”¨pseudo instanceä¼šæœ‰é—®é¢˜ã€‚å½“æ¨¡å‹ä¸€å¼€å§‹å­¦ä¹ æ•ˆæœä¸å¥½æ—¶ï¼Œå¯èƒ½ä¼šå‡ºç°clsã€objectç½®ä¿¡åº¦éƒ½å¾ˆé«˜ï¼Œä½†æ˜¯è¾¹ç•Œæ¡†èŒƒå›´ä¸å‡†ï¼Œä½¿ç”¨ä¸å‡†çš„boxä¼šäº§ç”Ÿä¸å®Œæ•´çš„ç›®æ ‡ç‰©ä½“ã€‚<br>
ä½¿ç”¨å¤šä¸ªproposalçš„boxèŒƒå›´å–å¹¶é›†ï¼Œé¿å…äº§ç”Ÿä¸å®Œæ•´ç›®æ ‡
<br>ç”±äºlabeled sceneä¸­åŒ…å«ground truthçš„bboxï¼Œç›¸æ¯”unlabeled sceneï¼Œæœ‰ä¸¤ç§å¯èƒ½çš„mixæ–¹å¼ï¼š<br>
<br>æ·»åŠ åˆ°åœºæ™¯ä¸­ä¸€ä¸ªæ–°çš„ä½ç½®ä¸­ï¼ˆä¸ unlabeled sceneæ–¹å¼ç›¸åŒï¼‰
<br>æ›¿æ¢åœºæ™¯ä¸­çš„ä¸€ä¸ªç›¸åŒclassçš„ç‰©ä½“
<br>æ›¿æ¢çš„ä¸¤ä¸ªç‰©ä½“çš„sizeä¸ç›¸åŒï¼Œç›´æ¥æ›¿æ¢ä¼šä¸ç›¸é‚»ç‰©ä½“äº§ç”Ÿç¢°æ’ã€‚ï¼ˆSun et al. 2022ï¼‰ä¸­é€šè¿‡è®¡ç®—ï¼ˆlï¼Œwï¼Œhï¼‰çš„ä½™å¼¦ç›¸ä¼¼åº¦æ¥é€‰æ‹©å½¢çŠ¶ç›¸è¿‘çš„ç‰©ä½“ã€‚ï¼ˆè¯•ä¸€ä¸‹ï¼Œå¦‚æœä¼ªæ ‡ç­¾æ•°é‡è¿‡å°‘å¯èƒ½æ²¡æœ‰åŒ¹é…çš„å½¢çŠ¶ï¼‰ã€‚<br>å¦ä¸€ç§å¯èƒ½çš„æ–¹å¼æ˜¯ä½¿ç”¨resizeæ¥fitï¼Œ<br><img alt="Pasted image 20241021191415.png" src="lib\media\pasted-image-20241021191415.png"><br><br>å°†pseudo instanceæ”¾å›åˆ°æœªæ ‡æ³¨åœºæ™¯ä¸­ï¼Œmixçš„æ–¹å¼åŒ ground truth instance â€”&gt; unlabeled scene; pseudo instance boxçš„èŒƒå›´åŒpseudo instance â€”&gt; labeled scene<br><br><br><a data-href="SECOND_ Sparsely embedded convolutional detection" href="paper-reading-notes\second_-sparsely-embedded-convolutional-detection.html" class="internal-link" target="_self" rel="noopener nofollow">SECOND_ Sparsely embedded convolutional detection</a><br><a data-href="Correlation field for boosting 3D object detection in structured scenes" href="paper-reading-notes\correlation-field-for-boosting-3d-object-detection-in-structured-scenes.html" class="internal-link" target="_self" rel="noopener nofollow">Correlation field for boosting 3D object detection in structured scenes</a><br><br><br><br>centeråæ ‡å¯¹é½ä¿®æ­£<br><br>åœ¨ augment_helper_10_31_1.py åŸºç¡€ä¸Š<br>
å¯†åº¦ã€ç‚¹äº‘æ•°é‡ç­›é€‰æ¨¡å—ï¼šline 720-722<br><br>ä¸ä¿æŒmix instance å‰åæ€»æ•°é‡ä¸å˜ï¼Œè€Œæ˜¯gt A% + pseudo (1-A)% &gt;=N ï¼Œç„¶ååœ¨æ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘é‡é‡‡æ ·åˆ°40000ï¼Œä¸å¸¦å¯†åº¦ç­›é€‰æ¨¡å—<br><br>åœ¨ augment_helper_11_01_3.py åŸºç¡€ä¸Šï¼Œä» æ¯ä¸ªæ ·æœ¬ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªä¼ªæ ‡ç­¾mixup æ”¹ä¸º å¢åŠ æ¯ä¸ªæ ·æœ¬ä¼ªæ ‡ç­¾mixupæ•°é‡çš„æ¯”ä¾‹ï¼Œè®¾å®šä¸º0.5ï¼šline 745<br><br>Aï¼šmixup instance ç‚¹æ•°çº¦æŸï¼ˆgt A% + pseudo (1-A)% &gt;=N ï¼‰<br>
Bï¼špseudo instance å¯†åº¦ã€ç‚¹äº‘ç‚¹æ•°ç­›é€‰æ¨¡å—<br>
Cï¼šæ¯ä¸ªåœºæ™¯å¤šä¸ª mixup pseudo instance / å•ä¸ª<br><br><br><br>3DIoUMatch<br>sunrgbd<br>
<br>1%: 1d
<br>5%: 2d
<br>10%: 3d
<br>20%: 6d
<br>scannet<br>
<br>5%: 6h
<br>10%: 12h
<br>20%: 1d
<br>å•æ¬¡å®éªŒæ€»æ—¶é—´ï¼š7.75d<br>mixupç­–ç•¥æ¶ˆèå®éªŒæ€»æ—¶é—´ï¼š6  (scan5%) + 6  (sun 1%) = 7.5d<br>mixup_ratio æ¯”ä¾‹è°ƒä¼˜(0.3, 0.5, 0.7, 1.0)ï¼š3  (scan5%)  + 3  (sun1%)= 3.75d <br><br>å•å¡æ€»æ—¶é—´ï¼š17.5d<br><br><br>ground truth instance â€”&gt; unlabeled scene,ï¼Œéšæœºä½ç½®ï¼Œåªæœ‰studentä½¿ç”¨mixåæ ·æœ¬<br>
<br>4090 GPU1
<br>LOG_DIR="results/train/exp_mix_random/scan_0.1"
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2 v4
<br>results | map 0.25 | map 0.50<br>
v1 | 49.0086 | 27.7310<br>
v2 | 47.2400 | 29.0669<br>
v4 | 50.6233 | 30.5021<br><br>ground truth instance â€”&gt; unlabeled scene,ï¼Œéšæœºä½ç½®ï¼Œåªæœ‰studentä½¿ç”¨mixåæ ·æœ¬<br>
<br>4090 GPU0
<br>LOG_DIR="results/train/exp_mix_random/sun_0.05"
<br>DATASET=sunrgbd_0.05
<br>VERSION=v4 v7 v8
<br>results | map 0.25 | map 0.50<br>
v4 | 42.1826 | 24.5071<br>
v7 | 42.5572 | 23.2031<br>
v8 | <br><br>scannet 10% è®­ç»ƒæ—¶é—´å¼‚å¸¸ï¼Œä¸ä½¿ç”¨æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¯¹æ¯”æ—¶é•¿ã€‚<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/debug_time/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1
<br>æ¯epochè€—æ—¶25s<br><br>ground truth instance â€”&gt; unlabeled scene,ï¼Œé™„è¿‘ç©ºä½ç½®ï¼Œåªæœ‰studentä½¿ç”¨mixåæ ·æœ¬<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mix_empty/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2 v4
<br>results | map 0.25 | map 0.50<br>
v1 | 48.2659 | 28.0515<br>
v2 | 47.4078 | 28.9533<br>
v4 | 48.5970 | 28.9941<br><br>ground truth instance â€”&gt; unlabeled sceneï¼Œé™„è¿‘ç©ºä½ç½®ï¼Œåªæœ‰studentä½¿ç”¨mixåæ ·æœ¬<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mix_empty/sun_0.05
<br>DATASET=sunrgbd_0.05
<br>VERSION=v4 v7 v8
<br>results | map 0.25 | map 0.50<br>
v4 | 42.0110 | 25.2361<br>
v7 | 41.2513 | 24.0500<br>
v8 | 41.3347 | 21.0572<br><br>å‰é¢çš„æ•ˆæœä¸å¤ªå¥½ï¼ŒéªŒè¯ä¸åŒå¡çš„æ•ˆæœ<br>
ground truth instance â€”&gt; unlabeled scene,ï¼Œé™„è¿‘ç©ºä½ç½®ï¼Œåªæœ‰studentä½¿ç”¨mixåæ ·æœ¬<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mix_empty/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2 v4
<br>results | map 0.25 | map 0.50<br>
v1 | 48.2249 | 28.7654<br>
v2 | 46.9337 | 28.1312<br>
v4 | 49.6711 | 29.4796<br><br>pseudo instance â€”&gt; labeled scene, add empty<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mix_pseudo_empty/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2 v4
<br>results | map 0.25 | map 0.50<br>
v1 | 48.6067 | 28.5803<br>
v2 | 46.4287 | 27.9852<br>
v4 | 48.6594 | 27.1702<br><br>é€‰æ‹©ç©ºä½ç½®æ•ˆæœåè€Œä¸å¥½ï¼Œéš¾é“æ˜¯æœ‰å¤ªå¤šæ ·æœ¬ä¸­æ‰¾ä¸åˆ°åˆé€‚çš„ä½ç½®ï¼Ÿ<br>ground truth instance â€”&gt; unlabeled scene,ï¼Œé™„è¿‘ç©ºä½ç½®ï¼Œå¦‚æœæ‰¾ä¸åˆ°ç©ºä½ç½®ï¼Œä½¿ç”¨éšæœºä½ç½®ï¼Œåªæœ‰studentä½¿ç”¨mixåæ ·æœ¬<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mix_empty/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2 v4
<br>v2 | 46.9337 | 28.1312<br>
v4 | 49.6711 | 29.4796<br><br>mixup ç­–ç•¥1<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup_1/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v1 | 48.7984 | 28.3462<br>
v2 | 46.3598 | 28.1137<br>
v4 | 48.2726 | 28.6435<br><br>mixup ç­–ç•¥2<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup_2/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_2_scan_1.sh
<br>v1 | 48.1797 | 29.0132<br>
v2 | 48.4467 | 28.9935<br><br>mixup ç­–ç•¥3<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup_3/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_3_scan_1.sh
<br>v1 | 49.3566 | 27.8274<br>
v2 | 46.0526 | 28.2909<br><br>æ˜¨å¤©çš„ä»£ç æœ‰é”™è¯¯ï¼Œæ··åˆç‚¹äº‘çš„æ—¶å€™æ²¡æœ‰å¯¹é½centeråæ ‡ï¼›åŠ å…¥å¯†åº¦ã€ç‚¹äº‘æ•°é‡è¿›ä¸€æ­¥ç­›é€‰éœ€è¦mixupçš„ä¼ªæ ‡ç­¾<br>mixup ç­–ç•¥1<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup_1_2/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v1 | 48.2789 | 29.9236<br>
v2 | 46.0034 | 28.9876<br><br>mixup ç­–ç•¥2<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup_2_2/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_2_scan_1.sh
<br>v1 | 48.0871 | 28.4064<br>
v2 | 47.6146 | 28.3722<br><br>mixup ç­–ç•¥3<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup_3_2/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v2 v4
<br>SCRIPT=exp_mixup_3_scan_1.sh
<br>v1 | 46.6500 | 27.3655<br>
v4 | 47.5137 | 28.2747<br><br>ä¿®æ”¹äº†mixå‰åç‚¹äº‘æ•°é‡ï¼Œä¸ä¿æŒæ€»æ•°é‡ä¸å˜ï¼Œè€Œæ˜¯gt A% + pseudo (1-A)% &gt;=N ï¼Œç„¶ååœ¨æ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘é‡é‡‡æ ·åˆ°40000ï¼Œä¸å¸¦æ˜¨å¤©çš„å¯†åº¦ç­›é€‰æ¨¡å—<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_3.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/d767puqv" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/d767puqv" target="_blank">wandb</a><br>mixup ç­–ç•¥1<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup_1_3/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 |  40.0947 | 22.5539<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/ynct7qb6" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/ynct7qb6" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥1<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup_1_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_1_scan_1.sh
<br>v4 | 42.5278 | 23.6537<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_3.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/l4rvay5x" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/l4rvay5x" target="_blank">wandb</a><br>mixup ç­–ç•¥2<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup_2_3/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 | 40.2911 | 22.7576<br>
v6 | 39.6959 | 22.9028<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/6b4z9z07" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/6b4z9z07" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥2<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup_2_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_2_scan_1.sh
<br>v4 |  41.6675 | 23.8388<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/hb7vsdkx" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/hb7vsdkx" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥3<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup_3_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_3_scan_1.sh
<br>v4 |  42.2338 | 23.6369<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_3.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/n50e0lvf" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/n50e0lvf" target="_blank">wandb</a><br>mixup ç­–ç•¥3<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup_3_3/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_3_scan_1.sh
<br>v4 | 40.1940 | 23.8254<br><br>å¯¹ç…§è¯•éªŒ<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_10_31_1.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/nmvutlp5" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/nmvutlp5" target="_blank">wandb</a><br>mixup ç­–ç•¥1<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup1_10_31_1/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 |  37.6985 | 22.8207<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_02_1.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/m35ailcc" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/m35ailcc" target="_blank">wandb</a><br>mixup ç­–ç•¥1<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup1_11_02_1/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_1_scan_1.sh
<br>v4 |  41.5972 | 23.4578<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_02_1.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/vf5wznux" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/vf5wznux" target="_blank">wandb</a><br>mixup ç­–ç•¥2<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup2_11_02_1/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_2_scan_1.sh
<br>v4 |  39.7267 | 22.9489<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_02_1.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/ltthhqd6" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/ltthhqd6" target="_blank">wandb</a><br>mixup ç­–ç•¥3<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup3_11_02_1/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_3_scan_1.sh
<br>v4 |  40.0779 | 23.7552<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/5fkg2s3i" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/5fkg2s3i" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥1|2|3<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup123_11_01_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 | 42.9969 | 24.0625<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/nwv8phjx" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/nwv8phjx" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥1&amp;2&amp;3<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup1-2-3_11_01_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_1-2-3_scan_1.sh
<br>v4 | 41.5698 | 22.8128<br><br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/heb8nd92" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/heb8nd92" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥1|2|3<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup123_11_01_4/sun_0.05
<br>DATASET=sunrgbd_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_sun.sh
<br>v4 | 42.3491 | 25.9211<br>å¾…ç™»è®°<br><br>æ¶ˆèå®éªŒ mixup 1&amp;2<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/i1e0effp" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/i1e0effp" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥1|2|3<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup12_11_01_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 | 41.5024 | 24.1251<br><br>æ¶ˆèå®éªŒ mixup 1&amp;3<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/vs8iykuu" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/vs8iykuu" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥1|3<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup13_11_01_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 | 40.6122 | 23.4175<br>
v6 | 41.9697 | 22.2207<br><br>æ¶ˆèå®éªŒ mixup 2&amp;3<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>
å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/zb9h7aka" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Active_Sampler_train/runs/zb9h7aka" target="_blank">wandb</a><br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5
<br>mixup ç­–ç•¥2|3<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup23_11_01_4/scan_0.05
<br>DATASET=scannet_0.05
<br>VERSION=v4
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>v4 | 41.5220 | 23.3983<br>
v6 | 40.6888 | 24.3937<br><br>mixup_ratioå‚æ•°çµæ•åº¦åˆ†æ<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=1.0, 0.7, 0.3
<br>mixup ç­–ç•¥1|2|3<br>
<br>
4060T GPU0

<br>
LOG_DIR=results/train/ablation_mixup123/mixup_ratio/

<br>
DATASET=scannet_0.05

<br>
VERSION=v4

<br>
SCRIPT=ablation_mixup_123_mixup_ratio_scan.sh
1.0 | 41.2398 | 22.6567<br>
0.7 | 42.4988 | 23.4858<br>
0.3 | 40.4732 | 22.6708

<br><br>Diffusion-SS3D sunrgbd é¢„è®­ç»ƒå¤ç°<br>å¯è§†åŒ–ï¼š<a data-tooltip-position="top" aria-label="https://wandb.ai/3265168281-south-china-university-of-technology/Diffusion-SS3D_pretrain_0.01/runs/tw7jejbu" rel="noopener nofollow" class="external-link" href="https://wandb.ai/3265168281-south-china-university-of-technology/Diffusion-SS3D_pretrain_0.01/runs/tw7jejbu" target="_blank">wandb</a><br>
<br>4090 GPU0
<br>LOG_DIR=results/pretrain/sun_0.01/v4/
<br>DATASET=sunrgbd_0.01
<br>VERSION=v4
<br>SCRIPT=pretrain_sun.sh
<br>v4 | <br><br>mixup_ratioå‚æ•°çµæ•åº¦åˆ†æ<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=1.0, 0.5, 0.7, 0.3
<br>mixup ç­–ç•¥1|2|3<br>
<br>
4060T GPU0

<br>
LOG_DIR=results/train/ablation_mixup123/mixup_ratio/

<br>
DATASET=sunrgbd_0.01

<br>
VERSION=v7

<br>
SCRIPT=ablation_mixup_123_mixup_ratio_sun.sh
1.0 | 23.5746 | 9.1484<br>
0.7 | 21.1248 | 7.9669<br>
0.5 | 22.9031 | 8.7449<br>
0.3 | 22.8716 | 8.1766

<br><br>Diffusion-SS3D scannet 0.1 0.2 é¢„è®­ç»ƒ<br>
<br>4090 GPU1
<br>LOG_DIR=results/pretrain/
<br>DATASET=scannet
<br>SCRIPT=pretrain_scan_0.1_0.2.sh
<br>scannet_0.1_v1 |<br>
scannet_0.2_v2 | <br><br>ISA-Diffusion-SS3D on scan 0.05<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/scan_0.1
<br>DATASET=scannet
<br>SCRIPT=train_scan.sh
<br><br>mixup_ratioå‚æ•°çµæ•åº¦åˆ†æ<br>ç­–ç•¥æ–‡ä»¶ï¼šaugment_helper_11_01_4.py<br>è¶…å‚æ•°ï¼š<br>
<br>ä¼ªæ ‡ç­¾mixupæ¯”ä¾‹=0.5, 0.7, 1.0
<br>mixup ç­–ç•¥1|2|3<br>
<br>
4060T GPU0

<br>
LOG_DIR=results/train/ablation_mixup123/mixup_ratio/

<br>
DATASET=sunrgbd_0.01

<br>
VERSION=v10

<br>
SCRIPT=ablation_mixup_123_mixup_ratio_sun.sh
1.0 | 26.1401 | 10.9358<br>
0.7 | 27.3297 | 12.0621<br>
0.5 | 27.5041 | 11.4116

<br><br>]]></description><link>projects\instance-level-strong-augmentation.html</link><guid isPermaLink="false">Projects/Instance-Level Strong Augmentation.md</guid><pubDate>Fri, 22 Nov 2024 07:25:59 GMT</pubDate><enclosure url="lib\media\pasted-image-20241014151311.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241014151311.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Time-Efficient SSL]]></title><description><![CDATA[ 
 <br><br><br><br>åœ¨åŠç›‘ç£å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ç¬¬ä¸€æ­¥åœ¨éƒ¨åˆ†æ ‡æ³¨çš„æ ·æœ¬ä¸Šè¿›è¡Œæœ‰ç›‘ç£çš„é¢„è®­ç»ƒï¼Œç¬¬äºŒæ­¥åŒæ—¶åœ¨æœ‰æ ‡æ³¨å’Œæ— æ ‡æ³¨æ ·æœ¬ä¸Šè®­ç»ƒã€‚<br>åœ¨3DåŠç›‘ç£ç›®æ ‡æ£€æµ‹è®­ç»ƒä¸­ï¼Œå‘ç°3DIoUMatchå’ŒDiffusion-SS3Dåœ¨å„ç§æ¯”ä¾‹åˆ’åˆ†ä¸‹ï¼Œåœ¨ç¬¬äºŒæ­¥åŠç›‘ç£è®­ç»ƒå¼€å§‹ï¼ˆå‰200epochï¼‰ï¼Œéƒ½ä¼šå‡ºç°è¿‡æ‹Ÿåˆç°è±¡ã€‚è¡¨ç°ä¸ºtrain losséƒ½ä¸‹é™ï¼Œè€Œeval lossä¸Šå‡ï¼ŒmAPé™ä½ã€‚<br>
<br>è¿™ç§ç°è±¡åœ¨åŠç›‘ç£è®­ç»ƒä»»åŠ¡ä¸­æ˜¯æ™®éå­˜åœ¨çš„å—ï¼Ÿå’Œå®¤å†…å®¤å¤–çš„æ•°æ®é›†æœ‰å…³ç³»å—ï¼Ÿéœ€è¦æ¯”è¾ƒ2Då’Œ3Dåˆ†ç±»ï¼Œæ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡çš„è®­ç»ƒè¿‡ç¨‹ã€‚
<br>ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å¼çœŸçš„é«˜æ•ˆå—ï¼Ÿéœ€è¦æ‰¾åˆ°å“ªå‡ ç¯‡æ–‡ç« é¦–å…ˆä½¿ç”¨é¢„è®­ç»ƒçš„æ–¹æ³•çš„ï¼Œä¸ºä»€ä¹ˆä½¿ç”¨é¢„è®­ç»ƒã€‚
<br>èƒ½å¦æå‡ºä¸€ç§æ–¹æ³•ï¼Œè®©æ¨¡å‹æ€§èƒ½èƒ½å¤Ÿéšç€è®­ç»ƒepochç¨³å®šæå‡ï¼Œä½¿å¾—ç”¨æ›´å°‘çš„è®­ç»ƒæ—¶é—´ï¼Œè¾¾åˆ°ç›¸åŒç”šè‡³æ›´å¥½çš„æ•ˆæœï¼Ÿå€Ÿé‰´æ¨¡å‹å¾®è°ƒçš„æ€è·¯ã€‚ 
<br><br>åˆ—å‡ºç›¸å…³çš„å‚è€ƒæ–‡çŒ®åŠå…¶ä¸»è¦è§‚ç‚¹ã€‚<br><br><br>å®ç°æ€è·¯<br><br><br><br><br><br><br><br><br><br><br><br><br>]]></description><link>projects\time-efficient-ssl.html</link><guid isPermaLink="false">Projects/Time-Efficient SSL.md</guid><pubDate>Fri, 22 Nov 2024 12:49:11 GMT</pubDate></item><item><title><![CDATA[å·¥ä½œè®¡åˆ’ï¼ˆ2024å¹´11æœˆ-2025å¹´3æœˆï¼‰]]></title><description><![CDATA[ 
 <br><br><br><br>é¡¹ç›®èƒŒæ™¯ï¼šåœ¨ä¸Šä¸€ä¸ªå·¥ä½œä¸­ç§¯ç´¯äº†å¤§é‡çš„ä»£ç ç‰‡æ®µï¼ˆå¦‚æ¨ç†ç»“æœå¯è§†åŒ–ç­‰ï¼‰ï¼Œåˆ†æ•£çš„ä»£ç é™ä½äº†åç»­ç ”ç©¶çš„æ•ˆç‡ã€‚ <br>ç›®æ ‡ï¼šæ•´ç†å·²æœ‰ä»£ç ï¼Œæå–å¯èƒ½é‡å¤ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å—ï¼Œå°è£…æˆä¸€ä¸ªæ˜“ç”¨çš„PythonåŒ…ã€‚ <br>å·¥ä½œè®¡åˆ’ï¼š <br>
<br>æ¢³ç†ç ”ç©¶ä¸­é‡å¤ä½¿ç”¨çš„ä»£ç ï¼ˆå¦‚æ¨ç†ç»“æœå¯è§†åŒ–ã€æ•°æ®é¢„å¤„ç†ç­‰ï¼‰ã€‚
<br>è®¾è®¡å¹¶å®ç°ç»Ÿä¸€çš„æ¥å£ï¼Œå°è£…ä¸ºåŠŸèƒ½æ¨¡å—ã€‚ 
<br>ç®—åŠ›éœ€æ±‚ï¼š <br>
<br>æ¶‰åŠå¯è§†åŒ–å’Œæ¨ç†ï¼Œéœ€è¦1å¼ 4090 GPUï¼Œçº¦2å‘¨ã€‚
<br><br>é¡¹ç›®èƒŒæ™¯ï¼šåœ¨3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œå‘ç°åŒä¸€åœºæ™¯çš„ä¸åŒæ‰«æç»“æœ æ¨¡å‹æ¨ç†è¡¨ç°å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œå³ä¾¿æœ‰ä¸€è‡´æ€§çº¦æŸï¼Œä»æ— æ³•æ˜¾è‘—æ”¹å–„é²æ£’æ€§ã€‚ <br>ç ”ç©¶ç›®æ ‡ï¼šåˆ†æåœºæ™¯æ‰«æå·®å¼‚å¯¹æ¨ç†ç»“æœçš„å½±å“ï¼Œå°è¯•é€šè¿‡å®ä¾‹å¯¹é½æˆ–é²æ£’æ€§è®­ç»ƒç­–ç•¥æ”¹è¿›æ¨¡å‹è¡¨ç°ã€‚  <br>å·¥ä½œè®¡åˆ’ï¼š<br>
<br>å¯¹ä¸åŒçš„æ•°æ®é›†ï¼ˆScanNetã€SUN RGB-Dï¼‰ä½¿ç”¨åŒä¸€ä¸ªæ¨¡å‹å¯¹åŒä¸€åœºæ™¯ä¸‹ä¸åŒé‡‡æ ·çš„æ•°æ®è¿›è¡Œæ¨ç†ï¼Œå¯¹æ¯”æ¨ç†ç»“æœçš„å·®å¼‚ã€‚
<br>éªŒè¯ç°æœ‰æ–¹æ³•æ˜¯å¦éƒ½æœ‰è¿™ä¸ªé—®é¢˜ã€‚
<br>ç®—åŠ›éœ€æ±‚ï¼š<br>
<br>1å¼ 4090 GPUï¼Œçº¦2å‘¨ã€‚
<br><br><br>é¡¹ç›®èƒŒæ™¯ï¼šåœ¨åŠç›‘ç£è®­ç»ƒåˆæœŸï¼Œ3DIoUMatchå’ŒDiffusion-SS3Dæ¨¡å‹å‡è¡¨ç°å‡ºè¿‡æ‹Ÿåˆç°è±¡ï¼Œè¡¨ç°ä¸ºtrain lossä¸‹é™è€Œeval lossä¸Šå‡ã€‚  <br>ç ”ç©¶ç›®æ ‡ï¼šåˆ†æè¿™ç§ç°è±¡åœ¨ä¸åŒä»»åŠ¡å’Œæ•°æ®é›†ä¸Šçš„æ™®éæ€§ï¼Œå¹¶éªŒè¯æ˜¯å¦ä¸é¢„è®­ç»ƒç­–ç•¥æœ‰å…³ã€‚  <br>å·¥ä½œè®¡åˆ’ï¼š<br>
<br>æ”¶é›†2Då’Œ3Dåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ä»»åŠ¡çš„ç›¸å…³å®éªŒæ•°æ®ã€‚
<br>åˆ†æè¿‡æ‹Ÿåˆç°è±¡æ˜¯å¦ä¸ä»»åŠ¡ç±»å‹å’Œæ•°æ®é›†æœ‰å…³ã€‚
<br>å¤ç°ç›¸å…³è®ºæ–‡ï¼Œç¡®è®¤é¢„è®­ç»ƒç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚
<br>åˆæ­¥å°è¯•é€šè¿‡åŠ¨æ€å­¦ä¹ ç‡ã€æŸå¤±è°ƒæ•´ç­‰æ–¹æ³•ç¼“è§£è¿‡æ‹Ÿåˆã€‚
<br>ç®—åŠ›éœ€æ±‚ï¼š<br>
<br>æ•°æ®åˆ†æåŠå®éªŒå¤ç°ï¼š2å¼ 4090 GPUï¼Œçº¦1ä¸ªæœˆã€‚
<br><br><br><br>é¡¹ç›®èƒŒæ™¯ï¼šç°æœ‰åŠç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨æ€§èƒ½æå‡å’Œè®­ç»ƒæ—¶é—´æ•ˆç‡ä¹‹é—´éš¾ä»¥å¹³è¡¡ï¼Œéœ€è®¾è®¡æ–°æ–¹æ³•æå‡æ€§èƒ½çš„åŒæ—¶å‡å°‘è®­ç»ƒæ—¶é—´ã€‚  <br>ç ”ç©¶ç›®æ ‡ï¼šå€Ÿé‰´å¾®è°ƒç­–ç•¥ï¼Œæå‡ºä¸€ç§ç¨³å®šæå‡æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ï¼Œå®ç°æ›´é«˜æ•ˆçš„åŠç›‘ç£å­¦ä¹ ã€‚  <br>å·¥ä½œè®¡åˆ’ï¼š<br>
<br>è°ƒç ”å¾®è°ƒç­–ç•¥åœ¨åŠç›‘ç£å­¦ä¹ ä¸­çš„æ½œåœ¨åº”ç”¨åœºæ™¯ã€‚
<br>è®¾è®¡ç»“åˆå¾®è°ƒæ€è·¯çš„é«˜æ•ˆåŠç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚
<br>ç³»ç»Ÿå®éªŒéªŒè¯æ–°æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿åœ¨è®­ç»ƒæ—¶é—´å’Œæ€§èƒ½ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
<br>æ’°å†™æœ€ç»ˆè®ºæ–‡ã€‚
<br>ç®—åŠ›éœ€æ±‚ï¼š<br>
<br>æ¨¡å‹è®­ç»ƒåŠæ€§èƒ½éªŒè¯ï¼š4å¼ 4090 GPUï¼Œçº¦2ä¸ªæœˆã€‚
<br><br><br>
<br>æ—¶é—´æ®µä¸€ï¼šæ•°æ®é¢„å¤„ç†ä¸æ¨¡å‹è®­ç»ƒå…±è®¡2å¼ 4090 GPUï¼Œé¢„è®¡2ä¸ªæœˆã€‚
<br>æ—¶é—´æ®µäºŒï¼šæ–¹æ³•è®¾è®¡ä¸éªŒè¯å…±è®¡4å¼ 4090 GPUï¼Œé¢„è®¡2ä¸ªæœˆã€‚
]]></description><link>reports\å·¥ä½œè®¡åˆ’ï¼ˆ2024å¹´11æœˆ-2025å¹´3æœˆï¼‰.html</link><guid isPermaLink="false">Reports/å·¥ä½œè®¡åˆ’ï¼ˆ2024å¹´11æœˆ-2025å¹´3æœˆï¼‰.md</guid><pubDate>Fri, 22 Nov 2024 13:16:55 GMT</pubDate></item><item><title><![CDATA[Active Learning]]></title><description><![CDATA[ 
 <br>ä¸€èˆ¬åªè®¨è®º pool-based AL<br>batch mode AL<br>
stream-based AL<br><br>
<br>è¿­ä»£åœ°é€‰æ‹©æœ€informativeçš„data
<br>acquisition function 
<br>Querying Strategy

<br>Uncertainty-basedï¼šé€‰æ‹©high aleatoric uncertainty or epistemic uncertainty çš„data

<br>æœ€å¤§ç†µï¼ˆEntropyï¼‰
<br>Margin
<br>Least Confidenceï¼ˆLeastConfï¼‰
<br>Bayesian Active Learning by Disagreements (BALD)
<br>Mean Standard Deviation (MeanSTD)
<br>åˆ©ç”¨gradientï¼šBatch Active learning by Diverse Gradient Embeddings (BADGE)ç­‰


<br>Representative/Diversity-based

<br>Clustering methods
<br>selects a batch of representative points based on a core set


<br>Hybrid/combinedï¼ˆbalance uncertainty &amp; diversityï¼‰

<br>Weighted-sum optimization
<br>Two-stage (multi-stage) optimization




<br>Enhancing of DAL Methods

<br>Data aspect
<br>Model aspect


<br>Ref<br>
<br>Batch Active learning by Diverse Gradient Embeddings (BADGE)
<br>Discriminative AL (DiscAL)ï¼štwo different distributions (unlabeled/labeled)
<br><br>
<br><a data-href="Plug and play active learning for object detection" href="paper-reading-notes\plug-and-play-active-learning-for-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Plug and play active learning for object detection</a>
<br>Active learning for deep object detection via probabilistic modeling. In ICCV, 2021
<br>Not all labels are equal: Rationalizing the labeling costs for training object detection. In CVPR, 2022
<br>Multiple instance active learning for object detection. In CVPR, 2021
<br>Entropy-based active learning for object detection with progressive diversity constraint. In CVPR, 2022
<br><br><br><br><a data-tooltip-position="top" aria-label="https://github.com/baifanxxx/awesome-active-learning" rel="noopener nofollow" class="external-link" href="https://github.com/baifanxxx/awesome-active-learning" target="_blank">baifanxxx/awesome-active-learning: A curated list of awesome Active Learning (github.com)</a>]]></description><link>research-notes\active-learning.html</link><guid isPermaLink="false">Research Notes/Active Learning.md</guid><pubDate>Tue, 10 Sep 2024 09:17:33 GMT</pubDate></item><item><title><![CDATA[Class-Incremental Object Detection]]></title><description><![CDATA[ 
 <br><br>ä¸»è¦è§£å†³é—®é¢˜<br>
<br>catastrophic forgetting ç¾éš¾æ€§é—å¿˜
<br>æ–¹æ³•æµæ´¾<br>
<br>knowledge distillationï¼ˆçŸ¥è¯†è’¸é¦ï¼‰
<br>replay

<br>partial experience replay
<br>deep generative replay


<br><br><br><br>Papers about incremental learning: <a data-tooltip-position="top" aria-label="https://github.com/xialeiliu/Awesome-Incremental-Learning" rel="noopener nofollow" class="external-link" href="https://github.com/xialeiliu/Awesome-Incremental-Learning" target="_blank">xialeiliu/Awesome-Incremental-Learning: Awesome Incremental Learning (github.com)</a>]]></description><link>research-notes\class-incremental-object-detection.html</link><guid isPermaLink="false">Research Notes/Class-Incremental Object Detection.md</guid><pubDate>Fri, 23 Aug 2024 14:58:06 GMT</pubDate></item><item><title><![CDATA[Open Vocabulary Learning]]></title><description><![CDATA[ 
 <br><br><a data-href="Towards open vocabulary learning_ A survey" href="paper-reading-notes\towards-open-vocabulary-learning_-a-survey.html" class="internal-link" target="_self" rel="noopener nofollow">Towards open vocabulary learning_ A survey</a><br><br><br><br><br><a data-tooltip-position="top" aria-label="https://github.com/jianzongwu/Awesome-Open-Vocabulary" rel="noopener nofollow" class="external-link" href="https://github.com/jianzongwu/Awesome-Open-Vocabulary" target="_blank">jianzongwu/Awesome-Open-Vocabulary: (TPAMI 2024) A Survey on Open Vocabulary Learning (github.com)</a>]]></description><link>research-notes\open-vocabulary-learning.html</link><guid isPermaLink="false">Research Notes/Open Vocabulary Learning.md</guid><pubDate>Fri, 23 Aug 2024 15:00:15 GMT</pubDate></item><item><title><![CDATA[Semi-supervised 3D Object Detection]]></title><description><![CDATA[ 
 <br><br>
<br>consistency regularization
<br>pseudo-labeling
<br>teacher-student framework: <a data-href="FixMatch_ Simplifying semi-supervised learning with consistency and confidence" href="paper-reading-notes\fixmatch_-simplifying-semi-supervised-learning-with-consistency-and-confidence.html" class="internal-link" target="_self" rel="noopener nofollow">FixMatch_ Simplifying semi-supervised learning with consistency and confidence</a> | <a data-href="Weight-averaged consistency targets improve semi-supervised deep learning results" href="paper-reading-notes\weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html" class="internal-link" target="_self" rel="noopener nofollow">Weight-averaged consistency targets improve semi-supervised deep learning results</a><br><br>SSL(Semi-supervised Learning)<br><br>
<br>consistency regularization ä¸€è‡´æ€§æ­£åˆ™åŒ– : <a data-href="Proposal learning for semi-supervised object detection" href="paper-reading-notes\proposal-learning-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Proposal learning for semi-supervised object detection</a>
<br>teacher-student learning framework: <a data-href="End-to-end semi-supervised object detection with soft teacher" href="paper-reading-notes\end-to-end-semi-supervised-object-detection-with-soft-teacher.html" class="internal-link" target="_self" rel="noopener nofollow">End-to-end semi-supervised object detection with soft teacher</a>
<br><br><br>papers: <br>
<br><a data-href="SESS_ Self-ensembling semi-supervised 3D object detection" href="paper-reading-notes\sess_-self-ensembling-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">SESS_ Self-ensembling semi-supervised 3D object detection</a> 
<br><a data-href="3DIoUMatch_ Leveraging IoU prediction for semi-supervised 3D object detection" href="paper-reading-notes\3dioumatch_-leveraging-iou-prediction-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">3DIoUMatch_ Leveraging IoU prediction for semi-supervised 3D object detection</a> 
<br><a data-href="Learning object-level point augmentor for semi-supervised 3D object detection" href="paper-reading-notes\learning-object-level-point-augmentor-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Learning object-level point augmentor for semi-supervised 3D object detection</a> 
<br><a data-href="DetMatch_ Two teachers are better than one for joint 2D and 3D semi-supervised object detection" href="paper-reading-notes\detmatch_-two-teachers-are-better-than-one-for-joint-2d-and-3d-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">DetMatch_ Two teachers are better than one for joint 2D and 3D semi-supervised object detection</a> 
<br><a data-href="Diffusion-ss3d_ Diffusion model for semi-supervised 3D object detection" href="paper-reading-notes\diffusion-ss3d_-diffusion-model-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Diffusion-ss3d_ Diffusion model for semi-supervised 3D object detection</a>
<br><br><br><br><br><br>
<br>
<a data-href="Active teacher for semi-supervised object detection" href="paper-reading-notes\active-teacher-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Active teacher for semi-supervised object detection</a>  CVPR 2022

<br>
<a data-href="ALWOD_ Active learning for weakly-supervised object detection" href="paper-reading-notes\alwod_-active-learning-for-weakly-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">ALWOD_ Active learning for weakly-supervised object detection</a>  ICCV 2023

<br>
<a data-href="Active learning for deep object detection via probabilistic modeling" href="paper-reading-notes\active-learning-for-deep-object-detection-via-probabilistic-modeling.html" class="internal-link" target="_self" rel="noopener nofollow">Active learning for deep object detection via probabilistic modeling</a> ICCV 2021

<br>
<a data-href="Not all labels are equal_ Rationalizing the labeling costs for training object detection" href="paper-reading-notes\not-all-labels-are-equal_-rationalizing-the-labeling-costs-for-training-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Not all labels are equal_ Rationalizing the labeling costs for training object detection</a> CVPR 2022

<br>
<a data-href="BAOD_ Budget-aware object detection" href="paper-reading-notes\baod_-budget-aware-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">BAOD_ Budget-aware object detection</a> CVPR 2021

<br>
<a data-href="Active learning strategies for weakly-supervised object detection" href="paper-reading-notes\active-learning-strategies-for-weakly-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Active learning strategies for weakly-supervised object detection</a> ECCV 2022

<br>
<a data-href="Box-level active detection" href="paper-reading-notes\box-level-active-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Box-level active detection</a> CVPR 2023

<br>
<a data-href="Monocular 3D object detection with LiDAR guided semi supervised active learning" href="paper-reading-notes\monocular-3d-object-detection-with-lidar-guided-semi-supervised-active-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Monocular 3D object detection with LiDAR guided semi supervised active learning</a> WACV 2024

<br>
<a data-href="Joint semi-supervised and active learning via 3D consistency for 3D object detection" href="paper-reading-notes\joint-semi-supervised-and-active-learning-via-3d-consistency-for-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Joint semi-supervised and active learning via 3D consistency for 3D object detection</a> ICRA 2023

<br><br>
<br><a data-href="Deep active learning for efficient training of a LiDAR 3D object detector" href="paper-reading-notes\deep-active-learning-for-efficient-training-of-a-lidar-3d-object-detector.html" class="internal-link" target="_self" rel="noopener nofollow">Deep active learning for efficient training of a LiDAR 3D object detector</a> IV 2019 (IEEE Intelligent Vehicles Symposium)
<br><a data-href="Advanced active learning strategies for object detection" href="paper-reading-notes\advanced-active-learning-strategies-for-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Advanced active learning strategies for object detection</a> IV 2020
]]></description><link>research-notes\semi-supervised-3d-object-detection.html</link><guid isPermaLink="false">Research Notes/Semi-supervised 3D Object Detection.md</guid><pubDate>Thu, 26 Sep 2024 09:25:36 GMT</pubDate></item><item><title><![CDATA[SSL Theory]]></title><description><![CDATA[ 
 <br><a data-href="Combining labeled and unlabeled data with co-training" href="paper-reading-notes\combining-labeled-and-unlabeled-data-with-co-training.html" class="internal-link" target="_self" rel="noopener nofollow">Combining labeled and unlabeled data with co-training</a> proposed a co-training strategy that trains two models simultaneously using two randomly selected labeled data. then enlarge labeled dataset from unlabeled dataset with positive and negative samples each iteration.<br><a data-href="Learning from labeled and unlabeled data with label propagation" href="paper-reading-notes\learning-from-labeled-and-unlabeled-data-with-label-propagation.html" class="internal-link" target="_self" rel="noopener nofollow">Learning from labeled and unlabeled data with label propagation</a>  proposed a label propagation iterative algorithm to propagate labels through the dataset along high density areas defined by unlabeled data.<br><a data-href="Semi-supervised learning using gaussian fields and harmonic functions" href="paper-reading-notes\semi-supervised-learning-using-gaussian-fields-and-harmonic-functions.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning using gaussian fields and harmonic functions</a> <br><a data-href="Semi-supervised learning by entropy minimization" href="paper-reading-notes\semi-supervised-learning-by-entropy-minimization.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning by entropy minimization</a><br><a data-href="A co-regularization approach to semi-supervised learning with multiple views" href="paper-reading-notes\a-co-regularization-approach-to-semi-supervised-learning-with-multiple-views.html" class="internal-link" target="_self" rel="noopener nofollow">A co-regularization approach to semi-supervised learning with multiple views</a><br><a data-href="Generalization error bounds in semi-supervised classiï¬cation under the cluster assumption" href="paper-reading-notes\generalization-error-bounds-in-semi-supervised-classiï¬cation-under-the-cluster-assumption.html" class="internal-link" target="_self" rel="noopener nofollow">Generalization error bounds in semi-supervised classiï¬cation under the cluster assumption</a><br><a data-href="Does unlabeled data provably help_ Worst-case analysis of the sample complexity of semi-supervised learning" href="paper-reading-notes\does-unlabeled-data-provably-help_-worst-case-analysis-of-the-sample-complexity-of-semi-supervised-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Does unlabeled data provably help_ Worst-case analysis of the sample complexity of semi-supervised learning</a><br><a data-href="Semi-supervised learning by sparse representation" href="paper-reading-notes\semi-supervised-learning-by-sparse-representation.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning by sparse representation</a><br><a data-href="Semi-supervised learning via generalized maximum entropy" href="paper-reading-notes\semi-supervised-learning-via-generalized-maximum-entropy.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning via generalized maximum entropy</a><br><a data-href="Semi-supervised dimension reduction for multi-label classification" href="paper-reading-notes\semi-supervised-dimension-reduction-for-multi-label-classification.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised dimension reduction for multi-label classification</a><br><br>timeline<br>
<br>
<br><a data-href="Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results" href="paper-reading-notes\mean-teachers-are-better-role-models_-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html" class="internal-link" target="_self" rel="noopener nofollow">Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results</a>
<br><a data-href="SESS_ Self-ensembling semi-supervised 3D object detection" href="paper-reading-notes\sess_-self-ensembling-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">SESS_ Self-ensembling semi-supervised 3D object detection</a>
]]></description><link>research-notes\ssl-theory.html</link><guid isPermaLink="false">Research Notes/SSL Theory.md</guid><pubDate>Wed, 27 Nov 2024 13:18:28 GMT</pubDate></item><item><title><![CDATA[{{title}}]]></title><description><![CDATA[ 
 <br><br><br><br>æè¿°é—®é¢˜çš„æ¥æºæˆ–æ„ä¹‰ã€‚<br><br>åˆ—å‡ºç›¸å…³çš„å‚è€ƒæ–‡çŒ®åŠå…¶ä¸»è¦è§‚ç‚¹ã€‚<br><br><br>å®ç°æ€è·¯<br><br><br><br>
<br>å®éªŒç›®æ ‡ï¼šç®€è¦æè¿°å®éªŒç›®çš„ã€‚ 
<br>å‚æ•°è®¾ç½®ï¼šè®­ç»ƒå‚æ•°è®¾ç½®ã€‚
<br>å®éªŒç»“æœï¼šè¡¨æ ¼ã€å›¾è¡¨ã€ç»“æœæè¿°ç­‰ã€‚ 
<br><br>
<br>å®éªŒç›®æ ‡ï¼šç®€è¦æè¿°å®éªŒç›®çš„ã€‚
<br>å‚æ•°è®¾ç½®ï¼šè®­ç»ƒå‚æ•°è®¾ç½®ã€‚
<br>å®éªŒç»“æœï¼šè¡¨æ ¼ã€å›¾è¡¨ã€ç»“æœæè¿°ç­‰ã€‚ 
<br><br><br>ä½¿ç”¨è¡¨æ ¼æˆ–ç®€çŸ­æè¿°è®°å½•å®éªŒç»“æœï¼š<br><br><br><br>è®°å½•æ’°å†™è¿›å±•ï¼š<br>
<br>Introduction-v1
<br>Method-v1
<br>Experiments-v1
<br><br><br>ä½¿ç”¨ä»»åŠ¡åˆ—è¡¨è®°å½•é¡¹ç›®ä¸­éœ€è¦å®Œæˆçš„å…·ä½“å·¥ä½œï¼š<br>
<br>é˜…è¯»æŸç¯‡æ–‡çŒ®ï¼ˆå…·ä½“åç§°ï¼‰
<br>å®Œæˆå®éªŒ X
<br>æ ¡å¯¹è®ºæ–‡è‰ç¨¿
<br><br><br>]]></description><link>templates\project-template.html</link><guid isPermaLink="false">Templates/project-template.md</guid><pubDate>Fri, 22 Nov 2024 07:23:09 GMT</pubDate></item><item><title><![CDATA[citation_config]]></title><description><![CDATA[ 
 <br>---
citekey: {{citekey}}
title: {{title}}
authors: {{authorString}}
year: {{year}}
URL: {{URL}}
code: 
project-page: 
---
]]></description><link>wiki\citation_config.html</link><guid isPermaLink="false">Wiki/citation_config.md</guid><pubDate>Fri, 20 Sep 2024 04:59:07 GMT</pubDate></item><item><title><![CDATA[æ ‡ç­¾ç³»ç»Ÿè¯´æ˜]]></title><description><![CDATA[ 
 <br><br>æœ¬ä»“åº“çš„æ ‡ç­¾ä½“ç³»åŠå…¶ä½¿ç”¨è§„èŒƒã€‚<br><br><br><br>æ ‡è®°é¡¹ç›®å½“å‰çš„ç§‘ç ”è¿›åº¦ï¼š<br>
<br>#ideaï¼šåˆæ­¥æƒ³æ³•é˜¶æ®µï¼Œè¿›è¡Œæ–‡çŒ®è°ƒç ”æˆ–æ¦‚å¿µéªŒè¯ã€‚
<br>#experimentï¼šå®éªŒé˜¶æ®µï¼Œè®¾è®¡ä¸éªŒè¯ã€‚
<br>#manuscriptï¼šè®ºæ–‡æ’°å†™é˜¶æ®µã€‚
<br>#submittedï¼šè®ºæ–‡å·²æäº¤ï¼Œç­‰å¾…è¯„å®¡ç»“æœã€‚
<br>#revisionï¼šä¿®æ”¹æˆ–è½¬æŠ•é˜¶æ®µã€‚
<br>#completedï¼šé¡¹ç›®å·²å®Œæˆã€‚
<br><br>è¡¨ç¤ºé¡¹ç›®çš„ç´§æ€¥ç¨‹åº¦ï¼š<br>
<br>#priority-highï¼šé«˜ä¼˜å…ˆçº§ã€‚
<br>#priority-mediumï¼šä¸­ç­‰ä¼˜å…ˆçº§ã€‚
<br>#priority-lowï¼šä½ä¼˜å…ˆçº§ã€‚
<br><br>æè¿°é¡¹ç›®çš„ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚ï¼š<br>
<br>#semi-supervisedï¼šåŠç›‘ç£å­¦ä¹ ã€‚
<br>#3d-object-detectionï¼š3Dç›®æ ‡æ£€æµ‹ã€‚
<br>#neural-radiance-fieldsï¼šç¥ç»è¾å°„åœºã€‚
<br><br>æ ‡è®°æŠ•ç¨¿ç›®æ ‡ï¼Œä¾‹å¦‚ï¼š<br>
<br>#cvprï¼šCVPRä¼šè®®ã€‚
<br>#iccvï¼šICCVä¼šè®®ã€‚
<br>#journalï¼šæœŸåˆŠæŠ•ç¨¿ã€‚
<br><br><br><br>æ ‡ç­¾ç»Ÿä¸€æ”¾ç½®åœ¨ç¬”è®°çš„é¡¶éƒ¨ã€‚ä¾‹å¦‚ï¼š<br>---
tags: 
  - submitted 
  - cvpr 
  - 3d-object-detection
---
<br><br>
<br>æ ¹æ®é¡¹ç›®è¿›å±•ï¼Œæ›´æ–° #idea â†’ #experiment â†’ #manuscript ç­‰çŠ¶æ€æ ‡ç­¾ã€‚
<br>è‹¥æŠ•ç¨¿å®Œæˆï¼Œæ·»åŠ  #submittedï¼›è¿›å…¥ä¿®æ”¹æ—¶åˆ‡æ¢ä¸º #revisionã€‚
<br><br>
<br>ä½¿ç”¨ Obsidian çš„æ ‡ç­¾æœç´¢åŠŸèƒ½å®šä½ç‰¹å®šçŠ¶æ€çš„é¡¹ç›®ï¼š

<br>ä¾‹å¦‚ï¼Œtag:#submitted æŸ¥è¯¢æ‰€æœ‰å¾…ç»“æœé¡¹ç›®ã€‚


<br>ç»“åˆå…¶ä»–æ ‡ç­¾è¿›è¡Œç»†åŒ–ç­›é€‰ï¼Œå¦‚ tag:#submitted tag:#cvprã€‚
<br><br><br>ä»¥ä¸‹æ˜¯ä¸€ä¸ªé¡¹ç›®çš„æ ‡ç­¾ç¤ºä¾‹ï¼š<br>---
tags: 
  - experiment 
  - priority-high 
  - semi-supervised 
  - iccv
---
<br>
<br>å½“å‰çŠ¶æ€ï¼šå®éªŒé˜¶æ®µã€‚
<br>ä¼˜å…ˆçº§ï¼šé«˜ã€‚
<br>ç ”ç©¶ä¸»é¢˜ï¼šåŠç›‘ç£å­¦ä¹ ã€‚
<br>æŠ•ç¨¿ç›®æ ‡ï¼šICCVä¼šè®®ã€‚
]]></description><link>wiki\tags.html</link><guid isPermaLink="false">Wiki/tags.md</guid><pubDate>Fri, 22 Nov 2024 06:23:08 GMT</pubDate></item><item><title><![CDATA[ğŸ”‘ æ´»è·ƒé¡¹ç›®]]></title><description><![CDATA[ 
 <br><br><br><br><br><br><a data-tooltip-position="top" aria-label="Research Notes/Active Learning.md" data-href="Research Notes/Active Learning.md" href="research-notes\active-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Active Learning</a><br><a data-tooltip-position="top" aria-label="Research Notes/Class-Incremental Object Detection.md" data-href="Research Notes/Class-Incremental Object Detection.md" href="research-notes\class-incremental-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Class-Incremental Object Detection</a><br><a data-tooltip-position="top" aria-label="Research Notes/Open Vocabulary Learning.md" data-href="Research Notes/Open Vocabulary Learning.md" href="research-notes\open-vocabulary-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Open Vocabulary Learning</a><br><a data-tooltip-position="top" aria-label="Research Notes/Semi-supervised 3D Object Detection.md" data-href="Research Notes/Semi-supervised 3D Object Detection.md" href="research-notes\semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised 3D Object Detection</a><br><a data-tooltip-position="top" aria-label="Research Notes/SSL Theory.md" data-href="Research Notes/SSL Theory.md" href="research-notes\ssl-theory.html" class="internal-link" target="_self" rel="noopener nofollow">SSL Theory</a><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br>Wiki: 

<br><a data-href="tags" href="wiki\tags.html" class="internal-link" target="_self" rel="noopener nofollow">tags</a>
<br><a data-tooltip-position="top" aria-label="citation_config" data-href="citation_config" href="wiki\citation_config.html" class="internal-link" target="_self" rel="noopener nofollow">citation</a>


<br>Templates:

<br><a data-href="project-template" href="templates\project-template.html" class="internal-link" target="_self" rel="noopener nofollow">project-template</a>


]]></description><link>ğŸŒhome.html</link><guid isPermaLink="false">ğŸŒHome.md</guid><pubDate>Fri, 22 Nov 2024 09:19:25 GMT</pubDate></item><item><title><![CDATA[fields]]></title><description><![CDATA[ 
 <br><a data-href="Class-Incremental Object Detection" href="research-notes\class-incremental-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Class-Incremental Object Detection</a><br><a data-href="Semi-supervised 3D Object Detection" href="research-notes\semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised 3D Object Detection</a><br><a data-href="Active Learning" href="research-notes\active-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Active Learning</a><br><a data-href="Open Vocabulary Learning" href="research-notes\open-vocabulary-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Open Vocabulary Learning</a><br>Referring Expression Comprehension (REC)<br>Abstract 3D instance segmentation (3DIS)<br>Abstract Domain adaptation  <a data-tooltip-position="top" aria-label="https://openaccess.thecvf.com/content/CVPR2024/html/Nakamura_Active_Domain_Adaptation_with_False_Negative_Prediction_for_Object_Detection_CVPR_2024_paper.html" rel="noopener nofollow" class="external-link" href="https://openaccess.thecvf.com/content/CVPR2024/html/Nakamura_Active_Domain_Adaptation_with_False_Negative_Prediction_for_Object_Detection_CVPR_2024_paper.html" target="_blank">CVPR 2024 Open Access Repository (thecvf.com)</a><br>Unsupervised domain adaptation (UDA)  <a data-tooltip-position="top" aria-label="https://ieeexplore.ieee.org/abstract/document/10474037" rel="noopener nofollow" class="external-link" href="https://ieeexplore.ieee.org/abstract/document/10474037" target="_blank">Remote Sensing Teacher: Cross-Domain Detection Transformer With Learnable Frequency-Enhanced Feature Alignment in Remote Sensing Imagery | IEEE Journals &amp; Magazine | IEEE Xplore</a>]]></description><link>fields.html</link><guid isPermaLink="false">fields.md</guid><pubDate>Tue, 10 Sep 2024 07:02:29 GMT</pubDate></item><item><title><![CDATA[reading list]]></title><description><![CDATA[ 
 <br><br>
<br><a data-href="3D gaussian splatting for real-time radiance field rendering" href="paper-reading-notes\3d-gaussian-splatting-for-real-time-radiance-field-rendering.html" class="internal-link" target="_self" rel="noopener nofollow">3D gaussian splatting for real-time radiance field rendering</a>
<br><a data-href="Recent advances in 3D gaussian splatting" href="paper-reading-notes\recent-advances-in-3d-gaussian-splatting.html" class="internal-link" target="_self" rel="noopener nofollow">Recent advances in 3D gaussian splatting</a>

<br><a data-href="MonoGaussianAvatar_ Monocular gaussian point-based head avatar" href="paper-reading-notes\monogaussianavatar_-monocular-gaussian-point-based-head-avatar.html" class="internal-link" target="_self" rel="noopener nofollow">MonoGaussianAvatar_ Monocular gaussian point-based head avatar</a>

<br><a data-href="Dynamic neural radiance fields for monocular 4D facial avatar reconstruction" href="paper-reading-notes\dynamic-neural-radiance-fields-for-monocular-4d-facial-avatar-reconstruction.html" class="internal-link" target="_self" rel="noopener nofollow">Dynamic neural radiance fields for monocular 4D facial avatar reconstruction</a>


<br><a data-href="PSAvatar_ A point-based morphable shape model for real-time head avatar animation with 3D gaussian splatting" href="paper-reading-notes\psavatar_-a-point-based-morphable-shape-model-for-real-time-head-avatar-animation-with-3d-gaussian-splatting.html" class="internal-link" target="_self" rel="noopener nofollow">PSAvatar_ A point-based morphable shape model for real-time head avatar animation with 3D gaussian splatting</a>
<br><a data-href="GaussianHead_ High-fidelity head avatars with learnable gaussian derivation" href="paper-reading-notes\gaussianhead_-high-fidelity-head-avatars-with-learnable-gaussian-derivation.html" class="internal-link" target="_self" rel="noopener nofollow">GaussianHead_ High-fidelity head avatars with learnable gaussian derivation</a>
<br><a data-href="GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians" href="paper-reading-notes\gaussianavatars_-photorealistic-head-avatars-with-rigged-3d-gaussians.html" class="internal-link" target="_self" rel="noopener nofollow">GaussianAvatars_ Photorealistic head avatars with rigged 3D gaussians</a>
<br><a data-href="Rig3DGS_ Creating controllable portraits from casual monocular videos" href="paper-reading-notes\rig3dgs_-creating-controllable-portraits-from-casual-monocular-videos.html" class="internal-link" target="_self" rel="noopener nofollow">Rig3DGS_ Creating controllable portraits from casual monocular videos</a>
<br><a data-href="HeadGaS_ Real-time animatable head avatars via 3D gaussian splatting" href="paper-reading-notes\headgas_-real-time-animatable-head-avatars-via-3d-gaussian-splatting.html" class="internal-link" target="_self" rel="noopener nofollow">HeadGaS_ Real-time animatable head avatars via 3D gaussian splatting</a>
<br><a data-href="FlashAvatar_ High-fidelity head avatar with efficient gaussian embedding" href="paper-reading-notes\flashavatar_-high-fidelity-head-avatar-with-efficient-gaussian-embedding.html" class="internal-link" target="_self" rel="noopener nofollow">FlashAvatar_ High-fidelity head avatar with efficient gaussian embedding</a>
<br><a data-href="Gaussian head avatar_ Ultra high-fidelity head avatar via dynamic gaussians" href="paper-reading-notes\gaussian-head-avatar_-ultra-high-fidelity-head-avatar-via-dynamic-gaussians.html" class="internal-link" target="_self" rel="noopener nofollow">Gaussian head avatar_ Ultra high-fidelity head avatar via dynamic gaussians</a>


<br><br>
<br>Semi-supervised Learning

<br><a data-href="FixMatch_ Simplifying semi-supervised learning with consistency and confidence" href="paper-reading-notes\fixmatch_-simplifying-semi-supervised-learning-with-consistency-and-confidence.html" class="internal-link" target="_self" rel="noopener nofollow">FixMatch_ Simplifying semi-supervised learning with consistency and confidence</a>
<br><a data-href="Weight-averaged consistency targets improve semi-supervised deep learning results" href="paper-reading-notes\weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html" class="internal-link" target="_self" rel="noopener nofollow">Weight-averaged consistency targets improve semi-supervised deep learning results</a>


<br>2D Object Detection in SSL

<br><a data-href="Proposal learning for semi-supervised object detection" href="paper-reading-notes\proposal-learning-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Proposal learning for semi-supervised object detection</a>
<br><a data-href="End-to-end semi-supervised object detection with soft teacher" href="paper-reading-notes\end-to-end-semi-supervised-object-detection-with-soft-teacher.html" class="internal-link" target="_self" rel="noopener nofollow">End-to-end semi-supervised object detection with soft teacher</a>


<br>3D Object Detection in SSL

<br><a data-href="SESS_ Self-ensembling semi-supervised 3D object detection" href="paper-reading-notes\sess_-self-ensembling-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">SESS_ Self-ensembling semi-supervised 3D object detection</a>
<br><a data-href="3DIoUMatch_ Leveraging IoU prediction for semi-supervised 3D object detection" href="paper-reading-notes\3dioumatch_-leveraging-iou-prediction-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">3DIoUMatch_ Leveraging IoU prediction for semi-supervised 3D object detection</a>
<br><a data-href="Diffusion-ss3d_ Diffusion model for semi-supervised 3D object detection" href="paper-reading-notes\diffusion-ss3d_-diffusion-model-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Diffusion-ss3d_ Diffusion model for semi-supervised 3D object detection</a>

<br>code PointNet2 <a data-tooltip-position="top" aria-label="https://github.com/erikwijmans/Pointnet2_PyTorch" rel="noopener nofollow" class="external-link" href="https://github.com/erikwijmans/Pointnet2_PyTorch" target="_blank">erikwijmans/Pointnet2_PyTorch: PyTorch implementation of Pointnet2/Pointnet++ (github.com)</a>
<br>code votenet <a data-tooltip-position="top" aria-label="https://github.com/facebookresearch/votenet" rel="noopener nofollow" class="external-link" href="https://github.com/facebookresearch/votenet" target="_blank">facebookresearch/votenet: Deep Hough Voting for 3D Object Detection in Point Clouds (github.com)</a>
<br>code OpenPCDet <a data-tooltip-position="top" aria-label="https://github.com/open-mmlab/OpenPCDet" rel="noopener nofollow" class="external-link" href="https://github.com/open-mmlab/OpenPCDet" target="_blank">open-mmlab/OpenPCDet: OpenPCDet Toolbox for LiDAR-based 3D Object Detection. (github.com)</a>
<br>code DiffusionDet <a data-tooltip-position="top" aria-label="https://github.com/ShoufaChen/DiffusionDet" rel="noopener nofollow" class="external-link" href="https://github.com/ShoufaChen/DiffusionDet" target="_blank">ShoufaChen/DiffusionDet: [ICCV2023 Best Paper Finalist] PyTorch implementation of DiffusionDet (https://arxiv.org/abs/2211.09788) (github.com)</a>


<br><a data-href="Learning object-level point augmentor for semi-supervised 3D object detection" href="paper-reading-notes\learning-object-level-point-augmentor-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Learning object-level point augmentor for semi-supervised 3D object detection</a> 
<br><a data-href="DetMatch_ Two teachers are better than one for joint 2D and 3D semi-supervised object detection" href="paper-reading-notes\detmatch_-two-teachers-are-better-than-one-for-joint-2d-and-3d-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">DetMatch_ Two teachers are better than one for joint 2D and 3D semi-supervised object detection</a> 


<br><br><br><br>
<br>incremental learning
<br>å¯¹æ¯”å­¦ä¹ 
<br>è’¸é¦
<br>è¿ç§»å­¦ä¹ 
<br>3Dç›®æ ‡æ£€æµ‹çš„åŸŸè‡ªé€‚åº” domain adaptation
<br>3Dç›®æ ‡æ£€æµ‹ å¼±ç›‘ç£
<br>3Dç›®æ ‡æ£€æµ‹ è‡ªç›‘ç£
<br>é‡é‡‡æ ·
<br>é‡å‚æ•°åŒ–ï¼ˆVAEï¼‰
<br>KLæ•£åº¦
<br>diffusion model
<br>KAN
<br>mamba
]]></description><link>reading-list.html</link><guid isPermaLink="false">reading list.md</guid><pubDate>Fri, 23 Aug 2024 15:00:51 GMT</pubDate></item><item><title><![CDATA[thoughts]]></title><description><![CDATA[ 
 <br><br><br><br>è¾“å…¥æ˜¯é™æ€åœºæ™¯çš„ä¸€ç»„å›¾åƒï¼Œå’Œsfmé‡å»ºå¾—åˆ°çš„ç³»æ•°ç‚¹äº‘ã€‚<br>
The input to our method is a set of images of a static scene, together with the corresponding cameras calibrated by SfM which produces a sparse point cloud as a sideeffect.
<br>ä»ç¨€ç–ç‚¹äº‘ä¸­åˆ›å»ºä¸€ç»„3D Gaussiansï¼Œå‚æ•°åŒ…å«ï¼ˆå¹³å‡ä½ç½®åæ ‡ã€åæ–¹å·®çŸ©é˜µã€å¯†åº¦ï¼‰<br>
From these points we create a set of 3D Gaussians (Sec. 4), defined by a position (mean), covariance matrix and opacity ğ›¼, that allows a very flexible optimization regime. This results in a reasonably compact representation of the 3D scene, in part because highly anisotropic(å„å‘å¼‚æ€§) volumetric splats can be used to represent fine structures compactly.
<br>ä½¿ç”¨çƒè°å‡½æ•°æ¥è¡¨ç¤ºé¢œè‰²ï¼Œä½¿ç”¨è¾å°„åœºè¡¨ç¤ºå…‰<br>
The directional appearance component (color) of the radiance field is represented via spherical harmonics (SH), following standard practice.
<br>anisotropicï¼ˆå„å‘å¼‚æ€§ï¼‰ï¼šè¿™ä¸ªè¯è¡¨ç¤ºåœ¨ä¸åŒæ–¹å‘ä¸Šå…·æœ‰ä¸åŒçš„ç‰¹æ€§ã€‚åœ¨å›¾å½¢å­¦ä¸­ï¼Œå„å‘å¼‚æ€§é€šå¸¸æŒ‡çº¹ç†æˆ–å…‰ç…§åœ¨ä¸åŒæ–¹å‘ä¸Šè¡¨ç°å‡ºçš„ä¸åŒæ•ˆæœã€‚ä¸å„å‘åŒæ€§ï¼ˆå„ä¸ªæ–¹å‘ä¸Šç‰¹æ€§ç›¸åŒï¼‰ç›¸å¯¹ã€‚<br>spherical harmonics(SH): çƒè°å‡½æ•°<br>Tile-based rendererï¼ˆåŸºäºå—çš„æ¸²æŸ“å™¨ï¼‰<br><img alt="Pasted image 20240620235810.png" src="attachments\pasted-image-20240620235810.png"><br>ä¸ç®¡æ˜¯3DGSè¿˜æ˜¯NeRFï¼Œæ•°æ®çš„è¾“å…¥éƒ½æ˜¯ä¸€ç»„é™æ€åœºæ™¯çš„å›¾åƒé›†åˆï¼Œä»¥åŠå¯¹åº”çš„sfmé‡å»ºå¾—åˆ°çš„ç›¸æœºä½å§¿å’Œç¨€ç–ç‚¹äº‘ã€‚ä½†æ˜¯ï¼Œè¿™äº›ç®—æ³•çš„å‰æéƒ½æ˜¯å‡è®¾è¿™äº›ä¼°è®¡éƒ½æ˜¯æ­£ç¡®çš„ï¼Œåœ¨ä¸€äº›å¤æ‚åœºæ™¯ä¸­ï¼Œsfmè¯¯å·®è¾ƒå¤§ï¼Œæ˜¯å¦å¯ä»¥åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å°†sfmä¼°è®¡çš„ç»“æœä¹Ÿè€ƒè™‘è¿›å»ï¼Ÿ<br><br>ç›®å‰çš„3dé£æ ¼åŒ–æ–¹æ¡ˆï¼Œæ˜¯å…ˆä»è§†é¢‘é‡å»ºæˆä¸‰ç»´æ¨¡å‹ï¼Œç„¶åè¿›è¡Œé£æ ¼åŒ–ã€‚æ˜¯å¦æœ‰ç«¯åˆ°ç«¯çš„æ–¹æ¡ˆï¼Ÿè¾“å…¥åŸå§‹è§†é¢‘å’Œé£æ ¼åŒ–çš„å›¾åƒï¼Œè¾“å‡ºé£æ ¼åŒ–çš„æ¨¡å‹ã€‚]]></description><link>thoughts.html</link><guid isPermaLink="false">thoughts.md</guid><pubDate>Tue, 09 Jul 2024 09:55:47 GMT</pubDate><enclosure url="attachments\pasted-image-20240620235810.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;attachments\pasted-image-20240620235810.png&quot;&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>