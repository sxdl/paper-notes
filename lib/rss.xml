<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[PaperNotesRemote]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://sxdl.site/paper-notes/</link><image><url>https://sxdl.site/paper-notes/lib/media/favicon.png</url><title>PaperNotesRemote</title><link>https://sxdl.site/paper-notes/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 02 Dec 2024 07:28:40 GMT</lastBuildDate><atom:link href="https://sxdl.site/paper-notes/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 02 Dec 2024 07:28:35 GMT</pubDate><copyright><![CDATA[sxdl]]></copyright><ttl>60</ttl><dc:creator>sxdl</dc:creator><item><title><![CDATA[2024-08-23]]></title><description><![CDATA[ 
 <br>
<br>重新看了一遍 diffusion-ss3d
<br>浏览类增量目标检测论文，<a data-href="Learning task-aware language-image representation for class-incremental object detection" href="https://sxdl.site/paper-notes/paper-reading-notes/learning-task-aware-language-image-representation-for-class-incremental-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Learning task-aware language-image representation for class-incremental object detection</a>，提到“cross-modality learning paradigm has shown strong zero-shot and few-shot transfer ability to object detection”，思考是否能将文本多模态信息用于3d目标检测的半监督学习。
<br>搜索是否有相关的文本-视觉的3d目标检测器，发现一个新领域<a data-href="Open Vocabulary Learning" href="https://sxdl.site/paper-notes/research-notes/open-vocabulary-learning.html" class="internal-link" target="_self" rel="noopener nofollow">Open Vocabulary Learning</a>，似乎与半监督学习的思想有相通之处，明天计划看一下该领域的综述<a data-href="Towards open vocabulary learning_ A survey" href="https://sxdl.site/paper-notes/paper-reading-notes/towards-open-vocabulary-learning_-a-survey.html" class="internal-link" target="_self" rel="noopener nofollow">Towards open vocabulary learning_ A survey</a>,以及3d目标检测的论文
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-23.html</link><guid isPermaLink="false">Logs/2024-08-23.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 27 Aug 2024 12:34:37 GMT</pubDate></item><item><title><![CDATA[2024-08-24]]></title><description><![CDATA[ 
 <br>
<br>看了综述<a data-href="Towards open vocabulary learning_ A survey" href="https://sxdl.site/paper-notes/paper-reading-notes/towards-open-vocabulary-learning_-a-survey.html" class="internal-link" target="_self" rel="noopener nofollow">Towards open vocabulary learning_ A survey</a>背景和问题定义。visual-language model 在跨域上有优势
<br>需要研究一下CLIP的原理
<br>是否可以使用3D Novel Object Discovery (3D-NOD)的方法来增强半监督3D目标检测任务中伪标签的生成质量？
<br><a data-href="CoDA_ Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3D object detection" href="https://sxdl.site/paper-notes/paper-reading-notes/coda_-collaborative-novel-box-discovery-and-cross-modal-alignment-for-open-vocabulary-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">CoDA_ Collaborative novel box discovery and cross-modal alignment for open-vocabulary 3D object detection</a>看到Method部分
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-24.html</link><guid isPermaLink="false">Logs/2024-08-24.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Sat, 24 Aug 2024 08:54:51 GMT</pubDate></item><item><title><![CDATA[2024-08-25]]></title><description><![CDATA[ 
 <br>
<br>研究结合文本特征是否能提升伪标签的生成质量，GLIP将目标检测任务和文本的grouding任务结合起来，用deepfusion结合文本特征和图像特征，在少样本和零样本迁移上表现较好。另一篇关于目标检测的类增量学习<a data-href="Learning task-aware language-image representation for class-incremental object detection" href="https://sxdl.site/paper-notes/paper-reading-notes/learning-task-aware-language-image-representation-for-class-incremental-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Learning task-aware language-image representation for class-incremental object detection</a>的论文，也使用了GLIP方法来提高在新的task上的迁移能力。因此我觉得文本信息的引入可以提高目标检测的效果。如果参考这样的思路，将文本信息引入半监督3D目标检测中，来提高伪标签的生成质量，提高召回率，并且能够强化模型在跨域数据集上的表效果。问题在于，如何将GLIP这种用于2D目标检测的预训练模型或者其他的多模态结合的方式用于3D点云。一种方式是从3D点云中投影得到2D的图像，然后使用预训练的GLIP来生成伪标签，约束teacher模型生成的3D伪标签，但这样本质就是简单地使用2D的目标检测来约束teacher生成的伪标签。另一种方式是将文本特征嵌入到模型中，但需要考虑如何去对齐两种模态的信息。了解到一些可能相关的关键词：contrastive learning，deep fusion
<br>了解contrastive learning的方法
<br>看一下SS2D和SS3D的所有论文使用的方法
<br>可以使用GLIP主体得到的fusion特征
<br>能否借鉴弱监督的方法来根据box的center来预测rotation？
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-25.html</link><guid isPermaLink="false">Logs/2024-08-25.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Sun, 25 Aug 2024 14:43:38 GMT</pubDate></item><item><title><![CDATA[2024-08-26]]></title><description><![CDATA[ 
 <br>
<br>跨域适应文章调研
<br>图神经网络构建数据分布（想法
<br>构图，LLM
<br>不同class点云拼接，预测边界class
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-26.html</link><guid isPermaLink="false">Logs/2024-08-26.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 26 Aug 2024 02:54:28 GMT</pubDate></item><item><title><![CDATA[2024-08-27]]></title><description><![CDATA[ 
 <br>
<br>看了SSOD的2022年及以前的论文，看到 <a data-href="Semi-supervised object detection via multi-instance alignment with global class prototypes" href="https://sxdl.site/paper-notes/paper-reading-notes/semi-supervised-object-detection-via-multi-instance-alignment-with-global-class-prototypes.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised object detection via multi-instance alignment with global class prototypes</a> 这篇
<br>可以研究的点：label noise overfitting problem、scale inconsistency、class imbalance
<br>可能结合的领域：自蒸馏、主动学习、域自适应
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-27.html</link><guid isPermaLink="false">Logs/2024-08-27.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 27 Aug 2024 12:33:04 GMT</pubDate></item><item><title><![CDATA[2024-08-30]]></title><description><![CDATA[ 
 <br>
<br>将3DIoUMatch中 sunrgbd数据代码移植到了Diffusion-ss3d中，修改detect和ss数据集类的代码，增加了相应的数据，在sunrgb上跑起了pretrain代码
<br>看了<a data-href="DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection" href="https://sxdl.site/paper-notes/paper-reading-notes/dqs3d_-densely-matched-quantization-aware-semi-supervised-3d-detection.html" class="internal-link" target="_self" rel="noopener nofollow">DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection</a>，主要创新点是将比较新的全卷积的检测backbone加入，显著提升伪标签的生成质量。
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-30.html</link><guid isPermaLink="false">Logs/2024-08-30.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Fri, 30 Aug 2024 13:28:02 GMT</pubDate></item><item><title><![CDATA[2024-08-31]]></title><description><![CDATA[ 
 <br>
<br>idea，将student或teacher的预训练和训练过程看作是增量学习？
<br>打算follow<a data-href="DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection" href="https://sxdl.site/paper-notes/paper-reading-notes/dqs3d_-densely-matched-quantization-aware-semi-supervised-3d-detection.html" class="internal-link" target="_self" rel="noopener nofollow">DQS3D_ Densely-matched quantization-aware semi-supervised 3D detection</a>这篇，解决其中的voxel size灵敏以及scale variance 问题。直接减小voxel size会导致计算量倍增，因此需要某种方式来减小整个场景的大小，在小场景中做全卷积会好很多。改变场景大小，减小voxel size，本质上就是改变局部点云的稠密程度，似乎可以同时去增强尺度上的问题。
<br>需要设计一个实验来研究点云分辨率（尺度）变化对3D目标检测的置信度的影响。初步想法是对坐标x0.5以及x2来改变点云的分辨率
]]></description><link>https://sxdl.site/paper-notes/logs/2024-08-31.html</link><guid isPermaLink="false">Logs/2024-08-31.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Sat, 31 Aug 2024 14:16:31 GMT</pubDate></item><item><title><![CDATA[2024-09-02]]></title><description><![CDATA[ 
 <br>
<br>论文阅读 pointpillars，思路有相似<a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1812.05784" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1812.05784" target="_blank">[1812.05784] PointPillars: Fast Encoders for Object Detection from Point Clouds (arxiv.org)</a>
<br>主动学习+半监督学习
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-02.html</link><guid isPermaLink="false">Logs/2024-09-02.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 02 Sep 2024 14:20:21 GMT</pubDate></item><item><title><![CDATA[2024-09-03]]></title><description><![CDATA[ 
 <br>
<br>看3DIoUMatch代码
<br>精读<a data-href="Active teacher for semi-supervised object detection" href="https://sxdl.site/paper-notes/paper-reading-notes/active-teacher-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Active teacher for semi-supervised object detection</a>
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-03.html</link><guid isPermaLink="false">Logs/2024-09-03.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 03 Sep 2024 00:14:57 GMT</pubDate></item><item><title><![CDATA[2024-09-04]]></title><description><![CDATA[ 
 <br>
<br>早上了解Active Learning领域
<br>DQS3D代码环境
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-04.html</link><guid isPermaLink="false">Logs/2024-09-04.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Wed, 04 Sep 2024 14:17:57 GMT</pubDate></item><item><title><![CDATA[2024-09-05]]></title><description><![CDATA[ 
 <br>
<br>active teacher 被引文献
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-05.html</link><guid isPermaLink="false">Logs/2024-09-05.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 05 Sep 2024 09:24:01 GMT</pubDate></item><item><title><![CDATA[2024-09-10]]></title><description><![CDATA[ 
 <br>
<br>明天看这一篇<a data-tooltip-position="top" aria-label="https://arxiv.org/pdf/2305.10643" rel="noopener nofollow" class="external-link" href="https://arxiv.org/pdf/2305.10643" target="_blank">2305.10643 (arxiv.org)</a>，streaming based active learning
<br>online active learning 综述<a data-tooltip-position="top" aria-label="https://www.semanticscholar.org/reader/10a7f6463a6abe3e4723576a9c0ba03c1339cfbb" rel="noopener nofollow" class="external-link" href="https://www.semanticscholar.org/reader/10a7f6463a6abe3e4723576a9c0ba03c1339cfbb" target="_blank">[PDF] Active learning for data streams: a survey | Semantic Scholar</a>
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-10.html</link><guid isPermaLink="false">Logs/2024-09-10.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 10 Sep 2024 14:11:12 GMT</pubDate></item><item><title><![CDATA[2024-09-13]]></title><description><![CDATA[ 
 <br>
<br>2d目标检测和3d目标检测的区别：2d中可能一张图片只有一个目标，而3d的数据是一个场景，总是包含多个目标
<br>主动学习在重采样
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-13.html</link><guid isPermaLink="false">Logs/2024-09-13.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Fri, 13 Sep 2024 13:27:39 GMT</pubDate></item><item><title><![CDATA[2024-09-14]]></title><description><![CDATA[ 
 <br>
<br>看了重采样的思路。明天写实验代码。分别在预训练和半监督过程中加入重采样策略。重采样的比例通过主动学习的指标计算后排序得到。重采样的比例间隔n个epoch重新计算。自定义一个Dataloader，包含一个自定义的Sampler类，提供一个update_weights()方法，每次train_one_epoch()后，更新权重。
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-14.html</link><guid isPermaLink="false">Logs/2024-09-14.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Sat, 14 Sep 2024 14:37:20 GMT</pubDate></item><item><title><![CDATA[2024-09-18]]></title><description><![CDATA[ 
 <br>
<br>预训练过程重采样
<br>根据样本的AL分数调整伪标签阈值
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-18.html</link><guid isPermaLink="false">Logs/2024-09-18.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Wed, 18 Sep 2024 13:08:57 GMT</pubDate></item><item><title><![CDATA[2024-09-19]]></title><description><![CDATA[ 
 <br>
<br>在每个训练阶段，同时用原始数据和重采样数据训练，评估之后，选择性能更好的模型，并记录。研究是否在某个特定阶段重采样策略有效
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-19.html</link><guid isPermaLink="false">Logs/2024-09-19.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 19 Sep 2024 10:45:06 GMT</pubDate></item><item><title><![CDATA[2024-09-26]]></title><description><![CDATA[ 
 <br>
<br>3DIoUMatch和DiffusionSS3D在训练后半阶段（epoch&gt;500）class分类会出现过拟合现象，表现为eval_cls_acc上升。
<br>修改了之前代码中的错误：权重归一化代码写在了循环里面，导致对每个batch的样本做了归一化但是没有对全部的样本做归一化，已修改，重跑实验
<br>infomation的指标计算做了修改，现在只计算高于cls_threshold的置信度，因为在伪标签筛选过程中，低于cls_threshold的样本都会被筛出。修改后指标反映样本中当作伪标签的proposal的信息量
<br>指标的分数只使用max归一化作为权重，会导致权重过于分散（0.4~1.0），因此加了非线性滤波来人为控制权重的分散程度
]]></description><link>https://sxdl.site/paper-notes/logs/2024-09-26.html</link><guid isPermaLink="false">Logs/2024-09-26.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 26 Sep 2024 02:32:20 GMT</pubDate></item><item><title><![CDATA[2024-10-16]]></title><description><![CDATA[ 
 <br>
<br>在不同的数据集比例上测试了resample策略的效果，效果略有提升但超参数需要调优。
<br><img alt="Pasted image 20241016215813.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241016215813.png"><br>
<br>尝试利用主动学习指标动态调整阈值，没有效果。<br>
<img alt="Pasted image 20241016221548.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241016221548.png">
<br>重新思考，尝试 混合数据增强策略结合主动学习，计划尝试两种增强方式：

<br>对未标注场景计算diff指标，若场景小于diff阈值，应用混合增强，将有标注实例粘贴到该未标注场景中；
<br>将伪标签实例粘贴到有标签场景中（需要解决伪标签bbox定位不精确问题）


<br>编写混合增强策略实验代码，计划

<br>实例database：根据bbox提取相关点云，加入到database
<br>方式一实现：在dataset类getitem方法中，data augment之前，应用混合数据增强
<br>方式二实现
<br>其他：场景可视化openpcdet接口调用


<br><br>
<br>实现了bbox提取相关点云
<br><img alt="Pasted image 20241016222242.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241016222242.png">]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-16.html</link><guid isPermaLink="false">Logs/2024-10-16.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Wed, 16 Oct 2024 14:22:47 GMT</pubDate><enclosure url="https://sxdl.site/paper-notes/lib/media/pasted-image-20241016215813.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241016215813.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-17]]></title><description><![CDATA[ 
 <br>
<br>实现方式一策略代码：在dataset类getitem方法中，data augment之前，应用混合数据增强
<br>original  &lt;-- | --&gt; noisy<br><img alt="Pasted image 20241017163934.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241017163934.png"><br><img alt="Pasted image 20241017164006.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241017164006.png"><br><img alt="Pasted image 20241017164030.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241017164030.png"><br>
<br>在scannet 5%上测试：nohup ./my_sh/exp_mix_resample_scan_3.sh &gt; LOG.log 2&gt;&amp;1 &amp; scannet_0.05, gamma=0.15, mix_thresh=mean_diff, dir=exp_mix_resample
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-17.html</link><guid isPermaLink="false">Logs/2024-10-17.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 17 Oct 2024 09:15:20 GMT</pubDate><enclosure url="https://sxdl.site/paper-notes/lib/media/pasted-image-20241017163934.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241017163934.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-18]]></title><description><![CDATA[ 
 <br>
<br>整理本地代码，方便迁移到多个环境中同时跑
<br>方式一策略代码sunrgbd实现
<br> todo: <br>
<br>sunrgbd代码适配
<br>代码迁移服务器
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-18.html</link><guid isPermaLink="false">Logs/2024-10-18.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Fri, 18 Oct 2024 13:30:28 GMT</pubDate></item><item><title><![CDATA[2024-10-21]]></title><description><![CDATA[ 
 <br>工作内容：<br>
<br>整理混合数据增强idea思路，撰写文档。
<br>完成了数据增强策略的基础代码，调试通过。
<br>在scannet 10%上运行混合数据增强对比试验（ground truth instance -&gt; unlabeled scene，随机位置），预计剩余48h
<br>解决了应用数据增强策略后，在sunrgbd上训练eval结果异常问题。
<br>在sunrgbd 5%上运行对比试验，同上
<br>工作进展：<br>遇到的问题：<br>
<br>混合数据增强策略训练时间异常：scannet 10% baseline约6h，测试训练时间&gt;24h
<br>解决方案与计划：<br>
<br>可能与一张卡同时跑两个训练有关，换卡重试一下；监测代码每个模块的运行时间，看是否有异常耗时。
<br>明日计划：<br>
<br>编写collision test模块代码
<br>解决训练时间异常问题
<br>阅读相关论文<a data-href="De-biased teacher_ Rethinking iou matching for semi-supervised object detection" href="https://sxdl.site/paper-notes/paper-reading-notes/de-biased-teacher_-rethinking-iou-matching-for-semi-supervised-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">De-biased teacher_ Rethinking iou matching for semi-supervised object detection</a>
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-21.html</link><guid isPermaLink="false">Logs/2024-10-21.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 21 Oct 2024 14:52:13 GMT</pubDate></item><item><title><![CDATA[2024-10-22]]></title><description><![CDATA[ 
 <br>工作内容：<br>
<br>昨天在两张卡同时训练scannet 10%，CUDA OOM了，等待另一个训练结束后继续。
<br>完成collision test模块代码。
<br>修改mix实例位置的选择：不仅需要避免碰撞，还需要避免选择的位置和其他物体距离过远。
<br>完成上述功能，扩充了collision test模块，确保新的位置在原始点云附近，在scannet 10%上训练测试。
<br>调试了训练时间异常的问题，确认是单卡多训练的原因。
<br>遇到的问题：<br>
<br>使用ground truth instance mix增强之后的unlabelled scene数据，是只输入给student模型，或是同时输入给student和teacher模型，或者将ground truth和teacher模型生成的伪标签合并用于监督student的结果？我觉得三种方式都有道理，最后一种相比更为合理一点，但是增加的代码会复杂很多。目前使用第一种方式先看效果。
<br>明日计划：<br>
<br>开始写pseudo instance —&gt; labeled scene策略的代码，争取在现在的实验跑完之前，能够将这个策略的训练实验跑起来。
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-22.html</link><guid isPermaLink="false">Logs/2024-10-22.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 22 Oct 2024 15:27:28 GMT</pubDate></item><item><title><![CDATA[2024-10-24]]></title><description><![CDATA[ 
 <br>工作进展：<br>
<br>21号跑的实验(ground truth instance -&gt; unlabeled scene)，效果还不错，在scannet10%和sunrgbd5%上都有提升
<br><img alt="Pasted image 20241024171824.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241024171824.png"><br>遇到的问题：<br>
<br>想这个策略动机的时候，发现遗漏的一篇AAAI 24的论文“Dual-Perspective Knowledge Enrichment for Semi-Supervised 3D Object Detection”，同样也是做室内的，并且指标超过了Diffusion-SS3D，在Github上找到了开源的代码。能用这篇论文做baseline吗？
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-24.html</link><guid isPermaLink="false">Logs/2024-10-24.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 24 Oct 2024 13:45:58 GMT</pubDate><enclosure url="https://sxdl.site/paper-notes/lib/media/pasted-image-20241024171824.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241024171824.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-26]]></title><description><![CDATA[ 
 <br>工作内容：<br>
<br>完成 pseudo instance —&gt; labeled scene策略的代码，包括替换和粘贴。
<br>遇到的问题：<br>
<br>发现模型在训练初期，筛选过的pseudo instance，bounding box的定位仍非常不准（如下图），即使使用多个proposal的并集也无法保证得到完整的物体。需要进一步分析一下iou score和confidence的输出，调整上面的策略。
<br><img alt="Pasted image 20241026214940.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241026214940.png">]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-26.html</link><guid isPermaLink="false">Logs/2024-10-26.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Sat, 26 Oct 2024 13:49:53 GMT</pubDate><enclosure url="https://sxdl.site/paper-notes/lib/media/pasted-image-20241026214940.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241026214940.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-29]]></title><description><![CDATA[ 
 <br>
<br>详细看一下fixmatch
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-29.html</link><guid isPermaLink="false">Logs/2024-10-29.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 29 Oct 2024 14:53:16 GMT</pubDate></item><item><title><![CDATA[2024-10-30]]></title><description><![CDATA[ 
 <br>工作内容：<br>
<br>完成mixup 三种策略的代码，同时在三张卡上对scannet 10%数据集实验，预计31号中午看到结果
<br>实验记录：<br>mixup 策略1<br>
<br>4060T GPU0
<br>LOG_DIR=results/train/exp_mixup_1/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1
<br>SCRIPT=exp_mixup_123_scan_1.sh
<br>mixup 策略2<br>
<br>4090 GPU0
<br>LOG_DIR=results/train/exp_mixup_2/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_2_scan_1.sh
<br>mixup 策略3<br>
<br>4090 GPU1
<br>LOG_DIR=results/train/exp_mixup_3/scan_0.1
<br>DATASET=scannet_0.1
<br>VERSION=v1 v2
<br>SCRIPT=exp_mixup_3_scan_1.sh
]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-30.html</link><guid isPermaLink="false">Logs/2024-10-30.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Wed, 30 Oct 2024 16:36:02 GMT</pubDate></item><item><title><![CDATA[2024-10-31]]></title><description><![CDATA[ 
 <br>昨天的代码有错误，混合点云的时候没有对齐center坐标；加入密度、点云数量进一步筛选需要mixup的伪标签<br>记得git提交代码]]></description><link>https://sxdl.site/paper-notes/logs/2024-10-31.html</link><guid isPermaLink="false">Logs/2024-10-31.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 31 Oct 2024 16:36:52 GMT</pubDate></item><item><title><![CDATA[2024-11-01]]></title><description><![CDATA[ 
 <br>匹配方式：按照长宽高匹配；假设1st长度为长；2nd长度为宽；3rd长度为高，两个proposal就可以用长宽高匹配和resize<br>
第一种：从data取一个椅子，替换掉老师proposal中的椅子，原来的点去除<br>第二种：mixup，data里的椅子与teacher得到的椅子做mixup，例如椅子1的采样率为A%，那么椅子2就是100-A%<br>
第三种：mixup，data里的桌子与teacher得到的椅子做mixup，椅子是A%，桌子是100-A%（A&gt;&gt;50%）<br>11-01-3：不保持总数量不变，而是gt A% + pseudo (1-A)% &gt;=N ，然后在整个场景的点云重采样到40000，不带密度筛选模块]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-01.html</link><guid isPermaLink="false">Logs/2024-11-01.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Fri, 01 Nov 2024 14:01:09 GMT</pubDate></item><item><title><![CDATA[2024-11-04]]></title><description><![CDATA[ 
 <br>工作内容：<br>
<br>撰写论文，完成了论文method部分
<br>绘制了模型框架草图
<br><img alt="Pasted image 20241104194929.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241104194929.png"><br>
<br>目前的效果没有超过sota，打算在diffusion-ss3d上实现现在的方法。diffusion-ss3d 没有提供 sunrgbd数据集代码，之前没有复现成。重新补充了sunrgbd部分的代码，复现1%数据集，目前训练指标看起来正常。
<br>工作进展：<br>
<br>三种策略在scannet上效果比单独使用一种策略都有提升。
<br><img alt="Pasted image 20241104194220.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241104194220.png"><br>
<br>在scannet上完成了 强增强的伪标签比例(之前设定的是50%) 的灵敏度分析实验
<br><img alt="Pasted image 20241104194629.png" src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241104194629.png"><br>
<br>开始写论文，完成了论文method部分第一版
<br>遇到的问题：<br>
<br>三种策略的消融有些奇怪，两种策略一起比一种策略单独要差，可能是有偏差，后面有时间多跑几次
<br>在服务器上的gpu上训练时，sunrgbd数据集的训练异常慢，排查不出原因，目前看起来是偶然现象，希望后面的实验少出问题。
<br>粗略计算了下目前剩下的实验，剩下的消融实验加上diffusion-ss3d baseline 预计最少需要6.5天+，如果加上3dioumatch baseline 的结果，最少需要8.7天+，diffusion-ss3d训练时间不太确定，sunrgbd数据集上训练时间可能出现异常，还需要预留时间给结果不好的实验重跑。算下来时间比较极限。
<br>后续计划：<br>
<br>继续在sunrgbd上跑 强增强的伪标签比例(之前设定的是50%) 的灵敏度分析实验
<br>diffusion-ss3d sunrgbd数据集上复现没问题后，移植现在的方法到diffusion-ss3d上
<br>论文需要混合增强的效果可视化，需要跑通OpenPCDet的可视化代码
]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-04.html</link><guid isPermaLink="false">Logs/2024-11-04.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 04 Nov 2024 12:05:13 GMT</pubDate><enclosure url="https://sxdl.site/paper-notes/lib/media/pasted-image-20241104194929.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://sxdl.site/paper-notes/lib/media/pasted-image-20241104194929.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-11-12]]></title><description><![CDATA[ 
 <br>
<br>同一个场景的不同扫描，模型的推理表现差异很大。即使是做过增强，依旧会有较大性能差异， 不鲁棒
<br>半监督人工标注遗漏/错误问题
]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-12.html</link><guid isPermaLink="false">Logs/2024-11-12.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 12 Nov 2024 12:11:36 GMT</pubDate></item><item><title><![CDATA[2024-11-13]]></title><description><![CDATA[ 
 <br>接下来，我会给你部分完成的论文introduction部分，以及后续的论文思路，你需要完成introduction后面未完成的段落。The goal of 3D object detection is to identify category labels of objects and locate 3D boundary boxes from a point cloud scen, playing a crucial role in applications in autonomous driving and robotics[].<br>
Recent works~\cite{liu2021group, qi2019deep, rukhovich2022fcaf3d, shi2023pv, shi2019pointrcnn, shi2020points,  wang2022cagroup3d, yang20203dssd, zhou2018voxelnet, chen2023voxelnext, wang2022sparse2dense, yin2021center, fan2022fully} have made significant progress in 3D object detection. However, obtaining a large amount of carefully annotated 3D scene data is very expensive and time-consuming.<br>To overcome the limitation, semi-supervised learning (SSL) methods leverage a combination of few labeled data and a large amount of unlabeled data to enhance training and improve model performance. Prior works~\cite{zhao2020sess, wang20213dioumatch, ho2023diffusion, wang2023not} [sess, 3dioumatch, diffusion-ss3d, not-every-side-is-equal, DPKE] adopt a student-teacher framework with asymmetric data augmentation to train the student model through pseudo-labeling and consistency regularization. For instance, SESS~\cite{zhao2020sess} ... 3DIoUMatch~\cite{wang20213dioumatch} ... NESE~\cite{wang2023not} ...  Diffusion-SS3D~\cite{ho2023diffusion} ... Specifically, One of the critical keys to the well-performed semi-supervised learning is the strong augmentation strategy. Strong augmentation aids in robust feature learning by exposing the model to a wide range of transformations, which enhances its ability to detect objects under various real-world conditions. Additionally, it prevents overfitting by introducing variability into the training process, ensuring that the model generalizes better to novel, unseen data. Specifically, these approaches focused on scene-level augmentation strategies, such as flipping, rotation, and scaling. However, only utilize scene-level augmentation can suffer from limited diversity. This is because applying uniform transformations to entire scenes does not significantly alter individual objects within the scene, leading to less variability at the object level. As a result, the model may not experience a wide range of object poses or appearances, limiting its ability to learn robust, object-specific features necessary for accurate detection under varied conditions.  <br>To ... we propose...<br>Additionally, ... we propose ... augmentation constraints...<br>Our contribution.... ；<br>后面段落思路：DPKE在data augmentation上做出了改进，提出了双视角的数据增强方法，但仍旧是基于目前在3D目标检测中使用的scene-level的增强方法。受到在3D classification任务中PointMixup [31], RSMix [32], and SageMix [36].的启发，我们利用半监督学习框架student-teacher framework独特的结构特性,充分利用teacher model得到的伪标签，提出了适用于半监督下的instance-level augmentation methods. 我们提出了三种instance-level 的增强策略来扩充数据的多样性，同时加强模型对目标的语义分类能力。具体来说，第一种方式是 same class replacement, 使用相同的类的真实object替换未标注场景中的物体，来丰富该类物体的数据表示。第二种方式是 same class mixup, 使用相同的类的真实object的点云与未标注场景点云混合，从而加强模型对同类物体形状的鲁棒性；第三种方式是different class mixup，使用不同的类的真实object点云混入到未标注物体中，从而加强模型的语义分类能力。<br>另外，为了保证增强的数据的语义信息稳定，我们提出了两种constraints method来约束instance-level数据增强。The first constraint ensures that the augmented in-<br>
stances maintain a certain level of physically realism by<br>
aligning the shape and orientation of the objects. The sec<br>
ond constraint focuses on maintaining instance characteris<br>
tics by controlling the number of points after mixup oper<br>
ation. By enforcing these constraints, the model is guided<br>
to learn from augmented samples that contribute positively<br>
to training, improving robustness and generalization in 3D<br>
object detection. ]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-13.html</link><guid isPermaLink="false">Logs/2024-11-13.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Wed, 13 Nov 2024 02:30:31 GMT</pubDate></item><item><title><![CDATA[2024-11-14]]></title><description><![CDATA[ 
 ]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-14.html</link><guid isPermaLink="false">Logs/2024-11-14.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Thu, 14 Nov 2024 09:06:26 GMT</pubDate></item><item><title><![CDATA[2024-11-26]]></title><description><![CDATA[ 
 <br>工作内容<br>
<br>阅读SSL theory相关论文，从98年开始，看了 <a data-href="Combining labeled and unlabeled data with co-training" href="https://sxdl.site/paper-notes/paper-reading-notes/combining-labeled-and-unlabeled-data-with-co-training.html" class="internal-link" target="_self" rel="noopener nofollow">Combining labeled and unlabeled data with co-training</a>， <a data-href="Learning from labeled and unlabeled data with label propagation" href="https://sxdl.site/paper-notes/paper-reading-notes/learning-from-labeled-and-unlabeled-data-with-label-propagation.html" class="internal-link" target="_self" rel="noopener nofollow">Learning from labeled and unlabeled data with label propagation</a>，  <a data-href="Semi-supervised learning using gaussian fields and harmonic functions" href="https://sxdl.site/paper-notes/paper-reading-notes/semi-supervised-learning-using-gaussian-fields-and-harmonic-functions.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning using gaussian fields and harmonic functions</a>， <a data-href="Semi-supervised learning by entropy minimization" href="https://sxdl.site/paper-notes/paper-reading-notes/semi-supervised-learning-by-entropy-minimization.html" class="internal-link" target="_self" rel="noopener nofollow">Semi-supervised learning by entropy minimization</a>， <a data-href="A co-regularization approach to semi-supervised learning with multiple views" href="https://sxdl.site/paper-notes/paper-reading-notes/a-co-regularization-approach-to-semi-supervised-learning-with-multiple-views.html" class="internal-link" target="_self" rel="noopener nofollow">A co-regularization approach to semi-supervised learning with multiple views</a>，<a data-href="Generalization error bounds in semi-supervised classiﬁcation under the cluster assumption" href="https://sxdl.site/paper-notes/paper-reading-notes/generalization-error-bounds-in-semi-supervised-classiﬁcation-under-the-cluster-assumption.html" class="internal-link" target="_self" rel="noopener nofollow">Generalization error bounds in semi-supervised classiﬁcation under the cluster assumption</a>
<br>idea，能否将teacher生成伪标签的过程看作是异常值检测，然后用异常值检测的方法来替代teacher伪标签模块
<br>明日计划<br>
<br>继续阅读SSL theory
<br>梳理异常值检测领域的研究脉络
<br>整理autodl上的数据代码
<br>diffusion的复现继续（如果有条件）
]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-26.html</link><guid isPermaLink="false">Logs/2024-11-26.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Tue, 26 Nov 2024 14:02:37 GMT</pubDate></item><item><title><![CDATA[2024-11-27]]></title><description><![CDATA[ 
 <br>工作内容<br>
<br>将autodl上的训练results下载到了本地
<br>看了youtube的deep semi-supervised 公开课，<a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=PXOhi6m09bA" rel="noopener nofollow" class="external-link" href="https://www.youtube.com/watch?v=PXOhi6m09bA" target="_blank">L9 Semi-Supervised Learning and Unsupervised Distribution Alignment -- CS294-158-SP20 UC Berkeley</a> 理清半监督发展脉络
<br>SESS应该是3D半监督目标检测的开山之作，SESS follow 了 <a data-tooltip-position="top" aria-label="Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results" data-href="Mean teachers are better role models_ Weight-averaged consistency targets improve semi-supervised deep learning results" href="https://sxdl.site/paper-notes/paper-reading-notes/mean-teachers-are-better-role-models_-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results.html" class="internal-link" target="_self" rel="noopener nofollow">mean-teacher</a> 这篇工作。SESS采用首先在有监督样本上预训练的方式，而 mean-teacher 没有，论文中没有解释这样做的原因，后面的工作也都使用相同的训练策略。<a data-href="Not every side is equal_ Localization uncertainty estimation for semi-supervised 3D object detection" href="https://sxdl.site/paper-notes/paper-reading-notes/not-every-side-is-equal_-localization-uncertainty-estimation-for-semi-supervised-3d-object-detection.html" class="internal-link" target="_self" rel="noopener nofollow">Not every side is equal_ Localization uncertainty estimation for semi-supervised 3D object detection</a> 预训练和训练的轮数更少360，在补充材料中提到。
<br>明日计划<br>
<br>再详细看一下<a data-href="Self-training with Noisy Student improves ImageNet classification" href="https://sxdl.site/paper-notes/paper-reading-notes/self-training-with-noisy-student-improves-imagenet-classification.html" class="internal-link" target="_self" rel="noopener nofollow">Self-training with Noisy Student improves ImageNet classification</a> 这篇文章
<br>复现SESS代码，看是否有预训练影响
]]></description><link>https://sxdl.site/paper-notes/logs/2024-11-27.html</link><guid isPermaLink="false">Logs/2024-11-27.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Wed, 27 Nov 2024 13:50:53 GMT</pubDate></item><item><title><![CDATA[2024-12-02]]></title><description><![CDATA[ 
 <br>
<br>周报分享链接
<br>换轴体
<br>暑研陶瓷
]]></description><link>https://sxdl.site/paper-notes/logs/2024-12-02.html</link><guid isPermaLink="false">Logs/2024-12-02.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 02 Dec 2024 05:46:57 GMT</pubDate></item><item><title><![CDATA[📑<a data-tooltip-position="top" aria-label="📑Weekly Reports" data-href="📑Weekly Reports" href="📑weekly-reports.html" class="internal-link" target="_self" rel="noopener nofollow">周报</a>]]></title><description><![CDATA[ 
 <br><br>近一个月周报：<br><br><a data-tooltip-position="top" aria-label="Weeklies/2024-12-02.md" data-href="Weeklies/2024-12-02.md" href="https://sxdl.site/paper-notes/weeklies/2024-12-02.html" class="internal-link" target="_self" rel="noopener nofollow">2024-12-02</a><br><br>近一周日志：<br><br><a data-tooltip-position="top" aria-label="Logs/2024-12-02.md" data-href="Logs/2024-12-02.md" href="https://sxdl.site/paper-notes/logs/2024-12-02.html" class="internal-link" target="_self" rel="noopener nofollow">2024-12-02</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-27.md" data-href="Logs/2024-11-27.md" href="https://sxdl.site/paper-notes/logs/2024-11-27.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-27</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-26.md" data-href="Logs/2024-11-26.md" href="https://sxdl.site/paper-notes/logs/2024-11-26.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-26</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-14.md" data-href="Logs/2024-11-14.md" href="https://sxdl.site/paper-notes/logs/2024-11-14.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-14</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-13.md" data-href="Logs/2024-11-13.md" href="https://sxdl.site/paper-notes/logs/2024-11-13.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-13</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-12.md" data-href="Logs/2024-11-12.md" href="https://sxdl.site/paper-notes/logs/2024-11-12.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-12</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-04.md" data-href="Logs/2024-11-04.md" href="https://sxdl.site/paper-notes/logs/2024-11-04.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-04</a><br><br><br><a data-tooltip-position="top" aria-label="Reports/工作计划（2024年11月-2025年3月）.md" data-href="Reports/工作计划（2024年11月-2025年3月）.md" href="https://sxdl.site/paper-notes/reports/工作计划（2024年11月-2025年3月）.html" class="internal-link" target="_self" rel="noopener nofollow">工作计划（2024年11月-2025年3月）</a>]]></description><link>https://sxdl.site/paper-notes/reorts.html</link><guid isPermaLink="false">Reorts.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 02 Dec 2024 07:14:46 GMT</pubDate></item><item><title><![CDATA[2024-12-02]]></title><description><![CDATA[ 
 <br>From <a data-href="📑Weekly Reports" href="https://sxdl.site/paper-notes/📑weekly-reports.html" class="internal-link" target="_self" rel="noopener nofollow">📑Weekly Reports</a><br><br>工作进展<br>遇到的问题<br>下周计划<br>相关日报<br><br><a data-tooltip-position="top" aria-label="Logs/2024-12-02.md" data-href="Logs/2024-12-02.md" href="https://sxdl.site/paper-notes/logs/2024-12-02.html" class="internal-link" target="_self" rel="noopener nofollow">2024-12-02</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-27.md" data-href="Logs/2024-11-27.md" href="https://sxdl.site/paper-notes/logs/2024-11-27.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-27</a><br><a data-tooltip-position="top" aria-label="Logs/2024-11-26.md" data-href="Logs/2024-11-26.md" href="https://sxdl.site/paper-notes/logs/2024-11-26.html" class="internal-link" target="_self" rel="noopener nofollow">2024-11-26</a>]]></description><link>https://sxdl.site/paper-notes/weeklies/2024-12-02.html</link><guid isPermaLink="false">Weeklies/2024-12-02.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 02 Dec 2024 07:01:57 GMT</pubDate></item><item><title><![CDATA[📑Weekly Reports]]></title><description><![CDATA[ 
 <br><br>]]></description><link>https://sxdl.site/paper-notes/📑weekly-reports.html</link><guid isPermaLink="false">📑Weekly Reports.md</guid><dc:creator><![CDATA[sxdl]]></dc:creator><pubDate>Mon, 02 Dec 2024 07:17:55 GMT</pubDate></item><item><title><![CDATA[3D gaussian splatting for real-time radiance field rendering]]></title><description/></item></channel></rss>